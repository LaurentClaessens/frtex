% This is part of Mes notes de mathématique
% Copyright (c) 2011-2013,2016
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Sous-groupes du groupe linéaire}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}[\cite{KXjFWKA}]       \label{LemOCtdiaE}
    Soit \( V\) un espace vectoriel de dimension finie muni d'une norme euclidienne \( \| . \|\). Soit \( K\) un compact convexe de \( V\) et \( G\), un sous groupe compact de \( \GL(V)\) tel que
    \begin{equation}
        u(K)\subset K
    \end{equation}
    pour tout \( u\in G\). Alors il existe \( a\in K\) tel que \( u(a)=a\) pour tout \( u\in G\).
\end{lemma}
\index{groupe!linéaire!sous-groupes compacts}
\index{compacité!sous-groupes du groupe linéaire}

\begin{proof}
    Avant de nous lancer dans la preuve, nous avons besoin d'un petit résultat.
    \begin{subproof}
        \item[Un pré-résultat]

        Nous commençons par prouver que si \( v\in \aL(V)\) vérifie \( v(K)\subset K\), alors \( v\) a un point fixe dans \( K\). Pour cela nous considérons \( x_0\in K\) et la suite
        \begin{equation}
            x_k=\frac{1}{ k+1 }\sum_{i=0}^kv^i(x_0).
        \end{equation}
        Étant donné que \( K\) est convexe et stable par \( v\), la suite \( (x_k)\) est contenue dans \( K\) et accepte une sous-suite convergente\footnote{C'est Bolzano-Weierstrass, théorème \ref{ThoBWFTXAZNH}.} que nous allons noter \( x_{\varphi(n)}\) avec \( \varphi\colon \eN\to \eN\) strictement croissante. Soit \( a\in K\) la limite :
        \begin{equation}
            \lim_{n\to \infty} x_{\varphi(n)}=a.
        \end{equation}
        Tant que nous y sommes nous pouvons aussi calculer \( v(x_k)\) :
        \begin{subequations}
            \begin{align}
                v(x_k)&=v\left( \frac{1}{ k+1 }\sum_{i=1}^kv^i(x_0) \right)\\
                &=\frac{1}{ k+1 }\sum_{i=0}^kv^{i+1}(x_0)\\
                &=x_k+\frac{1}{ k+1 }\Big( v^{k+1}(x_0)-x_0 \Big).      \label{EqUAfcaKG}
            \end{align}
        \end{subequations}
        La norme \( \| v^{k+1}(x_0)-x_0 \|\) est bornée par le diamètre de \( K\), donc en prenant la limite \( k\to \infty\) le second terme de \eqref{EqUAfcaKG} tend vers zéro. En prenant ces égalités en \( k=\varphi(n)\) et en prenant \( n\to\infty\), nous trouvons
        \begin{equation}
            v(a)=a,
        \end{equation}
        c'est à dire le résultat que nous voulions dans un premier temps.

    \item[Une norme sur \( V\)]

        Nous passons maintenant à la preuve du lemme. D'abord nous remarquons que le groupe \( G\) agit sur \( V\) par \( u\cdot x=u(x)\) et de plus, considérant la fonction continue
        \begin{equation}
            \begin{aligned}
                \alpha\colon G&\to V \\
                u&\mapsto u(x), 
            \end{aligned}
        \end{equation}
        nous voyons que les orbites de cette action sont compactes en tant qu'image par \( \alpha\) du compact \( G\) (théorème \ref{ThoImCompCotComp}). Nous posons
        \begin{equation}
            \begin{aligned}
                \nu\colon V&\to \eR^+ \\
                x&\mapsto \max_{u\in G}\| u(x) \|. 
            \end{aligned}
        \end{equation}
        Cette définition a un sens parce que l'orbite \( \{ u(x)\tq u\in G \}\) est compacte dans \( V\) et donc l'ensemble des normes est compact dans \( \eR\) et admet un maximum. De plus cela donne une norme sur \( V\) parce que nous vérifions les conditions de la définition \ref{DefNorme} :
        \begin{enumerate}
            \item
                Pour tout \( x,y\in V\) nous avons :
                \begin{equation}
                    \nu(x+y)=\max_{u\in G}\| u(x)+u(y) \|\leq \max_{u\in G}\left( \| u(x) \|+\| u(y) \| \right)\leq \nu(x)+\nu(y).
                \end{equation}
            \item
                Si \( \nu(x)=0\), alors l'égalité \( \max_{u\in G}\| u(x) \|=0\) nous enseigne que \( \| u(x) \|=0\) pour tout \( u\in G\) et donc en particulier avec \( u=\id\) nous trouvons \( x=0\).
            \item
                Pour tout \( \lambda\in \eR\) et \( x\in V\),
                \begin{equation}
                    \nu(\lambda x)=\max_{u\in G}\| u(\lambda x) \|=\max\| \lambda u(x) \|=\max| \lambda |\| u(x) \|=| \lambda |\nu(x).
                \end{equation}
        \end{enumerate}
        De plus la fonction \( \nu\) est constante sur les orbites de \( G\).

    \item[Un point fixe]

        Pour tout \( u\in G\) nous posons
        \begin{equation}
            F_u=\{ x\in K\tq u(x)=x \};
        \end{equation}
        par le pré-résultat, aucun de ces ensembles n'est vide. Ils sont de plus tous fermés par continuité de \( u\) (le complémentaire est ouvert). Nous devons prouver que \( \bigcap_{u\in G}F_u\neq \emptyset\) parce qu'une intersection serait un point fixe de tous les éléments de \( G\). Supposons donc que \( \bigcap_{u\in G}F_u=\emptyset\). Alors les complémentaires des \( F_u\) forment un recouvrement ouvert de \( K\) et nous pouvons en extraire un sous-recouvrement fini par compacité. Soient \( \{ u_i \}_{i=1,\ldots, p}\) les éléments qui réalisent ce recouvrement. Alors
        \begin{equation}
            \bigcap_{i=1}^pF_{u_i}=\emptyset.
        \end{equation}
        Nous considérons l'opérateur
        \begin{equation}
            v=\frac{1}{ p }\sum_{i=1}^pu_i\in\aL(V).
        \end{equation}
        Vu que \( K\) est convexe et stable sous chacun des \( u_i\), nous avons aussi \( v(K)\subset K\) et donc il existe \( a\in K\) tel que \( v(a)=a\). Pour ce \( a\), nous avons
        \begin{subequations}
            \begin{align}
                \nu\big( v(a) \big)&=\nu\left( \frac{1}{ p }\sum_{i=1}^pu_i(a) \right)      \label{EqDXSnwPb}\\
                &\leq \frac{1}{ p }\sum_{i=1}^p\nu\left( u_i(a) \right)\\
                &=\frac{1}{ p }\sum_{i=1}^p\nu(a)\\
                &=\nu(a)
            \end{align}
        \end{subequations}
        où nous avons utilisé la constance de \( \nu\) sur les orbites de \( G\). Par ailleurs nous savons que \( v(a)=a\), donc en réalité à gauche dans \eqref{EqDXSnwPb} nous avons \( \nu(a)\) et toutes les inégalités sont des égalités. Nous avons en particulier
        \begin{equation}        \label{EqBMjypoV}
                \nu\left( \sum_{i=1}^pu_i(a) \right) =\sum_{i=1}^p\nu\left( u_i(a) \right).
        \end{equation}
        Notons \( u_0\in G\) l'élément qui réalise le maximum de la définition de \( \nu\) pour le vecteur \( \sum_iu_i(a)\) :
        \begin{equation}
            \nu\left( \sum_i u_i(a) \right)=\| u_0\left( \sum_iu_i(a) \right) \|\leq\sum_i\| u_0u_i(a) \|\leq \sum_i\nu\big( u_i(a) \big).
        \end{equation}
        Mais nous venons de voir (équation \eqref{EqBMjypoV}) que l'expression de gauche est égale à celle de droite. Donc les inégalités sont des égalités et en particulier la première inégalité devient l'égalité
        \begin{equation}
            \| \sum_iu_0u_i(a)  \|=\sum_i\| u_0u_i(a) \|.
        \end{equation}
        En vertu du lemme \ref{LemLPOHUme}, il existe des nombres positifs \( \lambda_i\) tels que
        \begin{equation}
            u_0u_1(a)=\lambda_2u_0u_2(a)=\ldots =\lambda_pu_0u_p(a).
        \end{equation}
        Du fait que \( u_0\) est inversible nous avons aussi 
        \begin{equation}       \label{EqSTQwfIl}
            u_1(a)=\lambda_2u_2(a)=\ldots =\lambda_pu_p(a).
        \end{equation}
        Mais par constance de \( \nu\) sur les orbites nous avons \( \nu(u_i(a))=\nu(u_j(a))\) pour tout \( i\) et \( j\); en appliquant \( \nu\) à la série d'égalités \eqref{EqSTQwfIl}, nous trouvons que tous les \( \lambda_i\) doivent être égaux à \( 1\). En particulier
        \begin{equation}     
            u_1(a)=u_2(a)=\ldots =u_p(a).
        \end{equation}
        
        Nous récrivons maintenant l'équation \( v(a)=a\) avec la définition de \( v\) :
        \begin{equation}
            a=v(a)=\frac{1}{ p }\sum_{i=1}^pu_i(a)=u_j(a)
        \end{equation}
        pour n'importe quel \( j\). Donc
        \begin{equation}
            a\in\bigcap_{i=1}^pF_{u_i},
        \end{equation}
        ce qui contredit notre hypothèse de départ.
        \end{subproof}
\end{proof}

\begin{proposition}[\cite{NHXUsTa,KXjFWKA,RXvMqkd}]     \label{PropQZkeHeG}
    Soit \( G\) un sous-groupe compact de \( \GL(n,\eR)\). Alors 
    \begin{enumerate}
        \item
            Il existe une forme quadratique définie positive \( q\) sur \( \eR^n\) telle que \( G\subset \gO(q)\).
        \item
            Le groupe \( G\) est conjugué à un sous-groupe de \( \gO(n,\eR)\).
    \end{enumerate}
\end{proposition}
\index{groupe!action!utilisation}
\index{matrice!équivalence!dans le groupe linéaire}
\index{forme!quadratique!groupe orthogonal}
\index{groupe!orthogonal!d'une forme quadratique}
\index{endomorphisme!préservant une forme quadratique}

\begin{proof}
    Nous considérons le (pas tout à fait) morphisme de groupe
    \begin{equation}
        \begin{aligned}
            \rho\colon G&\to \GL\big( \gS(n,\eR) \big) \\
            u&\mapsto \rho_u\colon s\to  u^tsu,
        \end{aligned}
    \end{equation}
    et tant que nous y sommes à considérer, nous considérons l'ensemble
    \begin{equation}
        H=\{ M^tM\tq M\in G \}\subset \gS(n,\eR).
    \end{equation}
    Cet ensemble est constitué de matrices définies positives parce que si \( \langle M^tMx, x\rangle =0\), alors \(0= \langle Mx, Mx\rangle =\| Mx \|\), mais \( M\) étant inversible, cela implique que \( x=0\). Qui plus est cet ensemble est compact dans \( \GL(n,\eR)\) en tant qu'image du compact \( G\) par l'application continue \( M\mapsto M^tM\). L'enveloppe convexe \( K=\Conv(H)\) est alors également compacte par le théorème \ref{CorOFrXzIf}. Enfin nous considérons \( L=\rho(G)\), qui est un sous-groupe compact de \( \GL\big( \gS(n,\eR) \big)\) parce que \( \rho_u\rho_v=\rho_{vu}\in\rho(G)\). Nous remarquons que \( \rho_u\) étant linéaire, elle préserve les combinaisons convexes et donc pour tout \( u\in G\), \( \rho_u(K)\subset K\).

    Bref, \( L\) est un sous-groupe compact de \( \GL(n,\eR)\) préservant le compact \( K\) de \( \gS(n,\eR)\). Par le lemme \ref{LemOCtdiaE}, il existe \( s\in K\) tel que \( \rho_u(s)=s\) pour tout \( u\in G\). Ou encore :
    \begin{equation}
        u^tsu=s
    \end{equation}
    pour tout \( u\in G\). Fort de ce \( s\) bien particulier, nous considérons la forme quadratique associée : \( q(x)=x^tsx\). Cette forme est définie positive parce que \( s\) l'est. Nous avons \( G\subset \gO(q)\) parce que si \( u\in G\) alors
    \begin{equation}
        q\big( ux \big)=(ux)^tsux=x^t\underbrace{u^tsu}_{=s}x=q(x).
    \end{equation}
    Le premier point est prouvé.

    La matrice \( s\) est symétrique et définie positive. Elle peut donc être diagonalisée\footnote{Théorème \ref{ThoeTMXla}} en \( \diag(\lambda_1,\ldots, \lambda_n)\) avec \( \lambda_i>0\), et ensuite transformée en la matrice \( \mtu_n\) par la matrice \( \diag(1/\sqrt{\lambda_i})\). Nous avons donc une matrice \( a\in\GL(n,\eR)\) telle que \( a^tsa=\mtu_n\). Avec ça, si \( u\in G\), nous avons
    \begin{equation}
        (a^{-1}ua)^t(a^{-1} ua)=(a^{-1}ua)^t\mtu_n(a^{-1} ua)=a^tu^t(a^t)^{-1}a^tsaa^{-1}ua=a^tu^tsua=a^tsa=\mtu,
    \end{equation}
    ce qui prouve que \( a^{-1} ua\) est dans \( \gO(n,\eR)\), et donc que \( a^{-1} G a\subset \gO(n,\eR)\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Isométries de l'espace euclidien}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons l'espace affine euclidien \( A=\affE_n(\eR)\) modelé sur \( \eR^n\) avec sa métrique usuelle. Un premier grand résultat sera le théorème \ref{ThoDsFErq} qui dira que les isométries de cet espace sont des applications linéaires\footnote{Regardez un coup dans le second tome du Landau et Lifchitz voir comment ils démontrent que les transformations de Lorentz doivent être linéaires. Ça vous donnera une idée à quel point notre théorème est cool.}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Structure du groupe  \texorpdfstring{\( \Isom(\eR^n)\)}{Isom(Rn)} }
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}
    La forme quadratique \( q(x)=x_1^2+x_2^2\) donne la norme euclidienne. La forme bilinéaire associée est \( b(x,y)=x_1y_1+x_2y_2\), qui est le produit scalaire usuel.
\end{example}

Il ne faudrait pas déduire trop vite que la formule \( \| x \|^2=q(x)\) donne une norme dès que \( q\) est non dégénérée. En effet \( q\) peut ne pas être définie positive. La forme \( q(x)=x_1^2-x_2^2\) prend des valeurs positives et négatives. A fortiori \( d(x,y)=q(x-y)\) ne donne pas toujours une distance.

\begin{definition}
    Une \defe{isométrie}{isométrie!de forme quadratique} pour la forme \( q\) est une application bijective \( f\colon V\to V\) telle que \( q(x-y)=q\big( f(x)-f(y) \big)\). Dans les cas où \( q\) donne une distance, alors c'est une isométrie au sens usuel.
\end{definition}

\begin{lemma}   \label{LemewGJmM}
    Soit \( q\) une forme quadratique et \( b\) la forme bilinéaire associée par le lemme \ref{LEMooLKNTooSfLSHt}.  Pour une application bijective \( f\colon E\to E\) telle que \( f(0)=0\), les conditions suivantes sont équivalentes: 
    \begin{enumerate}
        \item
            \( b\big( f(x),f(y) \big)=b(x,y)\) pour tout \( x,y\in E\);
        \item
            \( q\big( f(x)-f(y) \big)=q(x-y)\) pour tout \( x,y\in E\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Dans le sens direct, en posant \( x=y\) nous trouvons tout de suite \( q(f(x))=q(f)\); ensuite en utilisant la distributivité de \( b\),
    \begin{subequations}
        \begin{align}
            q\big( f(x)-f(y) \big)&=b\big( f(x)-f(y),f(x)-f(y) \big)\\
            &=q\big( f(x) \big)-2b\big( f(x),f(y) \big)+q\big( f(y) \big)\\
            &=q(x)+q(y)-2b(x,y)\\
            &=q(x-y).
        \end{align}
    \end{subequations}
    
    Dans l'autre sens, nous commençons par remarquer que l'hypothèse \( f(0)=0\) donne \( q(x)=q\big( f(x) \big)\). Ensuite nous utilisons l'identité de polarisation \eqref{EqMrbsop} :
    \begin{subequations}
        \begin{align}
            b\big( f(x),f(y) \big)&=\frac{ 1 }{2}\big[ q\big( f(x) \big)+q\big( f(y) \big)-q\big( f(x-y) \big) \big]\\
            &=\frac{ 1 }{2}\big[ q(x)+q(y)-q(x-y) \big]\\
            &=b(x,y).
        \end{align}
    \end{subequations}
\end{proof}

\begin{theorem}[\cite{ooQFKAooFnllQU}]     \label{ThoDsFErq}
    Soit \( f\colon E\to E\) une bijection telle que
    \begin{equation}
        q(x-y)=q\big( f(x)-f(y) \big)
    \end{equation}
    pour tout \( x,y\in E\). Alors
    \begin{enumerate}
        \item
            si \( f(0)=0\), alors \( f\) est linéaire;
        \item
            si \( f(0)\neq 0\) alors \( f\) est affine\footnote{Définition \ref{DEFooJWWYooNqfoPJ}.}.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Si \( f(0)=0\), nous savons par le lemme \ref{LemewGJmM} que \( b\big( f(x),f(y) \big)=b(x,y)\). Soit \( z\in E\); étant donné que \( f\) est bijective nous pouvons considérer l'élément \( f^{-1}(z)\in E\) et calculer
    \begin{subequations}
        \begin{align}
            b\big( f(x+y),z \big)&=b\big( f(x+y),f(f^{-1}(z)) \big)\\
            &=b(x+y,f^{-1}(z))\\
            &=b(x,f^{-1}(z))+b(y,f^{-1}(z))\\
            &=b(f(x),z)+b(f(y),z)\\
            &=b\big( f(x)+f(y),z \big),
        \end{align}
    \end{subequations}
    donc \( f(x+y)=f(x)+f(y)\) par le lemme \ref{LemyKJpVP}. 

    De la même façon on trouve \( b\big( f(\lambda x),z \big)=b\big( \lambda f(x),z \big)\) qui prouve que \( f(\lambda x)=\lambda f(x)\) et donc que \( f\) est linéaire.

    Si \( f(0)\neq 0\), alors nous posons \( g(x)=f(x)-f(0)\) qui vérifie \( g(0)=0\) et
    \begin{equation}
        q\big( g(x)-g(y) \big)=q\big( f(x)-f(0)-f(y)+f(0) \big)=q(x-y).
    \end{equation}
    Nous pouvons donc appliquer le premier point à \( g\), déduire que \( g\) est linéaire et donc que \( f\) est affine.
\end{proof}

\ifnumequal{\value{isAgreg}}{1}{}{
\begin{remark}
    Des preuves alternatives.
    \begin{enumerate}
        \item
            En utilisant un peut plus d'indices et un peu plus de mots comme «tenseurs», peut être trouvée  \href{http://physics.stackexchange.com/questions/12664/proving-that-interval-preserving-transformations-are-linear}{ici}. Le fait que la preuve donnée soit tensorielle me fait penser que le résultat peut encore être généralisé.
        \item
            Et encore une autre preuve, utilisant des techniques de groupes de Lie sera la proposition \ref{PROPooDVIWooAFDNPy}.
    \end{enumerate}
\end{remark}
}

Nous pouvons maintenant particulariser tout cela au cas de \( \eR^n\) pour voir quel résultat nous avons à peine prouvé. Nous notons ici \( T(n)\) le groupe des translations sur \( \eR^n\). Un élément de \( T(n)\) est une translation \( \tau_v\) donnée par un vecteur \( v\) et agissant sur \( \eR^n\) par
\begin{equation}
    \begin{aligned}
        \tau_v\colon \eR^n&\to \eR^{n} \\
        x&\mapsto x+v. 
    \end{aligned}
\end{equation}
Ce groupe est isomorphe au groupe abélien \( (\eR^n,+)\), et nous allons souvent identifier \( \tau_v\) à \( v\).

Si vous ne voulez pas savoir ce qu'est un produit semi-direct de groupes, vous pouvez lire seulement le point \ref{ITEMooLLUIooIGsknv} du théorème suivant, et passer directement à la remarque \ref{REMooLUEZooIwvTqu}.
\begin{theorem}     \label{THOooQJSRooMrqQct}
    Un peu de structure sur \( \Isom(\eR^n)\).
    \begin{enumerate}
        \item       \label{ITEMooLLUIooIGsknv}
            L'application
            \begin{equation}
                \begin{aligned}
                    \psi\colon T(n)\times \gO(n)&\to \Isom(\eR^n) \\
                    (v,\Lambda)&\mapsto \tau_v\circ\Lambda 
                \end{aligned}
            \end{equation}
            est une bijection. Ici,  \( T(n)\) est le groupe des translations de \( \eR^n\).
        \item
            Un couple \( (v,\Lambda)\in T(n)\times\SO(n)\) agit sur \( x\in \eR^n\) par
            \begin{equation}
                (v,\Lambda)x=\Lambda x+v
            \end{equation}
            au sens où \( \psi(v,\Lambda)x=\Lambda x+v\).
        \item       \label{ITEMooEWSIooNKzRxB}
            En tant que groupes,
            \begin{equation}
                \Isom(\eR^n)\simeq T(n)\times_{\rho}\gO(n)
            \end{equation}
            où \( \rho\) représente l'action adjointe de \( \gO(n)\) sur \( T(n)\) et \( \times_{\rho}\) dénotes le produit semi-direct de la définition \ref{DEFooKWEHooISNQzi}.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Point par point.
    \begin{enumerate}
        \item
            Prouvons que l'application proposée est injective et surjective. Notons aussi que ce point ne parle pas de structure de groupe, mais seulement d'une bijection en tant qu'ensembles.    
            \begin{subproof}
                \item[Injection]
                    Si \( \psi(v,\Lambda)=\psi(w,\Lambda')\) alors en appliquant sur \( x=0\) nous avons tout de suite \( v=w\). Et ensuite \( \Lambda=\Lambda'\) est immédiat.
                \item[Surjection]
                    Une isométrie \( g\in\Isom(\eR^n)\) est une application \( g\colon \eR^n\to \eR^n\) telle que \( d(x,y)=d\big( g(x),g(y) \big)\). Dans le cas de \( \eR^n\) cela se traduit par
                    \begin{equation}
                        \| x-y \|=\big\| g(x)-g(y) \big\|,
                    \end{equation}
                    Vu que \( x\mapsto\| x \|\) est une forme quadratique, elle tombe sous le coup du théorème  \ref{ThoDsFErq}, ce qui nous permet de dire que \( g\) est affine. Or par définition une application est affine lorsqu'elle est la composée d'une translation et d'une application linéaire.
            \end{subproof}
        \item
            C'est seulement le fait que \( (\tau_v\circ\Lambda)x=\tau_v\big( \Lambda x \big)=\Lambda(x)+v\).
        \item
            Nous allons étudier l'application
            \begin{equation}
                \psi\colon T(n)\times_{\rho}O(n)\to \Isom(\eR^n).
            \end{equation}
            \begin{subproof}
            \item[Le produit semi-direct est bien définit]
                Il faut montrer que
                \begin{equation}
                    \begin{aligned}
                        \rho\colon O(n)&\to \Aut\big( T(n) \big) \\
                        \Lambda&\mapsto \AD(\Lambda) 
                    \end{aligned}
                \end{equation}
                est correcte.

                D'abord pour \( \Lambda\in O(n)\), nous avons bien \( \rho_{\Lambda}(\tau_v)\in T(n)\) parce qu'en appliquant à \( x\in \eR^n\),
                    \begin{equation}
                        (\Lambda\tau_v\Lambda^{-1})(x)=\Lambda\big( \tau_v(\Lambda^{-1} x) \big)=\Lambda\big( \Lambda^{-1}x+v \big)=x+\Lambda(v)=\tau_{\Lambda(v)}(x).
                    \end{equation}
                    Donc \( \rho_{\Lambda}(\tau_v)=\tau_{\Lambda(v)}\).

                    De plus, \( \rho_{\Lambda}\in\Aut\big( T(n) \big)\) parce que 
                    \begin{equation}
                        \rho_{\Lambda}\big( \tau_v\circ \tau_w \big)=\rho_{\Lambda}(\tau_v)\circ\rho_{\Lambda}(\tau_v),
                    \end{equation}
                    comme on peut aisément vérifier que les deux membres sont égaux à \( \tau_{\Lambda(v+w)}\).
                \item[\( \psi\) est une bijection]
                    Cela est déjà vérifié.
                \item[\( \psi\) est un homomorphisme]
                    Nous avons d'une part
                    \begin{equation}
                        \psi\big( (v,g)(w,h) \big)=\psi\big( v\rho_g(w),gh \big)=\tau_v\circ g\circ\tau_w\circ g^{-1}\circ g\circ h=\tau_v\circ g\circ\tau_w\circ h.
                    \end{equation}
                    Et d'autre part,
                    \begin{equation}
                        \psi(v,g)\circ\psi(w,h)=\tau_v\circ g\circ \tau_w\circ h,
                    \end{equation}
                    ce qui est la même chose.
            \end{subproof}
    \end{enumerate}
\end{proof}

\begin{remark}      \label{REMooLUEZooIwvTqu}
    Notons au passage la loi de groupe sur les couples qui est donnée, pour tout \( v,v'\in \eR^n\), \( \Lambda,\Lambda'\in\SO(n)\), par
    \begin{equation}    \label{EqDiHcut}
            (v,\Lambda)\cdot(v',\Lambda')=(\Lambda v'+v,\Lambda\Lambda')
    \end{equation}
    comme le montre le calcul suivant :
    \begin{subequations}
        \begin{align}
            (v,\Lambda)\cdot(v',\Lambda')x&=(v,\Lambda)(\Lambda'x+v')\\
            &=\Lambda\Lambda'x+\Lambda v'+v\\
            &=(\Lambda v'+v,\Lambda\Lambda')x.
        \end{align}
    \end{subequations}
\end{remark}

\begin{proposition}[\cite{ooZYLAooXwWjLa}]      \label{PROPooDHYWooXxEXvl}
    Soit \( n\geq 1\) et un élément \( R\) de \( \gO(n)\) de déterminant \( -1\) tel que \( R^2=\id\). En posant \( C_2=\{ \id,R \}\) nous avons
    \begin{equation}
        \gO(n)=\SO(n)\times_{\rho} C_2
    \end{equation}
\end{proposition}

\begin{proof}
    Notons que pour \( R\) nous pouvons prendre par exemple \( (x_1,\ldots, x_n)\mapsto (-x_1,x_2,\ldots, x_n)\). Ce que nous allons montrer être un isomorphisme est :
    \begin{equation}
        \begin{aligned}
            \psi\colon \SO(n)\times C_2&\to \gO(n) \\
            (A,h)&\mapsto Ah. 
        \end{aligned}
    \end{equation}
    \begin{subproof}
        \item[Injectif]
            Soient \( A,B\in \SO(n)\) et \( h,k\in C_2\) tels que \( \psi(A,h)=\psi(B,k)\), c'est à dire tels que \( Ah=Bk\). Vu que \( \det(A)=\det(B)=1\) nous avons \( \det(h)=\det(k)\). Mais comme \( C_2\) contient un élément de déterminant \( 1\) et un élément de déterminant \( -1\), nous avons \( h=k\). De là \( A=B\).
        \item[Surjectif]
            Soit \( X\in\gO(n)\). Si \( \det(X)=1\) alors \( X\in \SO(n)\) et \( X=\psi(X,\mtu)\). Si par contre \( \det(X)=-1\) alors \( XR\in\SO(n)\) parce que \( \det(XR)=1\) et nous avons
            \begin{equation}
                \psi(XR,R)=XR^2=X.
            \end{equation}
        \item[Homomorphisme]
            Nous avons
            \begin{equation}
                \psi\Big( (A,h)(B,k) \Big)=\psi\big( A\rho_h(B),hk \big)=A(hBh^{-1})hk=AhBk,
            \end{equation}
            tandis que
            \begin{equation}
                \psi(A,h)\psi(B,k)=AhBk,
            \end{equation}
            qui est la même chose.
    \end{subproof}
\end{proof}

\begin{lemma}[\cite{JGAdTA}]
    Si \( n\geq 3\), alors toute droite est intersection de deux plans non isotropes.
\end{lemma}

\begin{proposition}[\cite{ooZYLAooXwWjLa}]      \label{PROPooVEEUooJQmmkN}
    Si une isométrie de \( \eR^n\) fixe un ensemble \( F\) de points, alors elle fixe l'espace affine engendrée par \( F\).
\end{proposition}

\begin{proof}
    Soit \( f\in \Isom(\eR^n)\) fixant \( F\). Par le théorème \ref{ThoDsFErq}, c'est une application affine et l'ensemble \( \Fix(f)\) des points fixés par \( f\) est un sous-espace affine de \( \eR^n\), grâce à la proposition \ref{PROPooYRCJooIcmUVI}.

    Donc \( \Fix(f)\) est un espace affine contenant \( F\). Vu que l'espace affine engendré par \( F\) est l'intersection de tous les espace affines contenant \( F\), il est en particulier contenu dans \( \Fix(f)\).
\end{proof}

\begin{corollary}       \label{CORooZHZZooDgTzsW}
    Si \( f\) et \( g\) sont des isométries de \( \eR^n\) qui coïncident sur \( F\), alors elles coïncident sur l'espace affine engendré par \( F\).
\end{corollary}

\begin{proof}
    Nous considérons \( h=g^{-1}\circ f\) qui est une isométrie de \( \eR^n\) fixant \( F\). Elle fixe donc, par la proposition \ref{PROPooVEEUooJQmmkN}, l'espace affine engendré par $F$. Or tout point fixé par \( h\) est un point sur lequel \( g\) et \( f\) coïncident.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Classification des isométries de \( \eR\)}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( x\in \eR\); nous notons \( \sigma_x\) la \defe{réflexion}{réflexion}\nomenclature[R]{\( \sigma_x\)}{réflexion par rapport à \( x\)} par rapport à \( x\), c'est à dire
\begin{equation}
    \sigma_x(y)=2x-y.
\end{equation}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]
    Toute isométrie de \( \eR\) est composée d'au plus \( 2\) réflexions. Plus précisément toute isométrie de \( \eR\) est dans une des trois catégories suivantes :
    \begin{itemize}
        \item l'identité (\( 0\) réflexions),
        \item les réflexions,
        \item les translations (\( 2\) réflexions)
    \end{itemize}
\end{theorem}

\begin{proof}
    Nous divisions la preuve en fonction du nombre de points fixés par l'isométrie \( f\in\Isom(\eR)\).
    \begin{subproof}
        \item[\( f\) fixe deux points distincts]
            Alors elle fixe l'espace affine engendrée par ces deux points par la proposition \ref{PROPooVEEUooJQmmkN}. Donc \( f\) fixe tout \( \eR\) et est l'identité.
        \item[\( f\) fixe un unique point]
            Soit \( x\) l'unique point fixé par \( f\) et considérons \( y\neq x\). Vu que \( x=f(x)\) et que \( f\) est une isométrie,
            \begin{equation}
                d\big( x,f(y) \big)=d\big( f(x),f(y) \big)=d(x,y).
            \end{equation}
            Donc \( f(y)\) est à égale distance de \( x\) que \( y\). Autrement dit, \( f(y)\) est soit \( y\) soit \( \sigma_x(y)\). Mais comme \( x\) est unique point fixe, \( f(y)=\sigma_x(y)\). Ce raisonnement étant valable pour tout \( y\neq x  \) nous avons \( f=\sigma_x\).
        \item[\( f\) n'a pas de points fixes]
            Soit \( x\in \eR\) et \( y=\frac{ x+f(x) }{ 2 }\). Nous posons \( g=\sigma_y\circ f\). Alors \( x\) est un point fixe de \( g\) parce que
            \begin{equation}
                g(x)=\sigma_y\big( f(x) \big)=2y-f(x)=x.
            \end{equation}
            Donc soit \( g\) est l'identité soit \( g\) est une réflexion (par les points précédents). La possibilité \( g=\id\) est exclue parce que cela ferait \( f=\sigma_y\) alors que \( f\) n'a pas de points fixes. Donc \( g\) est une réflexion; et comme \( x\) est un point fixe de \( g\) nous avons \( g=\sigma_x\). Au final
            \begin{equation}
                f=\sigma_y\circ\sigma_x.
            \end{equation}
            Montrons que cela implique que \( f\) est une translation :
            \begin{equation}
                \sigma_y\sigma_x(z)=\sigma_y(2x-z)=2y-2x+z=z+2(y-x).
            \end{equation}
            Donc \( \sigma_y\circ\sigma_x\) est la translation de vecteur \( 2(y-x)\).
    \end{subproof}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Classification des isométries de \( \eR^2\)}
%---------------------------------------------------------------------------------------------------------------------------

Si \( l\) est une droite dans \( \eR^2\), nous notons \( \sigma_l\in\Isom(\eR^2)\) la réflexion d'axe \( l\). Cela est une isométrie et donc une application affine par le théorème \ref{ThoDsFErq}. Le lemme suivant détermine comment la réflexion \( \sigma_{\ell}\) se décompose en une translation et une application linéaire.

La réflexion d'axe \( \ell\) peut être caractérisée par quelque propriétés.

\begin{lemma}[Caractérisation des réflexions]
    Soit une droite \( \ell\) de \( \eR^2\). Il existe une unique application \( f\colon \eR^2\to \eR^2\) telle que
    \begin{enumerate}
        \item
            \( f(x)=x\) pour tout \( x\in \ell\).
        \item
            \( f\) échange les côtés de \( \ell\).
        \item
            \( f\) laisse invariants les droites perpendiculaires à \( \ell\) et les cercles dont le centre est sur \( \ell\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Soit \( x\) hors de \( \ell\) et \( p\) la droite perpendiculaire à \( \ell\) et passant par \( x\). Nous avons \( f(x)\in p\). En nommant \( P\) l'intersection entre \( \ell\) et \( p\), nous considérons le cercle \( S(P,\| Px \|)\) qui est un cercle dont le centre est sur \( \ell\). Il contient \( x\) et donc \( f(x)\in S(P,\| Px \|)\).

    Donc \( f(x)\in p\cap S(P,\| Px \|)\). L'intersection entre un cercle et une droite contient de façon générique deux point. L'un est \( x\), mais \( f(x)=x\) n'est pas possible parce que \( x\) est hors de \( \ell\) et \( f\) doit inverser les côtés de \( \ell\). Donc \( f(x)\) est l'autre.

    Cela prouve l'unicité. En ce qui concerne l'existence, il suffit de noter que la réflexion \( \sigma_{\ell}\) satisfait les contraintes.
\end{proof}

\begin{lemma}   \label{LEMooVOJLooCFgdNG}
    Soit une droite \( \ell\). Alors
    \begin{equation}
        \sigma_{\ell}=\tau_{2w}\circ\sigma_{\ell_0}
    \end{equation}
    où \( \ell_0\) est la droite parallèle à \( \ell\) passant par l'origine, et \( w\) est le vecteur perpendiculaire à \( \ell\) tel que \( \ell_0=\ell+v\).
\end{lemma}

\begin{proof}
    Il faut trouver trois points non alignés sur lesquels les deux applications coïncident; cela suffira par le corollaire \ref{CORooZHZZooDgTzsW}. 

    Pour tous les points de \( \ell_0\), l'égalité fonctionne parce que si \( x\in\ell_0\),
    \begin{equation}
        \sigma_{\ell}(x)=x+2w,
    \end{equation}
    tandis que
    \begin{equation}
        \sigma_{\ell_0}(x)+2w=x+2w
    \end{equation}
    du fait que \( \sigma_{\ell_0}(x)=x\).

    Si \( x\in\ell\), alors
    \begin{equation}
        \sigma_{\ell}(x)=x
    \end{equation}
    tandis que
    \begin{equation}
        \sigma_{\ell_0}(x)+2w=x-2w+2w=x.
    \end{equation}
    Donc les applications affines \( \sigma_{\ell}\) et \( x\mapsto \sigma_{\ell_0}(x)+2w\) coïncident sur \( \ell\) et \( \ell_0\). Elles coïncident donc partout.
\end{proof}

Avant d'aborder la classification des isométries, nous devons parler de l'angle entre deux droites. Si \( \ell_1\) et \( \ell_2\) sont deux droites, alors il est bien clair deux angles peuvent prétendre être «l'angle entre \( \ell_1\) et \( \ell_2\)». De plus chacun de ces deux angles sont doubles parce que si \( \alpha\) peut prétendre être l'angle entre \( \ell_1\) et \( \ell_2\), alors \( -\alpha\) peut également prétendre.

\begin{lemmaDef}        \label{DEFooEGKOooRPGOAs}
    Si \( \ell_1\) et \( \ell_2\) sont deux droites sécantes au point \( O\) et si \( x\in\ell_1\) n'est pas \( O\), alors il existe un unique \( \alpha\in \mathopen[ 0 , \pi \mathclose[\) tel que \( R_O(\alpha)x\in \ell_2\). La valeur de \( \alpha\) ne dépend pas du choix du point \( x\in \ell_1\).

        Cet angle \( \alpha\) est l'\defe{angle}{angle!entre deux droites} de \( \ell_1\) à \( \ell_2\).
\end{lemmaDef}

\begin{remark}
    Nous ne parlons pas de l'angle entre \( \ell_1\) et \( \ell_2\) mais bien de l'angle \emph{de} \( \ell_1\) \emph{à} \( \ell_2\). L'ordre des droites est important.
\end{remark}

\begin{normaltext}
    Pour la suite, \( R_O(\alpha)\) est la rotation d'angle \( \alpha\) autour du point \( O\) tandis que \( R(\alpha)\) est la rotation d'angle \( \alpha\) autour de l'origine. En termes matriciels, la rotation d'angle \( \alpha\) est donnée par
    \begin{equation}        \label{EQooQBEJooAHaBbJ}
        R(\alpha)=\begin{pmatrix}
            \cos(\alpha)    &   -\sin(\alpha)    \\ 
            \sin(\alpha)    &   \cos(\alpha)    
        \end{pmatrix},
    \end{equation}
\end{normaltext}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooJLHGooQIpKIE}
    Soit \( A\in \eR^2\) et une droite \( \ell_1\). Soit \( \ell_2\) une droite passant par \( A\) et intersectant \( \ell_1\) en \( O\). Alors
    \begin{equation}
        \sigma_{\ell_1}(A)=R_O(-2\alpha)A
    \end{equation}
    où \( \alpha\) est l'angle de \( \ell_1\) à \( \ell_2\).
\end{lemma}

\begin{proof}
    Nous allons utiliser des coordonnées autour de \( O\). Il existe un vecteur \( v\) tel que
    \begin{equation}
        A=O+v
    \end{equation}
    Par définition de l'angle \( \alpha\), la droite \( \ell_2\) s'obtient par rotation d'angle \( \alpha\) depuis la droite \( \ell_1\). Donc le point
    \begin{equation}
        B=R_O(-\alpha)A
    \end{equation}
    est sur \( \ell_1\).

    Nous allons prouver que le point
    \begin{equation}
        D=R_O(-2\alpha)A
    \end{equation}
    est \( D=\sigma_{\ell_1}A\).

    Nous commençons par montrer que la droite \( (DA)\) est perpendiculaire à \( \ell_1\), c'est à dire que
    \begin{equation}
        (D-A)\cdot (B-O)=0.
    \end{equation}
    En utilisant le fait que 
    \begin{equation}
        R_O(\alpha)(O+X)=O+R(\alpha)X,
    \end{equation}
    nous avons
    \begin{equation}
        D-A=R_O(-2\alpha)(O+v)-(O+v)=O+R(-2\alpha)v-O-v=R(-2\alpha)v-v
    \end{equation}
    et de la même façon,
    \begin{equation}
        B-O=R(-\alpha)v.
    \end{equation}
    Notons que tous les \( O\) se sont simplifiés et qu'il ne reste que des rotation usuelles. En utilisant le fait que \( R(\alpha)\) est une isométrie, nous pouvons alors calculer
    \begin{subequations}
        \begin{align}
            (D-A)\cdot (B-O)&=\langle R(-2\alpha)v-v, R(-\alpha)v\rangle \\
            &=\langle R(-\alpha)v-R(\alpha)v, v\rangle.
        \end{align}
    \end{subequations}
    En utilisant la matrice de rotation \eqref{EQooQBEJooAHaBbJ} nous trouvons
    \begin{equation}
        \big( R(-\alpha)-R(\alpha) \big)v=\begin{pmatrix}
            2\sin(\alpha)v_2    \\ 
            -2\sin(\alpha)v_1    
        \end{pmatrix}
    \end{equation}
    et donc
    \begin{equation}
        \langle  \big( R(-\alpha)-R(\alpha) \big)v  , v\rangle =0.
    \end{equation}

    Le point \( D\) est bien sur la droite perpendiculaire à \( \ell_1\) et passant par \( A\). Mais vu que \( D\) est obtenu à partir de \( A\) par une rotation, le point \( D\) est également sur le cercle de rayon \( \| OA \|\) et centré en \( O\). Ce cercle possède exactement deux intersections avec cette droite. Le premier est \( A\) et le second est \( \sigma_{\ell_1}(A)\). Vu que \( D\) n'est pas \( A\), nous avons \( D=\sigma_{\ell}(A)\).
\end{proof}


\begin{theorem}[\cite{ooZYLAooXwWjLa}]
    Toute isométrie du plan est une composition d'au plus \( 3\) réflexions. 
\end{theorem}

\begin{proof}
    Encore une fois nous décomposons la preuve en fonction du nombre de points fixes.
    \begin{subproof}
        \item[Si \( f\) n'a pas de points fixes]
            Soit \( x\in \eR^2\) et \( l\), la médiatrice du segment \( [x,f(x)]\). Par construction, \( f(x)=\sigma_l(x)\). Nous posons \( g=\sigma_l\circ f\), et nous avons
            \begin{equation}
                g(x)=x.
            \end{equation}
            Donc nous avons \( f=\sigma_l\circ g\) avec \( x\in\Fix(g)\).
        \item[Si \( f\) a un unique point fixe]
            Soit \( x\) cet unique point fixe. Soit \( y\neq x\) et \( l\) la médiatrice de \( [y,f(y)]\). En posant \( g=\sigma_l\circ f\) nous avons 
            \begin{equation}
                g(y)=y
            \end{equation}
            et \( g(x)=x\) parce que
            \begin{equation}
                d\big( x,f(y) \big)=d\big( f(x),f(y) \big)=d(x,y),
            \end{equation}
            ce qui donne que \( x\) est à égale distance de \( y\) et de \( f(y)\), c'est à dire que \( x\in l\) et par conséquent \( g(x)=(\sigma_l\circ f)(x)=\sigma_l(x)=x\). 

            Donc \( g\) fixe \( x\) et \( y\) et donc toute la droit \( (xy)\).
        \item[Si \( f\) fixe une droite]
            Soit \( l\) une droite fixée par \( f\), et soient \( x,y\in l\) et \( z\notin l\) (avec \( x\neq y\)). Le fait que \( x\) et \( y\) soient des points fixes de \( f\) implique
            \begin{subequations}
                \begin{numcases}{}
                    d\big( x,f(z) \big)=d(x,z)\\
                    d\big( y,f(z) \big)=d(y,z)
                \end{numcases}
            \end{subequations}
            ce qui signifie que \( f(z)\) est sur l'intersection des deux cercles\footnote{L'intersection existe pare que \( d(x,z)+d(y,z)>d(x,y)\).} \( S\big( x,d(x,z) \big)\) et \( S\big( y, d(y,z) \big)\), et comme ce sont deux cercles centrés sur la droite \( l\), les intersections sont liées par \( \sigma_l\). Autrement dit, les intersections sont \( z\) et \( \sigma_l(z)\).

            Si \( f(z)=z\) alors \( f\) fixe trois points non alignés et fixe dont \( \eR^2\), c'est à dire \( f=\id\).

            Si par contre \( f(z)=\sigma_l(z)\) alors les isométries \( f\) et \( \sigma_l\) coïncident sur trois points et coïncident donc partout par le corollaire \ref{CORooZHZZooDgTzsW} : \( f=\sigma_l\).
        \item[Conclusion]

            Nous avons montré que si \( \Fix(f)\) a dimension \( m\), alors il existe une droite pour laquelle \( f=\sigma_l\circ g\) avec \( \dim\big( \Fix(g) \big)>m\). Donc il faux au maximum trois pas pour avoir \( \dim\big( \Fix(g) \big)=2\) c'est à dire pour avoir \( g=\id\).
    \end{subproof}
\end{proof}

\begin{definition}
    Une \defe{réflexion glissée}{réflexion!glissée} est une transformation du plan de la forme \( \tau_v\circ\sigma_{\ell}\) où le vecteur \( v\) est parallèle à la droite \( \ell\).
\end{definition}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]      \label{THOooVRNOooAgaVRN}
    Les isométries du plan sont exactement
    \begin{enumerate}
        \item
            l'identité (composée de \( 0\) réflexions),
        \item
            les réflexions,
        \item
            les translations (composées de \( 2\) translations d'axes parallèles),
        \item
            les réflexions glissées (composées de \( 3\) réflexions)
    \end{enumerate}
\end{theorem}

\begin{proof}
    Nous savons déjà que \( f\in \Isom(\eR^2)\) est une composée de \( 0\), \( 1\), \( 2\) ou \( 3\) réflexions. 
    \begin{subproof}
        \item[Zéro réflexions]
            Alors c'est l'identité. Ce n'est pas très profond.
        \item[Une réflexion]
            Alors \( f\) est une réflexion. Toujours pas très profond.
        \item[Deux réflexions]
            Soit \( f=\sigma_{\ell_1}\circ\sigma_{\ell_2}\). Maintenant ça s'approfondit un bon coup.
            
            Nous supposons d'abord que \( \ell_1\parallel\ell_2\). Dans ce cas nous allons prouver que \( f=\tau_{2v}\) où \( v\) est le vecteur perpendiculaire à \(  \ell_1 \) tel que \( \ell_1+v=\ell_2\). Nous allons utiliser le lemme \ref{LEMooVOJLooCFgdNG} pour montrer que \( \sigma_{\ell_1}\circ\sigma_{\ell_2}=\tau_{2v}\). Nous avons
            \begin{subequations}
                \begin{align}
                    \ell_1=\ell_0+w\\
                    \ell_2=\ell_0+w+v
                \end{align}
            \end{subequations}
            où \( w\) est un vecteur perpendiculaire à \( \ell_1\) et \( \ell_0\) est la droite passant par l'origine et parallèle à \( \ell_1\) et \( \ell_2\). Avec cela,
            \begin{subequations}
                \begin{align}
                    (\sigma_{\ell_1}\circ\sigma_{\ell_2})(x)&=\sigma_{\ell_1}\big( \sigma_{\ell_0}(x)+2w \big)\\
                    &=\sigma_{\ell_0}\big( \sigma_{\ell_0}(x)+2w \big)+2(v+w)\\
                    &=x+\underbrace{\sigma_{\ell_0}(2w)}_{-2w}+2v+2w\\
                    &=x+2v.
                \end{align}
            \end{subequations}
            Donc si \( f\) est composée de deux réflexions d'axes parallèles, alors \( f\) est une translation.

            Toujours dans le cas où \( f\) est composée de deux réflexions, nous supposons que \( f=\sigma_{\ell_2}\circ\sigma_{\ell_1}\) avec \( \ell_1\) et \( \ell_2\) non parallèles. Nous notons \( O\) le point d'intersection, et nous allons voir que \( f=R_O(2\alpha)\) où \( \alpha\) est l'angle de \( \ell_1\) à \( \ell_2\) donné par le lemme \ref{DEFooEGKOooRPGOAs}.

            Soit \( x\in \ell_1\). Alors 
            \begin{equation}
                f(x)=\sigma_{\ell_2}(x),
            \end{equation}
            et le lemme \ref{LEMooJLHGooQIpKIE} nous donne un moyen de calculer \( \sigma_{\ell_2}(x)\) parce que \( \ell_1\) est une droite passant par \( x\) et coupant \( \ell_1\) au point \( O\). Le lemme dit que \( \sigma_{\ell_2}(x)=R_O(2\alpha)\). Remarque : c'est bien \( 2\alpha\) et non \( -2\alpha\) parce qu'il s'agit de l'angle de \( \ell_2\) à \( \ell_2\); il y a inversion des numéros entre ici et l'énoncé du lemme.

            Nous avons donc bien \( f(x)=R_O(2\alpha)x\) pour \( x\in \ell_1\).

            Si \( y\in\ell_2\) alors
            \begin{equation}
                f(y)=\sigma_{\ell_2}\big( R_O(-2\alpha)y \big)
            \end{equation}
            Nous posons \( z=\sigma_{\ell_1}(y)=R_O(-2\alpha)y\). Soit la droite \( \ell_3\) passant par \( O\) et \( z\). Vu que \( R_O(2\alpha)z=y\in \ell_2\), l'angle de \( \ell_3\) à \( \ell_2\) est \( 2\alpha\). Par conséquent 
            \begin{equation}
                \sigma_{\ell_2}(z)=R_O\big( -2\times (-2\alpha) \big)z=R_O(4\alpha)z=R_O(4\alpha)R_O(-2\alpha)y=R_O(2\alpha)y.
            \end{equation}
            
            Donc les transformations \( f\) et \( R_O(2\alpha)\) coïncident pour tous les points des droites \( \ell_1\) et \( \ell_2\), qui ne sont pas parallèles. Cela prouve que \( f=R_{O}(2\alpha)\).

        \item[Trois réflexions]
            Nous écrivons \( f=\sigma_{\ell_3}\circ\sigma_{\ell_2}\circ\sigma_{\ell_1}\). Nous allons transformer cela progressivement en une symétrie glissée en passant par plusieurs étapes :
            \begin{enumerate}
                \item       \label{ITEMooHVYCooPhFMiv}
                    \( f=\sigma_{\ell}\circ\tau_v\),
                \item       \label{ITEMooUKGLooFlCcjt}
                    \( f=\tau_v\circ\sigma_{\ell}\),
                \item       \label{ITEMooWUCWooZSjofe}
                    \( f=\tau_v\circ\sigma_{\ell} \) avec \( v\parallel\ell\).
            \end{enumerate}
            À chacune de ces étapes, \( v\) et \( \ell\) vont changer. La dernière est une réflexion glissée.

            Nous commençons par supposer \( \ell_2\parallel\ell_3\). Dans ce cas, \( \sigma_{\ell_3}\circ\sigma_{\ell_2}\) est une translation, comme nous l'avons déjà vu. Alors \( f= \tau_v\circ\sigma_{\ell_1}\) et nous sommes déjà dans le cas \ref{ITEMooUKGLooFlCcjt}.

            Nous supposons que \( \ell_2\) n'est pas parallèle à \( \ell_3\). Dans ce cas, si \( O=\ell_2\cap\ell_3\) nous avons 
            \begin{equation}
                \sigma_{\ell_3}\circ\sigma_{\ell_2}=R_O(2\alpha)
            \end{equation}
            où \( \alpha\) est l'angle de \( \ell_2\) à \( \ell_3\). En réalité tant que l'angle de \( \ell'_3\) à \( \ell'_2\) est \( \alpha\) nous avons
            \begin{equation}
                \sigma_{\ell'_3}\circ\sigma_{\ell'_2}= \sigma_{\ell_3}\circ\sigma_{\ell_2}=R_O(2\alpha).
            \end{equation}
            Nous choisissons \( \ell'_2\) parallèle à \( \ell_1\), de telle sorte à ce que \( \sigma_{\ell'_2}\circ\sigma_{\ell_1}\) soit une translation. Alors nous avons
            \begin{equation}
                f=\sigma_{\ell_3}\circ\sigma_{\ell_2}\circ\sigma_{\ell_1}=\sigma_{\ell_3}\circ\sigma_{\ell'_2}\circ\sigma_{\ell'_1}=\sigma_{\ell_3}\circ\tau_v.
            \end{equation}
            où \( v\) est le vecteur de la translation en question.

            Nous avons donc prouvé que toute composition de trois réflexions peut être écrite soit sous la forme \ref{ITEMooHVYCooPhFMiv} soit sous la forme \ref{ITEMooUKGLooFlCcjt}.

            Nous prouvons à présent que toute transformation de la forme \ref{ITEMooHVYCooPhFMiv} peut être écrite sous la forme \ref{ITEMooUKGLooFlCcjt}. Plus précisément nous allons prouver que si \( \ell\) est une droite, \( v\) un vecteur et \( \ell_0\) la droite parallèle à \( \ell\) passant par l'origine, alors
            \begin{equation}
                \sigma_{\ell}\circ\tau_v=\tau_{\sigma_{\ell_0}(v)}\circ\sigma_l
            \end{equation}
            D'abord nous savons que \( \sigma_{\ell}(x)=\sigma_{\ell_0}(x)+2w\) où \( w\) est le vecteur tel que \( \ell=\ell_0+w\). Ensuite c'est un simple calcul utilisant le fait que \( \sigma_{\ell_0}\) est linéaire :
            \begin{equation}
                (\sigma_{\ell}\circ\tau_v)(x)=\sigma_l(x+v)=\sigma_{\ell_0}(x)+\sigma_{\ell_0}(v)+2w,
            \end{equation}
            et
            \begin{equation}
                (\tau_{\sigma_{\ell_0}(v)}\circ\sigma_{\ell})(x)=\sigma_{\ell_0}(v)+\sigma_{\ell}(x)=\sigma_{\ell_0}(v)+\sigma_{\ell_0}(x)+2w.
            \end{equation}
            L'égalité est faite.

            Nous montrons maintenant que toute transformation de la forme \ref{ITEMooUKGLooFlCcjt} peut être mise sous la forme \ref{ITEMooWUCWooZSjofe}. Soit donc \( f=\tau_v\circ\sigma_{\ell}\) où \( v\) et \( \ell\) ne sont pas spécialement parallèles.

            Pour cela nous décomposons \( v=v_1+v_2\) avec \( v_1\perp \ell\) et \( v_2\parallel\ell\) et nous posons \( \ell'=\ell+\frac{ 1 }{2}v_1\). Nous montrons que
            \begin{itemize}
                \item \( \tau_v\circ\sigma_{\ell}=\tau_{v_2}\circ\sigma_{\ell'}\)
                \item \( v_2\parallel \ell'\).
            \end{itemize}
            Pour le deuxième point, \( v_2\parallel\ell\) et bien entendu \( \ell'\parallel\ell\). Donc \( v_2\parallel\ell'\).

            Soit \( \ell_0\) la droite parallèle à \(  \ell\) et \( \ell'\) et passant par l'origine. Soit aussi le vecteur \( w\) tel que \( \ell=\ell_0+w\). Alors nous avons
            \begin{subequations}
                \begin{numcases}{}
                    \sigma_{\ell}=\sigma_{\ell_0}+2w\\
                    \sigma_{\ell'}=\sigma_{\ell_0}+2w+v_1
                \end{numcases}
            \end{subequations}
            Nous avons
            \begin{equation}
                (\tau_v\circ\sigma_{\ell})(x)=v+\sigma_{\ell_0}(x)+2w
            \end{equation}
            et
            \begin{subequations}
                \begin{align}
                    (\tau_{v_2}\circ\sigma_{\ell'})(x)&=v_2+\sigma_{\ell_0}(x)+2w+v_1\\
                    &=\sigma_{\ell_0}(x)+v+2w
                \end{align}
            \end{subequations}
            où dans la dernière ligne, nous avons regroupé \( v_1+v_2=v\). Et voila.
    \end{subproof}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Isométries dans \( \eR^n\)}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Un \defe{hyperplan}{hyperplan} de \( \eR^n\) est un sous-espace affine de dimension \( n-1\). 
\end{definition}
    
\begin{lemmaDef}
    Si un hyperplan \( H\) de \( \eR^n\) est donné, et si \( x\in \eR^n\), il existe un unique point \( y\in \eR^n\) tel que
    \begin{enumerate}
        \item
            \( x-y\perp H\),
        \item
            Le segment \( [x,y]\) coupe \( H\) en son milieu.
    \end{enumerate}
    La \defe{réflexion}{réflexion!par rapport à un hyperplan} \( \sigma_H\) est l'application $\sigma_H\colon \eR^n\to \eR^n $ qui à \( x\) fait correspondre ce \( y\).
\end{lemmaDef}

\begin{proof}
    Il faut vérifier que les conditions données définissent effectivement un unique point de \( \eR^n\). Soit \( H_0\) le sous-espace vectoriel parallèle à \( H\) et une base orthonormée \( \{ e_1,\ldots, e_{n-1} \}\) de \( H_0\). Nous complétons cela en une base orthonormée de \( \eR^n\) avec un vecteur \( e_n\). Si \( H=H_0+v\), quitte à décomposer \( v\) en une partie parallèle et une partie perpendiculaire à \( H\), nous avons
    \begin{equation}
        H=H_0+\lambda e_n
    \end{equation}
    pour un certain \( \lambda\).

    Une droite passant par \( x\) et perpendiculaire à \( H\) est de la forme \( t\mapsto x+te_n\). Si \( x=\sum_{i=1}^{n}x_ie_i\) alors l'unique point de cette droit à être dans \( H\) est le point tel que \(   x_ne_n+te_n=\lambda e_n   \), c'est à dire \( t=-x_n\). L'unique point \( y\) sur cette droite à être tel que \( [x,y ]\) coupe \( H\) en son milieu est celui qui correspond à \( t=-2x_n\). 
\end{proof}

Notons au passage que cette preuve donne une formule pour \( \sigma_H\) :
\begin{equation}        \label{EQooRTWLooLPsUpY}
    \sigma_H(x)=\sum_{i=1}^{n-1}x_ie_i-x_ne_n.
\end{equation}
Il s'agit donc de changer le signe de la composante perpendiculaire à \( H\).

\begin{lemma}       \label{LEMooWYVRooQmWqvM}
    Dans cette même base si \( H_0\) est l'hyperplan parallèle à \( H\) et passant par l'origine, nous écrivons \( H=H_0+\lambda e_n\) pour un certain \( \lambda\). Alors
    \begin{equation}
        \sigma_H=\sigma_{H_0}+2\lambda e_n.
    \end{equation}
\end{lemma}

\begin{proof}
    Un élément \( x\in \eR^n\) peut être décomposé dans la base adéquate en \( x=x_H+x_ne_n\). Nous savons de la formule \eqref{EQooRTWLooLPsUpY} que 
    \begin{equation}
        \sigma_H(x)=x_H-x_ne_n.
    \end{equation}
    Mais vu que \( \sigma_{H_0}(x_H)=x_H-2\lambda e_n\) nous avons
    \begin{equation}
            \sigma_{H_0}(x)+2\lambda e_n=\sigma_{H_0}(x_H+x_ne_n)+2\lambda e_N=x_H-2\lambda e_n-x_ne_n+2\lambda e_n=x_H-x_ne_n.
    \end{equation}
\end{proof}

Le lemme suivant est une généralisation du fait que tous les points de la médiatrice d'un segment sont à égale distance des deux extrémités du segment (très utile lorsqu'on étudie les triangles isocèles).
\begin{lemma}[\cite{ooZYLAooXwWjLa}]        \label{LEMooDPLYooJKZxiM}
    Soient deux points distincts \( x_0,y_0\in \eR^n\) l'ensemble \( H\subset \eR^n\) donné par
    \begin{equation}
        H=\{ x\in \eR^n\tq d(x,x_0)=d(x,y_0) \}.
    \end{equation}
    Alors \( H\) est l'hyperplan orthogonal au vecteur \( v=y_0-x_0\) et \( H\) passe par le milieu du segment \( [x_0,y_0] \).
\end{lemma}

\begin{proof}
    Nous savons que
    \begin{equation}
        d(x,x_0)^2=\langle x-x_0, x-x_0\rangle =\| x \|^2+\| x_0 \|^2-2\langle x, x_0\rangle,
    \end{equation}
    ou encore
    \begin{equation}
        \| x_0 \|^2-\| y_0 \|^2=2\langle x, x_0-y_0\rangle .
    \end{equation}
    En posant \( v=y_0-x_0\) et en considérant la forme linéaire
    \begin{equation}
        \begin{aligned}
            \beta\colon \eR^n&\to \eR \\
            x&\mapsto \langle x, v\rangle , 
        \end{aligned}
    \end{equation}
    Nous avons \( x\in H\) si et seulement si \( \beta(x)=\frac{ 1 }{2}\big( \| y_0 \|^2-\| x_0 \|^2 \big)=\lambda\). En d'autres termes, \( H=\beta^{-1}(\lambda)\). Par la proposition \ref{PROPooAKJBooMkmsiV} la partie \( H\) est un sous-espace affine. C'est même un translaté de \( \ker(\beta)\), et comme \( \ker(\beta)\) est l'espace vectoriel des vecteurs perpendiculaires à \( v\), nous avons \( \dim(H)=\dim\big( \ker(\beta) \big)=n-1\).

    Le fait que \( H\) contienne le milieu du segment \( [x_0,y_0]\) est par définition.
\end{proof}

Pour le lemme suivant, et pour que la récurrence se passe bien nous disons que l'ensemble vide est un espace vectoriel de dimension \( -1\).
\begin{lemma}       \label{LEMooJCDRooGAmlwp}
    Si \( f\in\Isom(\eR^n)\) satisfait 
    \begin{equation}
        \dim\big( \Fix(f) \big)=n-k
    \end{equation}
    alors \( f\) peut être écrit comme composition d'au plus \( k\) réflexions hyperplanes.
\end{lemma}

\begin{proof}
    Nous faisons une récurrence sur \( k\geq 0\). 
    
    Pour l'initialisation, si \( k=0\) alors \( \dim\big( \Fix(f) \big)=n\), c'est à dire que \( f\) fixe tout \( \eR^n\), autant dire que \( f\) est l'identité, une composition de zéro réflexions.

    Pour la récurrence, nous supposons que le lemme est démontré jusqu'à \( k\geq 0\). Soit donc \( f\in\Isom(\eR^n)\) tel que 
    \begin{equation}
        \dim\big( \Fix(f) \big)=n-(k+1).
    \end{equation}
    Vu que \( k\geq 0\), la dimension de \( \Fix(f)\) est strictement plus petite que \( n\), donc il existe un \( x_0\in \eR^n\) tel que \( f(x_0)\neq x_0\). Nous posons
    \begin{equation}
        H=\{ x\in \eR^n\tq d(x,x_0)=d\big( x,f(x_0) \big)  \}.
    \end{equation}
    Par le lemme \ref{LEMooDPLYooJKZxiM}, ce \( H\) est l'hyperplan orthogonal à \( v=f(x_0)-x_0\) et passant par le milieu du segment \( [x_0,f(x_0)]\).

    Nous posons \( g=\sigma_H\circ f\). Vu que \( g(x_0)=\sigma_H(f(x_0))=x_0\), ce \( x_0\) est un point fixe de \( g\). Le fait que \( \sigma_H\big( f(x_0) \big)=x_0\) est vraiment la définition de l'hyperplan \( H\).

    Nous avons donc
    \begin{equation}
        x_0\in\Fix(g)\setminus\Fix(f).
    \end{equation}
    Mais nous prouvons de plus que \( \Fix(f)\subset\Fix(g)\). En effet si \( y\in Fix(f)\) alors \( y\in H\) parce que 
    \begin{equation}
        d(y,x_0)=d\big( f(y),f(x_0) \big)=d\big( y, f(x_0) \big).
    \end{equation}
    Vu que \( y\in H\) nous avons \( y\in \Fix(g)\) parce que 
    \begin{equation}
        g(y)=\sigma_H\big( f(y) \big)=\sigma_H(y)=y.
    \end{equation}
    Tout cela pour dire que l'ensemble \( \Fix(g)\) est \emph{strictement} plus grand que \( \Fix(f)\). Et comme ce sont des espaces affines nous pouvons parler de dimension :
    \begin{equation}
        \dim\big( \Fix(g) \big)>\dim\big( \Fix(f) \big).
    \end{equation}
    Par hypothèse de récurrence, l'application \(  g\) peut être écrite comme composition de \( k\) réflexions. Donc l'application
    \begin{equation}
        f=\sigma_H\circ g
    \end{equation}
    est une composition de \( k+1\) réflexions.
\end{proof}

\begin{lemma}       \label{LEMooMCVKooKzmlAg}
    Soit un hyperplan \( H\) et un vecteur \( v\) de \( \eR^n\). Nous avons
    \begin{equation}
        \tau_v\circ \sigma_H\circ\tau_v^{-1}=\sigma_{\tau_v(H)}.
    \end{equation}
\end{lemma}

\begin{proof}
    Pour ce faire nous considérons une base adaptée. Les vecteurs \( \{ e_1,\ldots, e_{n-1} \}\) forment une base orthonormée de \( H_0\) et \( e_n\) complète en une base orthonormée de \( \eR^n\). Soit \( H_0\) l'hyperplan parallèle à \( H\) et passant par l'origine; nous avons, pour un certain \( \lambda\in \eR\),
    \begin{equation}
        H=H_0+\lambda e_n
    \end{equation}
    D'un autre côté, le vecteur \( v\) peut être décomposé en \( v=v_1+v_2\) où \( v_1\perp H\) et \( v_2\parallel H\). Alors 
    \begin{equation}
        \tau_v(H)=H+v=H+v_2=H_0+\lambda e_n+v_2.
    \end{equation}
    Nous pouvons maintenant utiliser le lemme \ref{LEMooWYVRooQmWqvM} pour exprimer la transformation \( \sigma_{\tau_v(H)}\) :
    \begin{equation}        \label{EQooNYKFooXprXav}
        \sigma_{\tau_v(H)}(x)=\sigma_{H_0}(x)+ 2\lambda e_n+2v_2
    \end{equation}
    
    Mais d'autre part, 
    \begin{equation}
        (\tau_v\circ \sigma_H\circ\tau_{v}^{-1})(x)=v+\sigma_H(x-v)=v+\sigma_{H_0}(x-v)+2\lambda e_n.
    \end{equation}
    Vue la décomposition de \( v=v_1+v_2\) nous avons \( \sigma_{H_0}(v)=-v_1+v_2\) et donc
    \begin{equation}        \label{EQooGOHEooALPRFB}
        (\tau_v\circ \sigma_H\circ\tau_{v}^{-1})(x)= v+  \sigma_{H_0}(x)+v_1-v_2+2\lambda e_n=\sigma_{H_0}+2v_1+2\lambda e_n.
    \end{equation}
    Les expressions \eqref{EQooNYKFooXprXav} et \eqref{EQooGOHEooALPRFB} coïncident, d'où l'égalité recherchée.
\end{proof}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]
    Toute isométrie de \( \eR^n\) peut être écrite comme composition d'au plus \( n+1\) réflexions.
    
    Une isométrie de \( \eR^n\) préserve l'orientation si et seulement si est elle composition d'un nombre pair de réflexions.
\end{theorem}

\begin{proof}
    La première partie de ce théorème n'est rien d'autre que le lemme \ref{LEMooJCDRooGAmlwp} parce que le pire cas est celui où le fixateur de \( f\) est réduit à l'ensemble vide, et dans ce cas l'application \( f\) est une composition de \( n+1\) réflexions.

    Pour la seconde partie nous définissons
    \begin{equation}
        \begin{aligned}
            \epsilon\colon \Isom(\eR^n)&\to \{ \pm 1 \} \\
            \tau_v\circ \alpha&\mapsto \det(\alpha)
        \end{aligned}
    \end{equation}
    où nous nous référons à la décomposition unique d'un élément de \( \Isom(\eR^n)\) sous la forme \( \tau_v\circ \alpha\) avec \( \alpha\in O(n)\) donnée par le théorème \ref{THOooQJSRooMrqQct}\ref{ITEMooEWSIooNKzRxB}.

    Le noyau de \( \epsilon\) est alors la partie 
    \begin{equation}
        \ker(\epsilon)=\eR^n\times_{\AD}\SO(n).
    \end{equation}
    Une isométrie \( f\) préserve l'orientation si et seulement si \( \epsilon(f)=1\). Vu que toutes les isométries sont des composition de réflexions (première partie), il nous suffit de montrer que \( \epsilon(\epsilon_H)=-1\) pour qu'une isométrie préserve l'orientation si et seulement si elle est composition d'un nombre pair de réflexions.

    Nous commençons par prouver que pour tout vecteur \( v\), \( \epsilon\big( \sigma_H \big)=\epsilon\big( \sigma_{\tau_v(H)} \big)\). Pour cela nous utilisons le lemme \ref{LEMooMCVKooKzmlAg} et le fait que \( \epsilon\) est un homomorphisme :
    \begin{equation}
        \epsilon(\sigma_{\tau_v(H)})=\epsilon(\tau_v)\epsilon(\sigma_H)\epsilon(\tau_v^{-1})=\epsilon(\sigma_H)
    \end{equation}
    parce que la partie linéaire d'une translation est l'identité (et donc \( \epsilon(\tau_v)=1\) pour tout \( v\)).

    Nous avons donc \( \epsilon(\sigma_H)=\epsilon(\sigma_{H_0})\). En ce qui concerne \( \sigma_{H_0}\), dans la base adaptée la matrice est
    \begin{equation}
        \sigma_{H_0}=\begin{pmatrix}
             1   &       &       &       \\
                &   \ddots    &       &       \\
                &       &   1    &       \\ 
                &       &       &   -1     
         \end{pmatrix},
    \end{equation}
    dont le déterminant est \( -1\).
\end{proof}

Pour en savoir plus sur le groupe des isométries, il faut lire le théorème de Cartan-Dieudonné dans \cite{JGAdTA}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Groupes finis d'isomorphismes}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Si \( X\) est une partie finie de \( \eR^n\), le \defe{barycentre}{barycentre!cas vectoriel} de \( X\) est le point
    \begin{equation}
        B_X=\frac{1}{ | X | }\sum_{x\in X}x
    \end{equation}
    où \( | X |\) est le cardinal de \( X\).
\end{definition}
Cela est à mettre en relation avec la définition dans le cadre affine \ref{LemtEwnSH}.

\begin{lemma}[\cite{ooZYLAooXwWjLa}]
    Soit une partie finie \( X\) de \( \eR^n\) et une application affine \( f\in\Aff(\eR^n)\). Alors
    \begin{equation}
        f(B_X)=B_{f(X)}.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous savons que toute application affine est une composée de translation et d'une application linéaire : \( f=\tau_v\circ g\) avec \( v\in \eR^n\) et \( g\in \GL(n,\eR)\). Nous vérifions le résultat séparément pour \( \tau_v\) et pour \( g\).

    D'une part,
    \begin{equation}
        B_{\tau_v(X)}=\frac{1}{ | \tau_v(X) | }\sum_{y\in \tau_v(X)}y=\frac{1}{ | X | }\sum_{x\in X}(x+v)=B_x+\frac{1}{ | X | }\sum_{x\in X}v=B_x+v=\tau_v(B_X).
    \end{equation}
    Nous avons utilisé le fait que \( X\) et \( \tau_v(X)\) possèdent le même nombre d'éléments, ainsi que le fait d'avoir une somme de \( | X |\) termes tous égaux à \( v\).

    D'autre part,
    \begin{equation}
        B_{g(X)}=\frac{1}{ | X | }\sum_{x\in X}g(x)=g\big( \frac{1}{ |X | }\sum_{x\in X}x \big)=g(B_X)
    \end{equation}
    où nous avons utilisé la linéarité de \( g\) dans tous ses retranchements.
\end{proof}

\begin{proposition}     \label{PROPooLAEBooWdcBoe}
    Points fixes d'un sous-groupe.
    \begin{enumerate}
        \item
            Soit \( H\) un sous-groupe finie de \( \Isom(\eR^n)\). Alors il existe \( v\in \eR^n\) tel que \( f(v)=v\) pour tout \( f\in H\).
        \item
            Si \( H\) est un sous-groupe de \( \Isom(\eR^n)\) n'acceptant pas de points fixes, alors il est infini.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Le groupe \( H\) agit sur \( \eR^n\), et si \( x\in \eR^n\) nous pouvons considérer son orbite \( Hx\), qui est une partie finie de \( \eR^n\). Considérons son barycentre
    \begin{equation}
        v=B_{Hx}
    \end{equation}
    Soit \( f\in H\). Alors \( f(v)=f(B_{Hx})=B_{f(Hx)}=B_{Hx}=v\), donc \( v\) est fixé par \( H\).

    La seconde affirmation n'est rien d'autre que la contraposée de la première.
\end{proof}

\begin{proposition}     \label{PROPooEUFIooDUIYzi}
    À propos de groupes finis d'isométries.
    \begin{enumerate}
        \item
            Tout sous groupe finie de \( \Isom(\eR^n)\) est isomorphe à un sous-groupe fini de \( \gO(n)\).
        \item
            Tout sous-groupe fini de \( \Isom^+(\eR^n)\) est isomorphe à un sous-groupe fini de \( \SO(n)\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Soit \( H\) un sous-groupe fini de \( \Isom(\eR^n)\) et \( v\in \eR^n\) un élément fixé par \( H\) (comme garantit par la proposition \ref{PROPooLAEBooWdcBoe}). Nous posons
    \begin{equation}
        \begin{aligned}
            \phi\colon H&\to \Isom(\eR^n) \\
            f&\mapsto \tau_v^{-1}\circ f\circ \tau_v. 
        \end{aligned}
    \end{equation}

    \begin{subproof}
        \item[\( \phi\) est un homomorphisme]
            Les opération du type \( \phi=\AD(\tau_v)\) sont toujours des homomorphismes.
        \item[\( \phi\) consiste à extraire la partie linéaire]
            Si \( f=\tau_w\circ g\) alors
            \begin{subequations}
                \begin{align}
                    \phi(f)(x)&=(\tau_{-v}\circ\tau_w\circ g\circ\tau_v)(x)\\
                    &=\tau_{w-v}(   g(x)+g(v)  )\\
                    &=g(x)+g(v)-v+w
                \end{align}
            \end{subequations}
            Mais \( g(v)+w=f(v)\) et nous savons que \( f(v)=v\). Donc il ne reste que \( \phi(f)(x)=g(x)\).
        \item[\( \phi\) est injective]
            Si \( f=\tau_w\circ g\) vérifie \( \phi(f)=\id\), il faut en particulier que \( g=\id\). Mais \( H\) est fini et ne peut donc pas contenir de translations non triviales. Donc \( w=0\) et \( f=\id\).
    \end{subproof}
    Donc \( \phi\) est une injection à valeur dans les transformation linéaires de \( \Isom(\eR^n)\). Autrement dit, \( \phi\) est un isomorphisme entre \( H\) et son image, laquelle image est dans \( \gO(n)\).

    En ce qui concerne la seconde partie, si \( f\in\Isom^+(\eR^n)\), alors \( \phi(f)\) y est aussi, tout en étant linéaire. Donc \( \phi(f)\in \SO(n)\).
\end{proof}

L'extraction de la partie linéaire est injective ? Certe c'est prouvé, mais on peut se demander ce qu'il se passe si \( H\) contient deux éléments qui ont la même partie linéaire. Cela n'est pas possible parce si \( f_1=\tau_{w_1}\circ g\) et \( f_2=\tau_{w_2}\circ g\) sont dans \( H\) alors \( f_1f_2^{-1}=\tau_{w_1+w_2}\) est également dans \( H\), ce qui n'est pas possible si \( H\) est fini.

\begin{definition}[Groupe de symétrie d'une partie de \( \eR^n\)\cite{ooZYLAooXwWjLa}]
    Si \( Y\) est une partie de \( \eR^n\), nous définissons le \defe{groupe des symétries}{groupe!des symétries} de \( Y\) par
    \begin{equation}
        \Sym(Y)=\{ f\in\Isom(\eR^n)\tq f(Y)=Y \}.
    \end{equation}
    Nous définissons aussi le groupe des symétries propres de \( Y\) par
    \begin{equation}
        \Sym^+(Y)=\{ f\in\Isom^+(\eR^n)\tq f(Y)=Y \}.
    \end{equation}
\end{definition}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]
    Soit \( Y\subset \eR^2\) tel que le groupe \( \Sym^+(Y)\) soit fini d'ordre \( n\). Alors c'est un groupe cyclique d'ordre \( n\).

    Si \( \Sym^+(Y)\) est fini, alors \( \Sym(Y)\) est soit cyclique d'ordre \( n\) soit isomorphe au groupe diédral d'ordre \( 2n\).
\end{theorem}

\begin{proof}
    Nous savons déjà par la proposition \ref{PROPooEUFIooDUIYzi} que \( \Sym^+(Y)\) est isomorphe à un sous-groupe \( H^+\) d'ordre \( n\) de \( \SO(2)\). Vérifions que ce groupe est cyclique. Si \( n=1\), c'est évident. Si \( n\geq 2\) alors nous savons que \( H^+\) est constitué de rotations d'angles dans \( \mathopen[ 0 , 2\pi \mathclose[\) et vu que c'est un ensemble fini, il possède une rotation d'angle minimal (à part zéro). Notons \( \alpha_0\) cet angle.

        Nous montrons que \( H^+\) est engendré par la rotation d'angle \( \alpha_0\). Soit une rotation d'angle \( \alpha\). Étant donné que \( \alpha_0<\alpha\) nous pouvons effectuer la division euclidienne\footnote{Théorème \ref{ThoDivisEuclide}.} de \( \alpha\) par \( \alpha_0\) et obtenir
        \begin{equation}
            \alpha=k\alpha_0+\beta
        \end{equation}
        avec \( \beta<\alpha_0\). Mézalors \( R(\beta)=R(\alpha)R(\alpha_0)^{-k}\) est également un élément du groupe. Cela contredit la minimalité dès que \( \beta\neq 0\). Avoir \( \beta=0\) revient à dire que \( \alpha\) est un multiple de \( \alpha_0\), ce qui signifie que le groupe \( H^+\) est cyclique engendré par \( \alpha_0\). 

        Notons au passage que nous avons automatiquement \( \alpha_0=\frac{ 2\pi }{ n }\) parce qu'il faut \( R(\alpha_0)^n=\id\). Nous avons prouvé que \( \Sym^+(Y) \) est cyclique d'ordre \( n\).

        Nous étudions maintenant le groupe \( \Sym(Y)\). Par la proposition \ref{PROPooEUFIooDUIYzi} nous avons un homomorphisme injectif
        \begin{equation}
            \phi\colon \Sym(Y)\to \gO(2),
        \end{equation}
        et en posant \( H=\phi\big( \Sym(Y) \big)\) nous avons un isomorphisme de groupes \( \phi\colon \Sym(Y)\to H\). Nous savons aussi que ce \( \phi\) se restreint en
        \begin{equation}
            \phi\colon   \Sym^+(Y) \to H^+\subset\SO(2)
        \end{equation}
        où \( H^+=\phi\big( \Sym^+(Y) \big)=H\cap\SO(2)\). Le groupe \( H^+\) est cyclique et est engendré par la rotation \( R(2\pi/n)\).

        Supposons un instant que \( H\subset \SO(2)\). Alors nous avons \( H=H^+\) et \( \phi\) est un isomorphisme entre \( \Sym(Y)\) et le groupe cyclique engendré par \( R(2\pi/n)\).

        Nous supposons à présente que \( H\) n'est pas un sous-ensemble de \( \SO(2)\). Quelles sont les isométries de \( \eR^2\) qui ne sont pas de déterminant \( 1\) ? Il faut regarder dans le théorème \ref{THOooVRNOooAgaVRN} quelles sont les isométries contenant un nombre impair de réflexions. Ce sont les réflexions et les réflexions glissées. Or il ne peut pas y avoir de réflexions glissées dans un groupe fini parce que si \( f\) est une réflexion glissée, tous les \( f^k\) sont différents.

        Nous en déduisons que si \( H\) n'est pas inclus à \( \SO(2)\), il contient une réflexion que nous nommons \( \sigma\). Nous allons en déduire que \( H\simeq H^+\times_{\AD}C_2\) où \( C_2=\{ \id,\sigma \}\). Si \( h\in H\) nous pouvons écrire 
        \begin{equation}
            h=(h\sigma^{\epsilon})\sigma^{\epsilon}
        \end{equation}
        pour n'importe quelle valeur de \( \epsilon\), et en particulier pour \( \epsilon=\pm 1\). 

        Si \( h\in \SO(2)\) alors nous écrivons \( h=h\epsilon^{0}\) et si \( h\notin\SO(2)\) nous écrivons \( h=(h\sigma)\sigma\). Vu que \( h\sigma\in\SO(2)\), cette dernière écriture est encore de la forme \( \SO(2)\times C_2\). Quoi qu'il en soit tout élément de \( H\) s'écrit comme un produit 
        \begin{equation}
            H=H^+C_2.
        \end{equation}
        Cette décomposition est unique parce que si \( h_1c_1=h_2c_2\) alors \( h_2^{-1}h_1=c_2c_1^{-1}\), et comme \( h_2^{-1}h_1\in H^+\) nous avons \( c_2c_1^{-1}\in H^+\) et donc \( c_1=c_2\). Partant nous avons aussi \( h_1=h_2\). Pour avoir le produit semi-direct il faut encore montrer que \( \AD(C_2)H^+\subset H^+\). Le seul cas à vérifier est \( \AD(\sigma)H^+\subset H^+\). Vu que les éléments de \( H^+\) sont caractérisés par le fait d'avoir un déterminant positif, nous avons 
        \begin{equation}
            \AD(\sigma)R(\alpha)=\sigma R(\alpha)\sigma^{-1}\in H^+.
        \end{equation}
\end{proof}

\begin{remark}
    Tout ceci est cohérent avec le théorème de Burnside \ref{ThooJLTit} parce que le sous-groupe fini de \( \SO(n)\) engendré par la rotation \( R(2\pi/n)\) est un groupe d'exposant fini, à savoir que si \( h\) est dans ce groupe, \( h^n=\id\).
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Sylvester}
%---------------------------------------------------------------------------------------------------------------------------

% TODO : Il y a une démonstration sur wikipédia, à voir.

\begin{theorem}[de Sylvester]   \label{ThoQFVsBCk}
    Soit $Q$ une forme quadratique réelle de signature \( (p,q)\). Alors pour toute base orthonormée on a
    \begin{subequations}
        \begin{align}
            p&=\Card\{ i\tq Q(e_i)>0 \}\\
            q&=\Card\{ i\tq Q(e_i)<0 \}.
        \end{align}
    \end{subequations}
    Le rang de \( Q\) est \( p+q\).

    Si \( A\) est la matrice de \( Q\) dans une base, alors il existe une matrice inversible \( P\) telle que
    \begin{equation}
        P^tAP=\begin{pmatrix}
            -\mtu_q    &       &       \\
                &   \mtu_p    &       \\
                &       &   0
        \end{pmatrix}.
    \end{equation}
\end{theorem}
\index{théorème!Sylvester}
\index{rang}
\index{matrice!semblables}
\index{forme!quadratique}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Groupe diédral}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecHibJId}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Définition et générateurs : vue géométrique}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{definition}  \label{DEFooIWZGooAinSOh}
    Le \defe{groupe diédral}{groupe!diédral} \( D_n\)\nomenclature[R]{\( D_n\)}{groupe diédral} est le groupe des isométries de \( \eR^2\) laissant invariant un polygone régulier à \( n\) côtés. 
\end{definition}
Le groupe diédral peut être vu comme le stabilisateur de l'ensemble
\begin{equation}
    \{  e^{2ik\pi/n},k=0,\ldots, n-1 \}
\end{equation}
dans le groupe des isométries affines de \( \eC^*\).
\index{groupe!agissant sur un ensemble!diédral}
\index{groupe!en géométrie}
\index{groupe!fini!diédral}
\index{groupe!permutation!diédral}
% TODO : prouver que les racines de l'unité forment un polygone régulier.

Si \( f\in D_n\), alors \( f( e^{2ik\pi/n}) \) doit être l'un des \(  e^{2ik'\pi/n}\), et vu que \( f\) conserve les longueurs dans \( \eC\), nous devons avoir
\begin{equation}
    1=d(0, e^{2ik\pi/n})=d\big( f(0), e^{2ik'\pi/n} \big).
\end{equation}
Donc \( f(0)\) est à l'intersection de tous les cercles de rayon \( 1\) centrés en les \(  e^{2ik\pi/n}\), ce qui montre que \( f(0))0\) (dès que \( n\geq 3\)). Par conséquent notre étude du groupe diédral ne doit prendre en compte que les isométries vectorielles de \( \eR^2\). En d'autres termes
\begin{equation}
    D_n\subset O(2,\eR).
\end{equation}

\begin{proposition}[\cite{tzHydF}]
    Le groupe \( D_n\) contient un sous groupe cyclique d'ordre \( 2\) et un sous groupe cyclique d'ordre \( n\).
\end{proposition}

\begin{proof}
    Si \( s\) est la réflexion d'axe \( \eR\), alors \( s\) est d'ordre \( 2\). De plus \( s\) est bien dans \( D_n\) parce que
    \begin{equation}    \label{EqSUshknP}
        s\big(  e^{2ki\pi/n} \big)= e^{2(n-k)i\pi/n}.
    \end{equation}

    De la même façon, la rotations d'angle \(2\pi/n\), que l'on note \( r\), agit sur les racines de l'unité et engendre un le groupe d'ordre \( n\) des rotations d'angle \(2 k\pi/n\).
\end{proof}

Notons que la conjugaison complexe ne fait pas spécialement partie du groupe \( D_n\). En effet pour \( n=3\) par exemple les points fixes sont \( A_1=(1,0)\), \( A_2=(-\frac{ 1 }{2},\frac{ \sqrt{3} }{2})\) et \( A_3=(\frac{ 1 }{2},-\frac{ \sqrt{3} }{2})\). La conjugaison complexe envoie évidemment \( A_1\) sur \( A_1\), mais pas du tout \( A_2\) sur \( A_3\).
%TODO : un dessin du triangle équilatéral serait pas mal ici.

\begin{proposition}[\cite{tzHydF}]
    Nous avons \( (sr)^2=\id\).
\end{proposition}

\begin{proof}
    Si \( z^n=1\), alors
    \begin{equation}
        (srsr)z=srs e^{2 i\pi/n}z=sr\big( e^{-2\pi i/n\bar z}\big)=s\bar z=z.
    \end{equation}
\end{proof}

\begin{proposition}[\cite{tzHydF}] \label{PropLDIPoZ}
    Le groupe diédral \( D_n\) est engendré par \( s\) et \( r\). De plus tous les éléments de \( D_n\) s'écrivent sous la forme \( s\circ r^m\).
\end{proposition}
\index{groupe!diédral!générateurs (preuve)}
\index{racine!de l'unité}
\index{géométrie!avec nombres complexes}
\index{géométrie!avec des groupes}
\index{isométrie!de l'espace euclidien \( \eR^2\)}

\begin{proof}
    Nous considérons les points \( A_0=1\) et \( A_k= e^{2ki\pi/n}\) avec \( k\in\{ 1,\ldots, n-1 \}\). Par convention, \( A_n=A_0\). L'action des éléments \( s\) et \( r\) sur ces points est
    \begin{subequations}
        \begin{align}
            r(A_k)&=A_{k+1}\\
            s(A_k)&=A_{n-k}.
        \end{align}
    \end{subequations}
    Cette dernière est l'équation \eqref{EqSUshknP}.
    
    Soit \( f\in D_n\). Étant donné que c'est une isométrie de \( \eR^2\) avec un point fixe (le point \( 0\)), \( f\) est soit une rotation soit une réflexion.
    %TODO : il faut démontrer ce point et mettre un lien vers ici.

    Supposons pour commencer que un des \( A_k\) est fixé par \( f\). Dans ce cas \( f\) a deux points fixes : \( O\) et \( A_k\) et est donc la réflexion d'axe \( (OA_k)\). Dans ce cas, nous avons \( f=s\circ r^{n-2k}\). En effet
    \begin{equation}
        s\circ r^{n-2k}(A_k)=s(A_{k+n-2k})=s(A_{n-k})=A_k.
    \end{equation}
    Donc \( O\) et \( A_k\) sont deux points fixes de l'isométrie \( f\); donc \( f\) est bien la réflexion sur le bon axe.

    Nous passons à présent au cas où \( f\) ne fixe aucun des \( A_k\). 
    \begin{enumerate}
        \item
            Supposons que \( f\) soit une rotation. Si \( f(A_k)=A_m\), alors l'angle de la rotation est 
            \begin{equation}
                \frac{ 2(m-k)\pi }{ n },
            \end{equation}
            et donc \( f=r^{m-k}\), qui est de la forme demandée.
        \item
            Supposons à présent que \( f\) soit une réflexion d'axe \( \Delta\). Cette fois, \( \Delta\) ne passe par aucun des points \( A_k\), par contre \( \Delta\) passe par \( 0\). Nous commençons par montrer que \( \Delta\) doit être la médiatrice d'un des côtés \( [A_p,A_{p+1}]\) du polygone. Vu que \( \Delta\) passe par \( O\) et n'est aucune des droites \( (OA_k)\), cette droite passe par l'intérieur d'un des triangles \( OA_pA_{p+1}\) et intersecte donc le côté correspondant.

            Notre tâche est de montrer que \( \Delta\) coupe \( [A_p,A_{p+1}]\) en son milieu. Dans ce cas, \( \Delta\) sera automatiquement perpendiculaire parce que le triangle \( OA_pA_{p+1}\) est isocèle en \( O\). Nommons \( l\) la longueur des côtés du polygone, \( P=\Delta\cap[A_p,A_{p+1}]\), \( x=d(A_p,P)\) et \( \delta=d(A_p,\Delta)\). Vu que \( f\) est la symétrie d'axe \( \Delta\), nous avons aussi \( d\big( f(A_p),\Delta \big)=\delta\) et \( d\big( A_p,f(A_p) \big)=2\delta\). D'autre part, par la définition de la distance, \( \delta<x\). Si \( x<\frac{ l }{2}\), alors \( \delta<\frac{ \delta }{2}\) et donc \( d\big( A_p,f(A_p) \big)<l\). Or cela est impossible parce que le polygone ne possède aucun sommet à distance plus courte que \( l\) de \( A_p\).

            De la même manière si \( x>\frac{ l }{2}\), nous raisonnons avec \( A_{p+1}\) pour obtenir une contradiction. Nous en concluons que la seule possibilité est \( x=\frac{ l }{2}\), et donc \( f(A_p)=A_{p+1}\). Montrons alors que \( f=s\circ r^{n-2p-1}\). Il faut montrer que c'est une réflexion qui envoie \( A_p\) sur \( A_{p+1}\). D'abord c'est une réflexion parce que
            \begin{equation}
                \det(sr^{n-2p-1})=\det(s)\det(r^{n-2p-1})=-1
            \end{equation}
            parce que \( \det(s)=-1\) alors que \( \det(r^k)=1\) parce que \( r\) est une rotation dans \( \SO(2)\). Ensuite nous avons
            \begin{equation}
                s\circ r^{n-2p-1}(A_p)=s(A_{p+n-2p-1})=s(A_{n-p-1})=A_{n-(n-p-1)}=A_{p+1}.
            \end{equation}

            Donc \( s\circ r^{n-2p-1}\) est bien une réflexion qui envoie \( A_p\) sur \( A_{p+1}\).

    \end{enumerate}
\end{proof}

\begin{corollary}   \label{CorWYITsWW}
La liste des éléments de \( D_n\) est 
\begin{equation}
    D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
\end{equation}
et \( | D_n |=2n\).
\end{corollary}

\begin{proof}
    Nous savons par la proposition \ref{PropLDIPoZ} que tous les élément de \( D_n\) s'écrivent sous la forme \( r^k\) ou \( sr^k\). Vu que \( r\) est d'ordre \( n\), il ne faut considérer que \( k\in\{ 1,\ldots, n-1 \}\). Les éléments \( 1\), \( r\),\ldots, \( r^{n-1}\) sont tous différents, et sont (pour des raisons de déterminant) tous différents des \( sr^k\). Les isométries \( sr^k\) sont toutes différentes entre elles pour essentiellement la même raison :
    \begin{equation}
        sr^k(A_p)=s(A_{p+k})=A_{n-p+k}
    \end{equation}
    donc si \( k\neq k'\), \( sr^k(A_p)\neq sr^{k'}(A_p)\). La liste des éléments de \( D_n\) est donc
    \begin{equation}
        D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
    \end{equation}
    et donc \( | D_n |=2n\).
\end{proof}

\begin{example}     \label{EXooHNYYooUDsKnm}
    Nous considérons le carré \( ABCD\) dans \( \eR^2\) et nous cherchons les isométries de \( \eR^2\) qui laissent le carré invariant. Nous nommons les points comme sur la figure \ref{LabelFigIsomCarre}. La symétrie d'axe vertical est nommée \( s\) et la rotation de \( 90\) degrés est notée \( r\).
    \newcommand{\CaptionFigIsomCarre}{Le carré dont nous étudions le groupe diédral.}
    \input{Fig_IsomCarre.pstricks}

    Il est facile de vérifier que toutes les symétries axiales peuvent être écrites sous la forme \( r^is\). De plus le groupe engendré par \( s\) agit sur le groupe engendré par \( r\) parce que
    \begin{equation}
        (srs^{-1})(A,B,C,D)=sr(B,A,D,C)=s(A,D,C,B)=(B,C,D,A),
    \end{equation}
    c'est à dire \( srs^{-1}=r^{-1}\). Nous sommes alors dans le cadre du corollaire \ref{CoroGohOZ} et nous pouvons écrire que
    \begin{equation}
        D_4=\gr(r)\times_{\sigma}\gr(s).
    \end{equation}
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Générateurs : vue abstraite}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous allons montrer que \( D_n\) peut être décrit de façon abstraite en ne parlant que de ses générateurs. Nous considérons un groupe \( G\) engendré par des éléments \( a\) et \( b\) tels que
\begin{enumerate}
    \item
        \( a\) est d'ordre \( 2\),
    \item
        \( b\) est d'ordre \( n\) avec \( n\geq 3\),
    \item
        \( abab=e\).
\end{enumerate}
Nous allons prouver que ce groupe doit avoir la même liste d'éléments que celle du corollaire \ref{CorWYITsWW}.

\begin{proposition}[\cite{tzHydF}]
    Le groupe \( G\) n'est pas abélien.
\end{proposition}

\begin{proof}
    Nous savons que \( abab=e\), donc \( abab^{-1}=b^{-2}\), mais \( b^{-2}\neq e\) parce que \( b\) est d'ordre \( n>2\). Donc \( abab^{-1}\neq e\). En manipulant un peu :
    \begin{equation}
        e\neq abab^{-1}=(ab)(ba^{-1})^{-1}=(ab)(ba)^{-1}
    \end{equation}
    parce que \( a^{-1}=a\). Donc \( ab\neq ba\).
\end{proof}

\begin{lemma}[\cite{tzHydF}]        \label{LemKKXdqdL}
    Pour tout \( k\) entre \( 1\) et \( n-1\) nous avons
    \begin{equation}
        \AD(a)b^k=ab^ka^{-1}=ab^ka=b^{-k}.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous faisons la démonstration par récurrence. D'abord pour \( k=1\), nous devons avoir \( aba=b^{-1}\), ce qui est correct parce que par construction de \( G\) nous avons \( abab=e\). Ensuite nous supposons que le lemme tient pour \( k\) et nous regardons ce qu'il se passe avec \( k+1\) :
    \begin{equation}
            ab^{k+1}ba=ab^kba=\underbrace{ab^ka}_{b^{-k}}\underbrace{aba}_{b^{-1}}=b^{-k}b^{-1}=b^{-(k+1)}.
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooVQARooWuKHMZ}
    L'élément \( a\) n'est pas une puissance de \( b\).
\end{proposition}

\begin{proof}
    Supposons le contraire : \( a=b^k\). Dans ce cas nous aurions
    \begin{equation}
        e=(ab)(ab)=b^{k+1}b^{k+1}=b^{2k+2}=b^{2k}b^2=a^2b^2=b^2,
    \end{equation}
    ce qui signifierait que \( b\) est d'ordre \( 2\), ce qui est exclu par construction.
\end{proof}

\begin{proposition}[\cite{tzHydF}]      \label{PROPooEPVGooQjHRJp}
    La liste des éléments de \( G\) est donnée par
    \begin{equation}
        G=\{ 1,b,\cdots,b^{n-1},a,ab,\ldots, ab^{n-1} \}=\{ a^{\epsilon}b^k\}_{\substack{\epsilon=0,1\\k=0,\ldots, n-1}}
    \end{equation}
    Les éléments de ces listes sont distincts.
\end{proposition}

\begin{proof}
    Étant donné que \( a\) n'est pas une puissance de \( b\), les éléments \( 1\), \( a\), \( b\),\ldots, \( b^{n-1}\) sont distincts. De plus si \( k\) et \( m=k+p\) sont deux éléments distincts de \( \{ 1,\ldots, n-1 \}\), nous avons \( ab^k\neq ab^m\) parce que si \( ab^k=ab^{k+p}\), alors \( a=ab^p\) avec \( p<n\), ce qui est impossible. Pour la même raison, \( ab^k\neq e\), et \( ab^k\neq b^m\).

    Au final les éléments \( 1,a,b,\ldots, b^{n-1},ab,\ldots, ab^{n-1}\) sont tous différents. Nous devons encore voir qu'il n'y en a pas d'autres.

    Par définition le groupe \( G\) est engendré par \( a\) et \( b\), donc tout élément \( x\in G\) s'écrit $x=a^{m_1}b^{k_1}\ldots a^{m_r}b^{k_r}$ pour un certain \( r\) et avec pour tout \( i\), \( k_i\in\{ 1,\ldots, n-1 \}\) (sauf \( k_r\) qui peut être égal à zéro) et \( m_i=1\), sauf \( m_1\) qui peut être égal à zéro. Donc
    \begin{equation}
        x=a^mb^{k_1}ab^{k_2}a\ldots b^{k_{r-1}}ab^{k_r}
    \end{equation}
    où \( m\) et \( k_r\) peuvent éventuellement être zéro. En utilisant le lemme \ref{LemKKXdqdL} sous la forme \( b^{k_i}a=ab^{-k_i}\), quitte à changer les valeurs des exposants, nous pouvons passer tous les \( a \) à gauche et tous les \( b\) à droite pour finir sous la forme \( x=a^kb^m\). 

    Donc non, il n'existe pas d'autres éléments dans \( G\) que ceux déjà listés.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LemooNFRIooPWuikH}
    Tout élément de \( G\) s'écrit de façon unique sous la forme \( a^{\epsilon}b^k\) ou \( b^ka^{\epsilon}\) avec \( \epsilon=0,1\) et \( k=0,\ldots, n-1\).
\end{lemma}

\begin{proof}
    Nous commençons par la forme \( a^{\epsilon}b^k\). L'existence est la proposition \ref{PROPooEPVGooQjHRJp}. Pour l'unicité nous supposons \( a^{\epsilon}b^k=a^{\sigma}b^l\) et nous décomposons en \( 4\).
    \begin{subproof}
        \item[\( \epsilon=0\), \( \sigma=0\)]
            Alors \( b^k=b^l\). Mais \( b\) étant d'ordre \( n\) et \( k,l\) étant égaux au maximum à \( n-1\), cette égalité implique \( k=l\).
        \item[\( \epsilon=0\), \( \sigma=1\)]
            Alors \( b^k=ab^l\), ce qui donne \( a=b^{k-l}\), ce qui est interdit par la proposition \ref{PROPooVQARooWuKHMZ}.
        \item[\( \epsilon=1\), \( \sigma=0\)]
            Même problème.
        \item[\( \epsilon=1\), \( \sigma=1\)]
            Encore une fois \( b^k=b^l\) implique \( k=l\).
    \end{subproof}
    En ce qui concerne la forme \( b^ka^{\epsilon}\), l'existence est à montrer. Soit l'élément \( g=a^{\epsilon}b^k\) et cherchons à le mettre sous la forme \( b^la^{\sigma}\). Si \( \epsilon=0\) c'est évident. Sinon \( \epsilon=1\) et nous avons par le lemme \ref{LemKKXdqdL}
    \begin{equation}
        ab^k=b^{-k}a^{-1}=b^{-k}b^na=b^{-k}a.
    \end{equation}
    En ce qui concerne l'unicité, nous refaisons \( 4\) cas pour \( b^ka^{\epsilon}=b^la^{\sigma}\) comme précédemment et ils se traitement exactement comme précédemment.
\end{proof}

\begin{theorem}
    Les groupes \( G\) et \( D_n\) sont isomorphes.
\end{theorem}

\begin{proof}
        Nous utilisons l'application
    \begin{equation}
        \begin{aligned}
            \psi\colon G&\to D_n \\
            a^kb^m&\mapsto s^kr^m. 
        \end{aligned}
    \end{equation}
    C'est évidemment bien défini et bijectif, mais c'est également un homomorphisme parce que si nous calculons \( \psi\) sur un produit, nous devons comparer
    \begin{equation}        \label{EqBULPilp}
        \psi\big( a^{k_1}b^{m_1}a^{k_2}b^{m_2} \big)
    \end{equation}
    avec
    \begin{equation}        \label{EqIVEIphI}
        \psi\big( a^{k_1}b^{m_1}\big)\psi\big(a^{k_2}b^{m_2} \big)= s^{k_1}r^{m_1}s^{k_2}r^{m_2}.
    \end{equation}
    Vu que \( D_n\) et \( G\) ont les mêmes propriétés qui permettent de permuter \( a\) et \( b\) ou \( s\) et \( r\), l'expression à l'intérieur du \( \psi\) dans \eqref{EqBULPilp} se simplifie en \( a^kb^m\) avec les même \( k\) et \( n\) que l'expression à droite dans \eqref{EqIVEIphI} ne se simplifie en \( s^kr^m\).
\end{proof}

\begin{corollary}
    Toutes les propriétés démontrées pour \( G\) sont vraies pour \( D_n\). En particulier, avec quelques redites :
    \begin{enumerate}
        \item
            Le groupe \( D_n\) peut être défini comme étant le groupe engendré par un élément \( s\) d'ordre \( 2\) et un élément \( r\) d'ordre \( n-1\) assujettis à la relation \( srsr=e\).
        \item
            Le groupe \( D_n\) n'est pas abélien.
        \item
            Pour tout \( k\in\{ 1,\ldots, n-1 \}\) nous avons \( sr^ks=r^{-k}\).
        \item
            L'élément \( s\) ne peut pas être obtenu comme une puissance de \( r\).
        \item
            La liste des éléments de \( D_n\) est
            \begin{equation}
                D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
            \end{equation}
        \item
            Le groupe diédral \( D_n\) est d'ordre \( 2n\).
    \end{enumerate}
\end{corollary}

\begin{proposition}
    En posant \( C_n=\{ r^k \}_{k=0,\ldots, n-1}\) et \( C_2=\{ a^{\epsilon} \}_{\epsilon=0,1}\), nous pouvons exprimer \( D_n\) comme le produit semi-direct
    \begin{equation}
        D_n=C_n\times_{\rho}C_2
    \end{equation}
    où \( \rho\) désigne l'action adjointe.
\end{proposition}

\begin{proof}
    L'isomorphisme est :
    \begin{equation}
        \begin{aligned}
            \psi\colon C_n\times_{\rho}C_2&\to D_n \\
            (b^k,a^{\epsilon})&\mapsto b^ka^{\epsilon}.
        \end{aligned}
    \end{equation}
    \begin{subproof}
        \item[Action adjointe]
            L'application \( \rho_{a^{\epsilon}}=\AD(a^{\epsilon})\) est toujours un homomorphisme. Vu que \( a^{\epsilon}\) est soit \( e\) soit \( a\), nous allons nous restreindre à \( a\) et oublier l'exposant \( \epsilon\). Il faut montrer que\( \AD(a)\in\Aut(C_n)\). En utilisant le lemme \ref{LemKKXdqdL},
            \begin{equation}
                \AD(a)b^k=ab^ka^{-1}=b^{-k}=b^{n-k}.
            \end{equation}
            L'application \( \AD(a)\colon C_n\to C_n\) est donc bijective et homomorphique. Ergo isomorphisme.
        \item[Injectif]
            Si \( \psi(b^k,a^{\epsilon})=\psi(b^l,a^{\sigma})\), alors par unicité du lemme \ref{LemooNFRIooPWuikH} nous avons \( k=l\) et \( \epsilon=\sigma\).
        \item[Surjectif]
            Par la partie «existence»  du lemme \ref{LemooNFRIooPWuikH}.
        \item[Homomorphisme]
            L'homomorphisme est toujours de mise lorsque l'on prend deux sous-groupes d'un même groupe (ici le groupe des isométries de \( \eR^2\)) et que l'on tente de faire un produit semi-direct en utilisant l'action adjointe. Dans notre cas, le calcul est : 
            \begin{equation}
                \psi\big( (b^k,a^{\epsilon})(b^l,a^{\sigma}) \big)=b^k\rho_{a^{\epsilon}}(b^l)a^{\epsilon+\sigma}=b^ka^{\epsilon}b^la^{-\epsilon}a^{\epsilon+\sigma}=b^ka^{\epsilon}b^la^{\sigma}=\psi(b^k,a^{\epsilon})\psi(b^l,a^{\sigma}).
            \end{equation}
    \end{subproof}
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Classes de conjugaison}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{subsubsecZQnBcgo}

Pour les classes de conjugaison du groupe diédral nous suivons \cite{HRIMAJJ}.

D'abord pour des raisons de déterminants\footnote{Vous notez qu'ici nous utilisons un argument qui utilise la définition de \( D_n\) comme isométries de \( \eR^2\). Si nous avions voulu à tout prix nous limiter à la définition «abstraite» en termes de générateurs, il aurait fallu trouver autre chose.}, les classes des éléments de la forme \( r^k\) et de la forme \( sr^k\) ne se mélangent pas. Nous notons \( C(x)\) la classe de conjugaison de \( x\), et \( y\cdot x=yxy^{-1}\).

Les relations que nous allons utiliser sont 
\begin{subequations}
    \begin{align}
        sr^ks=r^{-k}\\
        rs=sr^{-1}=sr^{n-1}.
    \end{align}
\end{subequations}

La classe de conjugaison qui ne rate jamais est bien entendu \( C(1)={1}\). Nous commençons les vraies festivités \( C(r^{m})\). D'abord \( r^k\cdot r^m=r^m\), ensuite
\begin{equation}
    (sr^k)\cdot r^m=sr^kr^mr^{-k}s^{-1}=sr^ms^{-1}=r^{-m}.
\end{equation}
Donc
\begin{equation}    \label{EqVFfFxgi}
    C(r^m)=\{ r^m,r^{-m} \}.
\end{equation}
À ce niveau il faut faire deux remarques. D'abord si \( m>\frac{ n }{2}\), alors \( C(r^m)\) est la classe de \( C^{n-m}\) avec \( n-m<\frac{ n }{2}\). Donc les classes que nous avons trouvées sont uniquement à lister avec \( m<\frac{ n }{2}\). Ensuite si \( m=\frac{ n }{2}\) alors \( r^m=r^{-m}\) et la classe est un singleton. Cela n'arrive que si \( n\) est pair.

Nous passons ensuite à \( C(s)\). Nous avons
\begin{equation}
    r^k\cdot s=r^ksr^{-k}=ssr^ksr^{-k}=sr^{-k}r^{-k}=sr^{n-2k},
\end{equation}
et
\begin{equation}
    (sr^k)\cdot s=\underbrace{sr^ks}_{r^{-k}}r^{-k}s^{-1}=r^{-2k}s=r^{n-2k}s=sr^{(n-1)(n-2k)}=sr^{n^2-2kn-n+2k}=sr^{2k}.
\end{equation}
donc
\begin{equation}
    C(s)=\{ sr^{n-2k},sr^{2k} \}_{k=0,\ldots, n-1}.
\end{equation}
Ici aussi l'écriture n'est pas optimale : peut-être que pour certains \( k\) il y a des doublons. Nous reportons l'écriture exacte à la discussion plus bas qui distinguera \( n\) pair de \( n\) impair. Notons juste que si \( n\) est pair, l'élément \( sr\) n'est pas dans la classe \( C(s)\).

Nous en faisons donc à présent le calcul en gardant en tête le fait qu'il n'a de sens que si \( n\) est pair. D'abord
\begin{equation}
    s\cdot (sr)=ssrs=rs=sr^{n-1}.
\end{equation}
Ensuite
\begin{equation}
    (sr^k)\cdot (sr)=sr^ksrr^{-k}s=r^{-2k+1}s=sr^{2k-1}.
\end{equation}
Avec \( k=\frac{ n }{2}\), cela rend \( s\cdot (sr)\), donc pas besoin de le recopier. Nous avons
\begin{equation}
    C(sr)=\{ sr^{2k-1} \}_{k=1,\ldots, n-1}.
\end{equation}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le compte pour $ n$ pair}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{SubsubsecROVmHuM}

Si \( n\) est pair, nous avons les classes
\begin{subequations}
    \begin{align}
        C(1)&=\{ 1 \}       &&&\text{\( 1\) élément}\\
        C(r^m)&=\{ r^m,r^{m-1} \}&\text{ pour }&0<m<\frac{ n }{2}   &\text{\( \frac{ n }{2}-1\) fois \( 2\) éléments}\\
        C(r^{n/2})&=\{ r^{n/2} \}   &&& \text{\( 1\) élément}\\ 
        C(s)&=\{ sr^{2k} \}_{k=0,\ldots, \frac{ n }{2}-1} &&& \text{\( \frac{ n }{2}\) éléments}\\
        C(sr)&=\{ sr^{2k+1} \}_{k=0,\ldots, \frac{ n }{2}-1} &&& \text{\( \frac{ n }{2}\) éléments}.
    \end{align}
\end{subequations}
Au total nous avons bien listé \( 2n\) éléments comme il se doit, dans \(  \frac{ n }{2}+3\) classes différentes.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le compte pour $ n$ impair}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{Subsubsec*GJIzDEP}

Si \( n\) est impair, nous avons les classes
\begin{subequations}
    \begin{align}
        C(1)&=\{ 1 \}       &&&\text{\( 1\) élément}\\
        C(r^m)&=\{ r^m,r^{m-1} \}&\text{ pour }&0<m<\frac{ n-1 }{2}   &\text{\( \frac{ n-1 }{2}\) fois \( 2\) éléments}\\
        C(s)&=\{ sr^k \}_{k=0,\ldots, n-1} &&& \text{\( n\) éléments}
    \end{align}
\end{subequations}
Au total nous avons bien listé \( 2n\) éléments comme il se doit, dans \(  \frac{ n+3 }{2}\) classes différentes.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Applications : du dénombrement}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le jeu de la roulette}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{pTqJLY}
\index{groupe!fini}
\index{groupe!de permutations}
\index{groupe!et géométrie}
\index{combinatoire}
\index{dénombrement}

Soit une roulette à \( n\) secteurs que nous voulons colorier en \( q\) couleurs\cite{HEBOFl}. Nous voulons savoir le nombre de possibilités à rotations près. Soit d'abord \( E\) l'ensemble des coloriages possibles sans contraintes; il y a naturellement \( q^n\) possibilités. Sur l'ensemble \( E\), le groupe cyclique \( G\) des rotations d'angle \( 2\pi/n\) agit. Deux coloriages étant identiques si ils sont reliés par une rotation, la réponse à notre problème est donné par le nombre d'orbites de l'action de \( G\) sur \( E\) qui sera donnée par la formule du théorème de Burnside \ref{THOooEFDMooDfosOw}. 

Nous devons calculer \( \Card\big( \Fix(g) \big)\) pour tout \( g\in G\). Soit \( g\), un élément d'ordre \( d\) dans \( G\). Si \( g\) agit sur la roulette, chaque secteur a une orbite contenant \( d\) éléments. Autrement dit, \( g\) divise la roulette en \( n/d\) secteurs. Un élément de \( E\) appartenant à \( \Fix(g)\) doit colorier ces \( n/d\) secteurs de façon uniforme; il y a \( q^{n/d}\) possibilités.

Il reste à déterminer le nombre d'éléments d'ordre \( d\) dans \( G\). Un élément de \( G\) est donné par un nombre complexe de la forme \(  e^{2ik\pi/n}\). Les éléments d'ordre \( d\) sont les racines primitives\footnote{Une racine non primitive \( 8\)ième de l'unité est par exemple \( i\). Certes \( i^8=1\), mais \( i^4=1\) aussi. Le nombre \( i\) est d'ordre \( 4\).} \( d\)ièmes de l'unité. Nous savons que --par définition-- il y a \( \varphi(d)\) telles racines primitives de l'unité. Bref il y a \( \varphi(d)\) éléments d'ordre \( d\) dans \( G\). 

La formule de Burnside nous donne maintenant le nombre d'orbites :
\begin{equation}
    \frac{1}{ n }\sum_{d|n}\varphi(d)q^{n/d}.
\end{equation}
Cela est le nombre de coloriage possibles de la roulette à \( n\) secteurs avec \( q\) couleurs.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{L'affaire du collier}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{siOQlG}

Nous avons maintenant des perles de \( q\) couleurs différentes et nous voulons en faire un collier à \( n\) perles. Cette fois non seulement les rotations donnent des colliers équivalents, mais en outre les symétries axiales (il est possible de retourner un collier, mais pas une roulette). Le groupe agissant sur \( E\) est maintenant le groupe diédral\footnote{Définition \ref{DEFooIWZGooAinSOh}.}\index{diédral}\index{groupe!diédral} \( D_n\) conservant un polygone a \( n\) sommets.

Nous devons séparer le cas \( n\) impair du cas \( n\) pair.

Si \( n\) est impair, alors les axes de symétries passent par un sommet par le milieu du côté opposé. Le groupe \( D_n\) contient \( n\) symétries axiales. Nous avons donc maintenant
\begin{equation}
    | G |=2n.
\end{equation}
Nous écrivons la formule de Burnside
\begin{equation}
    \Card(\Omega)=\frac{1}{ 2n }\sum_{g\in G}\Card\big( \Fix(g) \big).
\end{equation}
Si \( g\) est une rotation, le travail est déjà fait. Si \( g\) est une symétrie, nous avons le choix de la couleur du sommet par lequel passe l'axe et le choix de la couleur des \( (n-1)/2\) paires de sommets. Cela fait
\begin{equation}
    qq^{(n-1)/2}=q^{\frac{ n+1 }{2}}
\end{equation}
possibilités. Nous avons donc
\begin{equation}
    \Card(\Omega)=\frac{1}{ 2n }\left( \sum_{d|n}q^{n/d}\varphi(d)+nq^{\frac{ n+1 }{2}} \right).
\end{equation}

Si \( n\) est pair, le choses se compliquent un tout petit peu. En plus de symétries axiales passant par un sommet et le milieu du côté opposé, il y a les axes passant par deux sommets opposés. Pour colorier un collier en tenant compte d'une telle symétrie, nous pouvons choisir la couleur des deux perles par lesquelles passe l'axe ainsi que la couleur des \( (n-2)/2\) paires de perles. Cela fait en tout
\begin{equation}
    q^2q^{\frac{ n-2 }{2}}=q^{\frac{ n+2 }{2}}.
\end{equation}
Le groupe \( G\) contient \( n/2\) tels axes.

Notons que cette fois \( G\) ne contient plus que \( n/2\) symétries passant par un sommet et un côté. L'ordre de $G$ est donc encore \( 2n\). La formule de Burnside donne
\begin{equation}
    \Card(\Omega)=\frac{1}{ 2n }\left( \sum_{d\divides n}\varphi(d)q^{n/d}+\frac{ n }{2}q^{(n+2)/2}+\frac{ n }{2}q^{n/2} \right).
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Géométrie hyperbolique}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Inversion}
%---------------------------------------------------------------------------------------------------------------------------
