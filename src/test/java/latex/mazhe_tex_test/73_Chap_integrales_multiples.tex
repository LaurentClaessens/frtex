% This is part of Mes notes de mathématique
% Copyright (c) 2009-2016
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Intégrales convergeant uniformément}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Définition et propriété}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooSHWAooWtswtp}
    Soit \( (\Omega,\mu)\) un espace mesuré. Nous disons que l'intégrale
    \begin{equation}
        \int_{\Omega}f(x,\omega)d\mu(\omega)
    \end{equation}
    \defe{converge uniformément}{convergence!uniforme!intégrale} en \( x\) si pour tout \( \epsilon>0\), il existe un compact \( K_{\epsilon}\) tel que pour tout compact \( K\) tel que \( K_{\epsilon}\subset K\) nous avons
    \begin{equation}
        \left| \int_{\Omega\setminus K}f(x,\omega)d\mu(\omega) \right| \leq \epsilon.
    \end{equation}
    Le point important est que le choix de \( K_{\epsilon}\) ne dépend pas de \( x\).
\end{definition}

\begin{lemma}       \label{LemOgQdpJ}
    Soit
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega),
    \end{equation}
    une intégrale uniformément convergente. Pour chaque \( k\in \eN\) nous considérons un compact \( K_k\) tel que
    \begin{equation}
        \left| \int_{\Omega\setminus K_k}f(x,\omega)d\mu(\omega) \right| \leq\frac{1}{ k }.
    \end{equation}
    Alors la suite de fonctions \( F_k\) définie par
    \begin{equation}
        F_k(x)=\int_{K_k}f(x,\omega)d\mu(\omega)
    \end{equation}
    converge uniformément vers \( F\).
\end{lemma}

\begin{proof}
    Nous avons
    \begin{subequations}
        \begin{align}
            \big| F_k(x)-F(x) \big|&=\left| \int_{K_k}f(x,\omega)d\mu(\omega)-\int_{\Omega}f(x,\omega)d\mu(\omega) \right| \\
            &=| \int_{\Omega\setminus K_k}f(x,\omega)d\mu(\omega) |\\
            &\leq \frac{1}{ k }.
        \end{align}
    \end{subequations}
\end{proof}

%------------------------------------------------------------------------------------------------------------------------
\subsection{Critères de convergence uniforme}
%---------------------------------------------------------------------------------------------------------------------------

Afin de tester l'uniforme convergence d'une intégrale, nous avons le \defe{critère de Weierstrass}{critère!Weierstrass}:
\begin{theorem}		\label{ThoCritWeiIntUnifCv}
Soit $f(x,t)\colon [\alpha,\beta]\times[a,\infty[ \to \eR$, une fonction dont la restriction à toute demi-droite $x=cst$ est mesurable. Si $| f(x,t) |< \varphi(t)$ et $\int_a^{\infty}\varphi(t)dt$ existe, alors l'intégrale
\begin{equation}
	\int_0^{\infty}f(x,t)dt
\end{equation}
est uniformément convergente.
\end{theorem}

Le théorème suivant est le \defe{critère d'Abel}{critère!Abel pour intégrales} :
\begin{theorem}		\label{ThoAbelIntUnif}
	Supposons que $f(x,t)=\varphi(x,t)\psi(x,t)$ où $\varphi$ et $\psi$ sont bornée et intégrables en $t$ au sens de Riemann sur tout compact $[a,b]$, $b\geq a$. Supposons que :
	\begin{enumerate}
		\item $| \int_a^{T}\varphi(x,t)dt |\leq M$ où $M$ est indépendant de $T$ et de $x$,
		\item $\psi(x,t)\geq 0$,
		\item pour tout $x\in[\alpha,\beta]$, $\psi(x,t)$ est une fonction décroissante de $t$,
		\item les fonctions $x\mapsto \psi(x,t)$ convergent uniformément vers $0$ lorsque $t\to\infty$.
	\end{enumerate}
	Alors l'intégrale
	\begin{equation}
		\int_a^{\infty}f(x,t)dt
	\end{equation}
	est uniformément convergente.
\end{theorem}

\begin{remark}
    Étant donné que la fonction sinus est bornée, il est tentant de l'utiliser comme $\varphi$ dans le critère d'Abel (théorème \ref{ThoAbelIntUnif}). Hélas,
    \begin{equation}
        \int_0^T\sin(xt)=-\frac{ 1 }{ x }\big( \cos(xT)-\cos(x) \big),
    \end{equation}
    qui n'est pas bornée pour tout $x$ ! Poser $\varphi(x,t)=\sin(xt)$ \emph{ne fonctionne pas} pour assurer la convergence uniforme sur un intervalle qui contient des $x$ arbitrairement proches de $0$. Le critère d'Abel avec $\varphi(x,t)=\sin(xt)$ ne permet que de conclure à l'uniforme convergence \emph{sur tout compact} ne contenant pas $0$. Cela est toutefois souvent suffisant pour étudier la continuité ou la dérivabilité en se servant du fameux coup du compact.
\end{remark}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions définies par une intégrale}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecCHwnBDj}
\index{suite!de fonctions intégrables}
\index{fonction!définie par une intégrale}
\index{permuter!limite et intégrale}

Soit \( (\Omega,\mu)\) un espace mesuré. Nous nous demandons dans quel cas l'intégrale
\begin{equation}
    F(x)=\int_{\Omega}f(x,\omega)d\omega
\end{equation}
définit une fonction \( F\) continue, dérivable ou autre. 

Dans la suite nous allons considérer des fonctions \( f\) à valeurs réelles. Quitte à passer aux composantes, nous pouvons considérer des fonctions à valeurs vectorielles. Par contre le fait que \( x\) soit dans \( \eR\) ou dans \( \eR^n\) n'est pas spécialement une chose facile à traiter.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Continuité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------
\index{continuité!fonction définie par une intégrale}

Nous allons présenter deux théorèmes donnant la continuité de \( F\).
\begin{enumerate}
    \item
        Si \( f\) est majorée par une fonction ne dépendant pas de \( x\), nous avons le théorème \ref{ThoKnuSNd},
    \item
        si l'intégrale est uniformément convergente, nous avons le théorème \ref{ThotexmgE}.
\end{enumerate}

\begin{theorem} \label{ThoKnuSNd}
    Soit \( (\Omega,\mu)\) est un espace mesuré, soit \( x_0\in \eR^m\) et \( f\colon U\times \Omega\to \eR\) où \( U\) est ouvert dans \( \eR^m\). Nous supposons que
    \begin{enumerate}
        \item
            La fonction \( f(x,.)\) est dans \( L^1(\Omega,\mu)\) pour tout \( x \in \eR^m\).
        \item
            La fonction \( f(.,\omega)\) est continue en \( x_0\) pour tout \( \omega\in\Omega\).
            %TODO : peut-être qu'on peut dire seulement pour presque tout omege dans Omega, voir la proposition \ref{prop:fdefint}.
        \item       \label{ItemNAuYNG}
            Il existe une fonction \( G\in L^1(\Omega)\) telle que
            \begin{equation}
                | f(x,\omega) |\leq G(\omega)
            \end{equation}
            pour tout \( x\in U\).
    \end{enumerate}
    Alors la fonction 
    \begin{equation}
        \begin{aligned}
            F\colon U&\to \eR \\
            x&\mapsto \int_{\Omega}f(x,\omega)d\mu(\omega) 
        \end{aligned}
    \end{equation}
    est continue en \( x_0\).
\end{theorem}
\index{permuter!limite et intégrale!espace mesuré}

\begin{proof}
    Soit \( (x_n)\) une suite convergente vers \( x_0\). Nous considérons la suite de fonctions \( f_n\colon \Omega\to \eR\) définies par
    \begin{equation}
        f_n(\phi)=f(x_n,\omega).
    \end{equation}
    sur qui nous pouvons utiliser le théorème de la convergence dominée (théorème \ref{ThoConvDomLebVdhsTf}) pour obtenir
    \begin{subequations}
        \begin{align}
            \lim_{n\to \infty} F(x_n)&=\lim_{n\to \infty} \int_{\Omega}f(x_n,\omega)d\mu(\omega)\\
            &=\int_{\Omega}\lim_{n\to \infty} f(x_n,\omega)d\mu(\omega)\\
            &=\int_{\Omega}f(x,\omega)d\mu(\omega)\\
            &=F(x).
        \end{align}
    \end{subequations}
    Nous avons utilisé la continuité de \( f(.,\omega)\).
\end{proof}


Si nous avons un peu de compatibilité entre la topologie et la mesure, alors nous pouvons utiliser l'uniforme convergence d'une intégrale pour obtenir la continuité d'une fonction définie par une intégrale.

\begin{theorem} \label{ThotexmgE}
    Soit \( (\Omega,\mu)\) un espace topologique mesuré tel que tout compact est de mesure finie. Soit une fonction \( f\colon \eR\times \Omega\to \eR\) telle que
    \begin{enumerate}
        \item
            Pour chaque \( x\in \eR\), la fonction \( f(x,.)\) est \( L^1(\Omega,\mu)\).
        \item
            Pour chaque \( \omega\in \Omega\), la fonction \( f(.,\omega)\) est continue en \( x_0\).
        \item
            L'intégrale
            \begin{equation}
                F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega)
            \end{equation}
            est uniformément convergente\footnote{Définition \ref{DEFooSHWAooWtswtp}.}.
    \end{enumerate}
    Alors la fonction \( F\) est continue en \( x_0\).
\end{theorem}
\index{permuter!limite et intégrale!espace mesuré}

\begin{proof}
    Nous reprenons les notations du lemme \ref{LemOgQdpJ}. Les fonctions
    \begin{equation}
        F_k(x)=\int_{K_k}f(x,\omega)d\mu(\omega)
    \end{equation}
    existent parce que les fonctions \( f(x,.)\) sont dans \( L^1(\Omega)\). Montrons que les fonctions \( F_k\) sont continues. Soit une suite \( x_k\to x_0\) nous avons
    \begin{equation}
        \lim_{n\to \infty} F_k(x_n)=\lim_{n\to \infty} \int_{K_k}f(x_n,\omega)d\mu(\omega).
    \end{equation}
    Nous pouvons inverser la limite et l'intégrale en utilisant le théorème de la convergence dominée. Pour cela, la fonction \( f(x_n,\omega)\) étant continue sur le compact \( K_k\), elle y est majorée par une constante. Le fait que les compacts soient de mesure finie (hypothèse) implique que les constantes soient intégrales sur \( K_k\). Le théorème de la convergence dominée implique alors que
    \begin{equation}
        \lim_{n\to \infty} F_k(x_n)=\int_{K_k}\lim_{n\to \infty} f(x_n,\omega)d\mu(\omega)=\int_{K_k}f(x_0,\omega)d\mu(\omega)=F_k(x_0).
    \end{equation}
    Nous avons utilisé le fait que \( f(.,\omega)\) était continue en \( x_0\).

    Le lemme \ref{LemOgQdpJ} nous indique alors que la convergence \( F_k\to F\) est uniforme. Les fonctions \( F_k\) étant continues, la fonction \( F\) est continue.
\end{proof}

Pour finir, citons ce résultat concernant les fonctions réelles.
\begin{theorem}		\label{ThoInDerrtCvUnifFContinue}
    Nous considérons \( F(x)=\int_a^{\infty}f(x,t)dt\). Si \( f\) est continue sur $[\alpha,\beta]\times[a,\alpha[$ et l'intégrale converge uniformément, alors $F(x)$ est continue.
\end{theorem}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Le coup du compact}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons vu des fonctions définies par toute une série de processus de limite (suites, séries, intégrales). Une des questions centrales est de savoir si la fonction limite est continue, dérivable, intégrale, etc. étant donné que les fonctions sont continues.

Pour cela, nous inventons le concept de \emph{convergence uniforme}. Si la limite (série, intégrale) est uniforme, alors la fonction limite sera continue. Il arrive qu'une limite ne soit pas uniforme sur un intervalle ouvert $]0,1]$, et que nous voulions quand même prouver la continuité sur cet intervalle. C'est à cela que sert la notion de convergence uniforme \emph{sur tout compact}. En effet, la notion de continuité est une notion locale : savoir ce qu'il se passe dans un petit voisinage autour de $x$ est suffisant pour savoir la continuité en $x$ (idem pour sa dérivée).

Si nous avons uniforme convergence sur tout compact de $]0,1]$, mais pas uniforme convergence sur cet intervalle, la limite sera quand même continue sur $\mathopen] 0 , 1 \mathclose]$. En effet, si $x\in]0,1]$, il existe un ouvert autour de $x$ contenu dans un compact contenu dans $]0,1]$. L'uniforme convergence sur ce compact suffit à prouver la continuité en $x$.

Déduire la continuité sur un ouvert à partir de l'uniforme convergence sur tout compact de l'ouvert est appelé faire le \defe{coup du compact}{compact!le coup du}.


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivabilité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------
\index{dérivabilité!fonction définie par une intégrale}

Nous traitons à présent de la dérivabilité de la fonction \( F\) définie comme intégrale de \( f\).

\begin{theorem}[Dérivation sous le signe intégral\cite{MesIntProbb}]    \label{ThoMWpRKYp}
    Soit \( (\Omega,\mu)\) un espace mesuré et une fonction \( f\colon \eR\times \Omega\to \eR\) dont nous voulons étudier la dérivabilité en \(a\in \eR\). Nous supposons qu'il existe \( \delta>0\), \( A\) mesurable de mesure nulle dans \( \Omega\) tels que
    \begin{enumerate}
        \item
            \( f(x,.)\) soit dans \( L^1(\Omega)\).
        \item
            L'application \( x\mapsto f(x,\omega)\) est dérivable pour tout \( x\in B(a,\delta)\) et pour tout \( \omega\in \complement A\).
        \item
            Il existe une fonction \( G\) intégrable sur \( \Omega\) telle que
            \begin{equation}
                \left| \frac{ \partial f }{ \partial x }(x,\omega) \right| \leq G(\omega)
            \end{equation}
            pour tout \( x\in B(a,\delta)\) et pour tout \( \omega\in\complement A\).
    \end{enumerate}
    Alors la fonction
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega)
    \end{equation}
    est dérivable en \( a\) et nous pouvons permuter la dérivée et l'intégrale :
    \begin{equation}
        F'(a)=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\mu(\omega).
    \end{equation}
\end{theorem}
\index{permuter!dérivée et intégrale!dans \( \eR\)}

\begin{proof}
    Soit une suite \( (x_n)\) dans \( B(a,\delta)\) telle que \( x_n\neq a\) et \( x_n\to a\). Si la limite
    \begin{equation}
        \lim_{n\to \infty} \frac{ F(a)-F(x_n) }{ a-x_n }
    \end{equation}
    existe et ne dépend pas de la suite choisie, alors la fonction \( F\) est dérivable en \( a\) et sa dérivée vaut cette limite. Par linéarité de l'intégrale, nous devons étudier la limite
    \begin{equation}    \label{EqLIiralx}
        \lim_{n\to \infty} \int_{\Omega}\frac{ f(a,\omega)-f(x_n,\omega) }{ a-x_n }d\omega,
    \end{equation}
    montrer qu'elle existe, ne dépend pas de la suite choisie et vaut \( \int_{\Omega}\partial_xf(a,\omega)d\omega\). Nous sommes donc dans un problème d'inversion de limite et de dérivée pour lequel nous allons utiliser le théorème de la convergence dominée de Lebesgue. D'abord nous posons
    \begin{equation}    \label{EqAFOUbQB}
        g_n(\omega)=\frac{ f(x_n,\omega)-f(a,\omega) }{ x_n-a }.
    \end{equation}
    Cela est une suite de fonctions dans \( L^1(\Omega)\) parce qu'à la fois \( a\) et \( x_n\) sont dans \( B(a,\delta)\). De plus nous avons
    \begin{equation}
        \lim_{n\to \infty} g_n(\omega)=\frac{ \partial f }{ \partial x }(a,\omega)
    \end{equation}
    parce que nous savons que \( f\) est dérivable en \( a\) pour tout \( \omega\in\complement A\). En ce qui concerne la majoration de \( g_n\), nous utilisons le théorème des accroissements finis (théorème \ref{ThoAccFinis}) sur le numérateur de \eqref{EqAFOUbQB}. Pour tout \( n\) et pour tout \( \omega\in \complement A\), il existe un \( \theta_{n,\omega}\) dans \( \mathopen] a , x_n \mathclose[\) tel que
        \begin{equation}
            f(x_n,\omega)-f(a,\omega)=\frac{ \partial f }{ \partial x }(\theta_{n,\omega},\omega)(x_n-a),
        \end{equation}
        donc
        \begin{equation}
            | g_n(\omega) |=\left| \frac{ \partial f }{ \partial x }(\theta_{n,\omega},\omega) \right| \leq G(\omega).
        \end{equation}
        La dernière inégalité provient des hypothèses. Le théorème de la convergence dominée de Lebesgue (théorème \ref{ThoConvDomLebVdhsTf}) nous permet alors de calculer la limite \eqref{EqLIiralx} :
        \begin{equation}
            \lim_{n\to \infty} \int_{\Omega}g_n(\omega)d\omega=\int_{\Omega}\lim_{n\to \infty} g_n(\omega)d\omega=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\omega.
        \end{equation}
        Notons que l'existence de la dernière intégrale fait partie du théorème de la convergence dominée.

        Nous avons donc prouvé que la limite de gauche existait et ne dépendant pas de la suite choisie. Donc \( F\) est dérivable en \( a\) et la dérivée vaut cette limite :
        \begin{equation}
            F'(a)=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\mu(\omega).
        \end{equation}
\end{proof}

\begin{theorem}
		Supposons $f$ continue et sa dérivée partielle $\frac{ \partial f }{ \partial x }$ continue sur $[\alpha,\beta]\times[a,\alpha[$. Supposons que $F(x)=\int_a^{\infty}f(x,t)dt$ converge et que $\int_a^{\infty}\frac{ \partial f }{ \partial x }dt$ converge uniformément. Alors $F$ est $C^1$ sur $[\alpha,\beta]$ et 
		\begin{equation}
			\frac{ dF }{ dx }=\int_a^{\infty}\frac{ \partial f }{ \partial x }dt.
		\end{equation}
\end{theorem}

En ce qui concerne les fonctions dans \( \eR^n\), il y a les  propositions \ref{PropDerrSSIntegraleDSD} et \ref{PropAOZkDsh} qui parlent de différentiabilité sous l'intégrale.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Absolue continuité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DefAbsoluCont}
    Une fonction \( F\colon \eR\to \eR\) est \defe{absolument continue}{absolument continue} sur \( \mathopen[ a , b \mathclose]\) si il existe une fonction \( f\) sur \( \mathopen[ a , b \mathclose]\) telle que
    \begin{equation}
        F(x)=\int_a^xf(t)dt
    \end{equation}
    pour tout \( x\in\mathopen[ a , b \mathclose]\).
\end{definition}

\begin{theorem}     \label{ThoDerSousIntegrale}
    Soit \( A\) un ouvert de \( \eR\) et \( \Omega\), un espace mesuré. Soit une fonction \( f\colon A\times \Omega\to \eR\) et
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\omega.
    \end{equation}
    Nous supposons les points suivants.
    \begin{enumerate}
        \item
            La fonction \( f\) est mesurable en tant que fonction \( A\times\Omega\to \eR\). Pour chaque \( x\in A\), la fonction \( f(x,\cdot)\) est intégrable sur \( \Omega\).
        \item
            Pour presque tout \( \omega\in\Omega\), la fonction \( f(x,\omega)\) est une fonction absolument continue de \( x\).
        \item
            La fonction \( \frac{ \partial f }{ \partial x }\) est localement intégrable, c'est à dire que pour tout \( \mathopen[ a , b \mathclose]\subset A\),
            \begin{equation}
                \int_a^b\int_{\Omega}\left| \frac{ \partial f }{ \partial x }(x,\omega) \right| d\omega\,dx<\infty.
            \end{equation}
    \end{enumerate}
    Alors la fonction \( F\) est absolument continue et pour presque tout \( x\in A\), la dérivée est donné par
    \begin{equation}
        \frac{ d }{ dx }\int_{\Omega}f(x,\omega)d\omega=\int_{\Omega}\frac{ \partial f }{ \partial x }(x,\omega)d\omega.
    \end{equation}
\end{theorem}

La proposition suivante sera utilisée entre autres pour montrer que sous l'hypothèse d'une densité continue, la loi exponentielle est sans mémoire, proposition \ref{PropREXaIBg}.
\begin{proposition}		\label{PropDerrFnAvecBornesFonctions}
Soit $f(x,t)$ une fonction continue sur $[\alpha,\beta]\times[a,b]$, telle que $\frac{ \partial f }{ \partial x }$ existe et soit continue sur $]\alpha,\beta[\times[a,b]$. Soient $\varphi(x)$ et $\psi(x)$, des fonctions continues de $[\alpha,\beta]$ dans $\eR$ et admettant une dérivée continue sur $]\alpha,\beta [$. Alors la fonction
\begin{equation}
	F(x)=\int_{\varphi(x)}^{\psi(x)}f(x,t)dt
\end{equation}
admet une dérivée continue sur $]\alpha,\beta[$ et
\begin{equation}	\label{EqFormDerrFnAvecBorneNInt}
	\frac{ dF }{ dx }=\int_{\varphi(x)}^{\psi(x)}\frac{ \partial f }{ \partial x }(x,t)dt+f\big( x,\psi(x) \big)\cdot\frac{ d\psi }{ dx }- f\big( x,\varphi(x) \big)\cdot\frac{ d\varphi }{ dx }.
\end{equation}
\end{proposition}
\index{permuter!dérivée et intégrale!dans \( \eR\) avec les bornes}
%TODO : une preuve de ce théorème ? allons allons ...

L'exemple qui suit devrait pouvoir être rendu rigoureux en utilisant des distributions correctement.

\begin{example} \label{ExfYXeQg}
    Si \( g\) est une fonction continue, la fonction suivante est une primitive de \( g\) :
    \begin{equation}
        \int_0^xf(t)dt=\int_0^{\infty}f(t)\mtu_{t<x}(t)dt.
    \end{equation}
    Nous nous proposons de justifier \emph{de façon un peu heuristique} le fait que ce soit bien une primitive de \( g\) en considérant la fonction
    \begin{equation}
        f(t,x)=g(t)\mtu_{t<x}(t).
    \end{equation}
    Nous posons
    \begin{equation}
        F(x)=\int_0^{\infty}f(x,t)dt,
    \end{equation}
    et nous calculons \( F'\) en permutant la dérivée et l'intégrale\footnote{Ceci n'est pas rigoureux : il faudrait avoir un théorème à propos de distributions qui permet de le faire.}. D'abord,
    \begin{equation}
        f(t,x)=\begin{cases}
            g(t)    &   \text{si \( t\in \mathopen[ 0 , x \mathclose]\)}\\
            0    &    \text{sinon.}
        \end{cases}
    \end{equation}
    La dérivée de \( f\) par rapport à \( x\) est donnée par la distribution
    \begin{equation}
        \frac{ \partial f }{ \partial x }(t_0,x_0)=g(t_0)\delta(t_0-x_0).
    \end{equation}
    Donc
    \begin{equation}
        F'(x_0)=\int_0^{\infty}\frac{ \partial f }{ \partial x }(t,x_0)dt=\int_0^{\infty}g(t)\delta(t-x_0)=g(x_0),
    \end{equation}
    comme attendu.
\end{example}

Cet exemple est rendu rigoureux par la proposition suivante.
\begin{proposition} \label{PropJLnPpaw}
    Si \( f\in L^1(\eR)\), alors la fonction
    \begin{equation}
        F(x)=\int_{-\infty}^xf(t)dt
    \end{equation}
    est presque partout dérivable et pour les points où elle l'est nous avons \( F'(x)=f(x)\).
\end{proposition}
\index{fonction!définie par une intégrale}
%TODO : une preuve.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentiabilité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant est restrictif sur l'ensemble d'intégration (qui doit être compact), mais accepte des fonctions de plusieurs variables, ce qui est un premier pas vers la différentiabilité.
\begin{proposition}[Dérivation sous l'intégrale]		\label{PropDerrSSIntegraleDSD}
    Supposons $A\subset\eR^m$ ouvert et $B\subset\eR^n$ compact. Nous considérons une fonction \( f\colon A\times B\to \eR\). Si pour un $i\in\{ i,\ldots,n \}$, la dérivée partielle $\frac{ \partial f }{ \partial x_i }$ existe dans $A\times B$ et est continue, alors la fonction
    \begin{equation}
        F(x)=\int_Bf(x,t)dt
    \end{equation}
    admet une dérivée partielle dans la direction \( x_i\) sur \( A\). Cette dérivée partielle y est continue et
    \begin{equation}
        \frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt,
    \end{equation}
    pour tout \( a\) dans l'ouvert \( A\).
\end{proposition}
\index{fonction!définie par une intégrale}
\index{permuter!dérivée et intégrale!\( \eR^n\)}

\begin{proof}
    Nous procédons en plusieurs étapes.
    \begin{subproof}
    \item[\( F\) est dérivable]
            
        Nous voulons prouver que \( \frac{ \partial F }{ \partial x_i }(a,t)\) existe. Pour cela nous posons
        \begin{equation}
            g_l(t)=\frac{ f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_k,\ldots, a_n,t) }{ \epsilon_l }
        \end{equation}
        où \( \epsilon_l\) est une suite de nombres tendant vers zéro. La fonction \( f\) est dérivable dans la direction \( x_i\) si et seulement si \( \lim_{l\to \infty}g_l(t) \) existe et ne dépend pas du choix de la suite. À ce moment, la valeur de la dérivée partielle sera cette limite. Dans notre cas, nous savons que \( f\) admet une dérivée partielle dans la direction \( x_i\) et donc nous avons
        \begin{equation}
            \frac{ \partial f }{ \partial x_i }(a,t)=\lim_{l\to \infty} g_l(t).
        \end{equation}
        
        De la même façon pour \( F\) nous avons
        \begin{equation}
            \frac{ \partial F }{ \partial x_i }=\lim_{l\to \infty} \int_{B}g_l(t)dt.
        \end{equation}
        Sous-entendu : si la limite de droite ne dépend pas de la suite choisie, alors \( \frac{ \partial F }{ \partial x_i }\) existe et vaut cette limite.

        Vu la continuité de \( f\), le seul point à vérifier pour le théorème de la convergence dominée de Lebesgue est l'existence d'une fonction intégrable de \( t\) majorant \( g_l\). Pour cela le théorème de accroissements finis (théorème \ref{ThoAccFinis}) appliqué à la fonction \( \epsilon\mapsto f(a_n,\ldots, a_i+\epsilon,\ldots, a_n)\) nous dit que
        \begin{equation}
            f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_i,\ldots, a_n,t)=\epsilon_l\frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)
        \end{equation}
        pour un certain \( \theta\in B(a_i,\epsilon_l)\). Notons que ce \( \theta\) dépend de \( t\) mais pas de \( l\). Vu que \( \partial_if\) est continue par rapport à ses deux variables, si \( K\) est un voisinage compact autour de \( a\), il existe \( M>0\) tel que
        \begin{equation}    \label{EqMXqviPC}
            \left| \frac{ \partial f }{ \partial x_i }(x,t) \right| < M
        \end{equation}
        pour tout \( x\in K\) et tout \( t\in B\). La valeur de \( \frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)\) est donc bien majorée par rapport à \( \theta\) et par rapport à \( t\) en même temps par une constante qui n'a pas de mal à être intégrée sur le compact \( B\).
        
        Le théorème de la convergence dominée (théorème \ref{ThoConvDomLebVdhsTf}) s'applique donc bien et nous avons
        \begin{equation}
            \lim_{l\to \infty} \int_Bg_l(t)dt=\int_B\lim_{l\to \infty} g_l(t)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
        \end{equation}
        Le membre de droite ne dépendant pas de la suite \( \epsilon_l\) choisie, le membre de gauche est bien la dérivée de \( F\) par rapport à \( x_i\) et nous avons
        \begin{equation}
            \frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
        \end{equation}
        Cela prouve la première partie de la proposition.

    \item[La dérivée est continue]

        Soit \( K\) un voisinage compact autour de \( a\) et \( U'\) un ouvert tel que \( a\in U'\subset K\). Nous avons encore la majoration \eqref{EqMXqviPC} sur \( U'\) et donc le théorème de continuité sous l'intégrale \ref{ThoKnuSNd} nous indique que la fonction
        \begin{equation}
            \begin{aligned}
                U'&\to \eR \\
                x&\mapsto \int_{B}\frac{ \partial f }{ \partial x_i }(x,t)dt 
            \end{aligned}
        \end{equation}
        est continue en \( a\).
        
    \end{subproof}
\end{proof}

Une conséquence de la proposition \ref{PropDerrSSIntegraleDSD} est que si elle fonctionne pour tous les \( i\), alors \( F\) est différentiable et même de classe \( C^1\), et la différentielle de \( F\) s'obtient comme intégrale de la différentielle de \( f\).

\begin{proposition}\label{PropAOZkDsh}
    Supposons $A\subset\eR^m$ ouvert et $B\subset\eR^n$ compact. Si pour tout $i\in\{ i,\ldots,n \}$, la dérivée partielle $\frac{ \partial f }{ \partial x_i }$ existe dans $A\times B$ et est continue, alors \( F\) est de classe \( C^1\) et
    \begin{equation}
        (dF)_a=\int_B(df_t)_adt
    \end{equation}
    où \( f_t(x)=f(x,t)\).
\end{proposition}
\index{permuter!différentielle et intégrale!\( \eR^n\)}

\begin{proof}
    En vertu de la proposition \ref{PropDerrSSIntegraleDSD}, toutes les dérivées partielles de \( F\) sont continues. Cela implique que \( F\) est de classe \( C^1\) par la proposition \ref{PropDerContCun} et que la différentielle s'écrive en terme des dérivées partielles avec la formule usuelle. Nous avons alors
    \begin{subequations}
        \begin{align}
            (dF)_a(u)&=\sum_k\frac{ \partial F }{ \partial x_k }(a)u_k\\
            &=\int_B\sum_k\frac{ \partial f }{ \partial x_k }(a,t)dt\\
            &=\int_B\sum_k\frac{ \partial f_t }{ \partial x_k }(a)u_kdt\\
            &=\int_B (df_t)_a(u)dt.
        \end{align}
    \end{subequations}
    Cela est la formule annoncée.
\end{proof}

Un autre théorème tourne autour du pot, et me semble inutile.
\begin{theorem} \label{ThoOLAQyRL}
    Soit \( (\Omega,\mu)\) un espace mesuré, une fonction \( f\colon \eR^n\times \Omega\to \eR\) et \( a\in \eR^n\). Nous considérons la fonction
    \begin{equation}
        F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega).
    \end{equation}
    Pour chaque \( k=1,\ldots, n\) nous supposons avoir
    \begin{equation}
        \frac{ \partial F }{ \partial x_k }(a)=F_{|_k}'(a)=\int_{\Omega}\frac{ \partial f_{|_k} }{ \partial t }(a_k,\omega)d\mu(\omega)
    \end{equation}
    où \( F_{|_k}(t)=F(a_1,\ldots, t,\ldots, a_n)\) et \( f_{|_k}\) est définie de façon similaire.

    Nous supposons de plus que les fonctions \( \partial_{x_k}F\) sont continues.

    Alors \( F\) est de classe \( C^1\) et sa différentielle est donnée par
    \begin{equation}
        df_a=\int_{\Omega}(df_{\omega})_ad\omega
    \end{equation}
    où \( f_{\omega}\) est définie par \( f_{\omega}(x)=f(x,\omega)\).
\end{theorem}

\begin{proof}
    Étant donné que les dérivées partielles de \( F\) en \( a\) existent et sont continues, la proposition \ref{PropDerContCun} dit que \( F\) est différentiable et que
    \begin{equation}
        dF_a(u)=\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k.
    \end{equation}
    La linéarité de l'intégrale et les hypothèses nous donnent alors
    \begin{subequations}
        \begin{align}
            df_a(u)&=\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k\\
            &=\int_{\Omega}\sum_k\frac{ \partial f_{|_k} }{ \partial t }(a_k;\omega)u_kd\mu(\omega)\\
            &=\int_{\Omega}\sum_k\frac{ \partial f }{ \partial x_k }(a;\omega)u_kd\mu(\omega)\\
            &=\int_{\Omega}(df_{\omega})_a(u)d\mu(\omega),
        \end{align}
    \end{subequations}
    et donc \( df_a=\int_{\Omega}(df_{\omega})_ad\mu(\omega)\).
\end{proof}
Notons qu'en passant aux composantes, ce théorème fonctionne tout aussi bien pour des fonctions à valeurs dans un espace vectoriel normé de dimension finie plutôt que dans \( \eR\).

\begin{lemma}[Hadamard\cite{MVIooKLsjpa}]   \label{LemWNBooGPlIwT}
    Soit une fonction \( f\colon \eR^n\to \eR\) de classe \( C^p\) avec \( p\geq 1\). Pour tout \( a\in \eR^n\) il existe des fonctions \( g_1\),\ldots, \( g_n\) de classe \( C^{p-1}\) telles que
    \begin{equation}
        f(x)=f(a)+\sum_{i=1}^n(x_i-a_i)g_i(x).
    \end{equation}
\end{lemma}
\index{lemme!Hadamard}

\begin{proof}
    Vu que \( f\) est de classe \( C^1\), le théorème fondamental de l'analyse \ref{ThoRWXooTqHGbC} fonctionne et
    \begin{equation}    \label{EqZLTooVKmGln}
        f(x)-f(a)=\int_0^1\frac{ d }{ dt }\Big[ f\big( a+t(x-a) \big) \Big]dt=\int_0^1\sum_{i=1}^n\frac{ \partial f }{ \partial x_i }\big( a+t(x-a) \big)(x_i-a_i).
    \end{equation}
    Plus de détails : la fonction \( t\mapsto \frac{ d }{ dt }\Big[ f\big( a+t(x-a) \big) \Big]\) possède comme primitive la fonction \( F(t)=f\big( a+t(x-a) \big)\).

    Nous posons 
    \begin{equation}
        g_i(x)=\int_0^1\frac{ \partial f }{ \partial x_i }\big( a+t(x-a) \big)dt
    \end{equation}
    Le fait que l'intégrale existe est simplement le fait qu'il s'agit d'une fonction continue sur un compact et donc majorée par une constante. Pour voir que \( g_i\) est de classe \( C^{p-1}\) nous pouvons calculer \( \frac{ \partial g_i }{ \partial x_k }\) en permutant dérivée et intégrale par la proposition \ref{PropDerrSSIntegraleDSD} :
    \begin{equation}
        \frac{ \partial g_i }{ \partial x_k }(x)=\int_0^1\frac{ \partial  }{ \partial x_k }\left( \frac{ \partial f }{ \partial x_i }\big( a+t(x-a) \big) \right)dt=\int_0^1 t\frac{ \partial^2f }{ \partial x_k\partial x_i }\big( a+t(x-a) \big).
    \end{equation}
    Nous pouvons ainsi permuter \( p-1\) dérivées tout en gardant une fonction continue dans l'intégrale. Le théorème \ref{ThoKnuSNd} nous donne alors une fonction continue. Ainsi toutes les fonctions
    \begin{equation}
        \frac{ \partial^{p-1}g_i }{ \partial x_{i_1}\ldots\partial x_{i_{p-1}} }
    \end{equation}
    sont continues et \( g_i\) est de classe \( C^{p-1}\) par la proposition \ref{PropDYKooHvrfGw}.

    En repartant de \eqref{EqZLTooVKmGln} nous avons alors bien ce qui était annoncé :
    \begin{equation}
        f(x)=f(a)+\sum_{i=1}^ng_i(x)(x_i-a_i).
    \end{equation}
\end{proof}

\begin{corollary}       \label{CorQBXHooZVKeNG}
    Soit \( \phi\in\swD(\eR)\) tel que \( \phi^{(k)}(x_0)=0\) pour tout \( k\leq n\). Alors il existe une fonction \( \psi\in\swD(\eR)\) telle que 
    \begin{equation}
        \phi(x)=(x-x_0)^{n+1}\psi(x)
    \end{equation}
    pour tout \( x\in \eR\).
\end{corollary}

\begin{proof}
    En utilisant le lemme de Hadamard \ref{LemWNBooGPlIwT} avec \( a=x_0\), \( n=1\) et \( f(x_0)=0\), nous avons une fonction \( g_1\) à support compact telle que
    \begin{equation}        \label{EqTOJGooWZBBRJ}
        \phi(x)=\phi(x_0)+(x-x_0)g_1(x).
    \end{equation}
    Alors \( \phi'(x)=g_1(x)+(x-x_0)g'_1(x)\), ce qui donne immédiatement \( g_1(x_0)=0\) et donc une fonction \( g_2\) telle que \( g_1(x)=(x-x_0)g_2(x)\). En injectant dans \eqref{EqTOJGooWZBBRJ} nous avons
    \begin{equation}
        \phi(x)=(x-x_0)^2g_2(x).
    \end{equation}
    Il suffit de continuer ainsi tant que les dérivées de \( \phi\) s'annulent.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Formes différentielles exactes et fermées}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà parlé de formes différentielles et de leurs intégrales sur un chemin dans la section \ref{SecFormDiffRappel}.

\begin{definition}  \label{DefEFKQmPs}
La forme différentielle $\omega$ est \defe{exacte}{forme!différentielle!exacte} si il existe une fonction $f$ telle que $\omega=df$; elle est dite \defe{fermée}{forme!différentielle!fermée} si $d\omega=0$.
\end{definition}

Dire que la forme différentielle $\omega=fdx+gdy$ est fermée, c'est dire que
\begin{equation}
    \frac{ \partial g }{ \partial x }=\frac{ \partial f }{ \partial y }.
\end{equation}

Il est naturel de se demander si toutes les formes différentielles sont des différentielles de fonctions. Une réponse complète est délicate à établir, mais a d'innombrables conséquences en physique, notamment en ce qui concerne l'existence d'un potentiel vecteur pour le champ magnétique dans les équations de Maxwell.

Le fait qu'une forme exacte soit fermée est relativement facile à établir; c'est la proposition suivante. La question plus délicate est la réciproque : sous quelles conditions une forme fermée est-elle exacte ?
\begin{proposition}
	Si $\omega$ est une $1$-forme exacte de classe $C^1$, alors $\omega$ est fermée.
\end{proposition}

\begin{proof}
	Le fait que $\omega$ soit exacte implique l'existence d'une fonction $f$ telle que $\omega=df$, c'est à dire
	\begin{equation}
		\omega_x=\sum_i a_i(x)dx_i=\sum_i\frac{ \partial f }{ \partial x_i }(x)dx_i,
	\end{equation}
	c'est à dire que $a_i(x)=\frac{ \partial f }{ \partial x_i }(x)$. L'hypothèse que $\omega$ est $C^1$ implique que $f$ est $C^2$, et donc que nous pouvons inverser l'ordre de dérivation pour les dérivées secondes $\partial^2_{ij}f=\partial^2_{ji}f$. Nous pouvons donc faire le calcul suivant :
	\begin{equation}
		\frac{ \partial a_i }{ \partial x_j }=\frac{ \partial  }{ \partial x_j }\frac{ \partial f }{ \partial x_i }=\frac{ \partial  }{ \partial x_i }\frac{ \partial f }{ \partial x_j }=\frac{ \partial a_j }{ \partial x_i },
	\end{equation}
	ce qu'il fallait démontrer.
\end{proof}

La réciproque est vraie sur un ouvert simplement connexe.
\begin{theorem}        \label{ThoFermeExactFormRappel}
Supposons que $D\subset\eR^n$ soit un ouvert simplement connexe. Alors toute forme différentielle de degré $1$ et de classe $C^1$ sur $D$ qui est fermée est exacte.
\end{theorem}

Nous allons prouver ce théorème dans un cas un peu moins général : celui d'un domaine étoilé de \( \eR^2\) plutôt que simplement connexe de \( \eR^n\).

\begin{theorem} \label{ThoMSofFxL}
Soit $D\subset\eR^2$, une ouvert étoilé, et $\omega$, une $1$-forme fermée de classe $C^1$. Alors $\omega$ est exacte.
\end{theorem}
\begin{proof}

Soit $D\subset\eR^2$, un ouvert étoilé par rapport à l'origine. Soient $f\colon D\to \eR$, $g\colon D\to \eR$, des fonctions de classe $C^1$ telles que
\begin{equation}
	\frac{ \partial f }{ \partial y }=\frac{ \partial g }{ \partial x }
\end{equation}
sur $D$, et
\begin{equation}		\label{EqIMDefFformI33}
	F(x,y)=\int_0^1\big[  f(tx,ty)x+g(tx,ty)y  \big]dt
\end{equation}
pour tout $(x,y)\in D$. 

Étant donné que nous ne définissons $F(x,y)$ que pour des $(x,y)\in D$, la fonction $t\mapsto f(tx,ty)$ est $C^1$ sur tout le compact $[0,1]$ et aucune divergence de l'intégrale n'est à craindre. Nous sommes donc dans le cadre de la proposition \ref{PropDerrSSIntegraleDSD}, et nous pouvons dériver sous le signe intégral.

Nous calculons, en utilisant la règle de dérivation de fonctions composées
\begin{equation}		\label{EqIMI33dsdsFlolo}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }(x,t)	&=\int_0^1\left[   f\frac{ \partial f }{ \partial x }(tx,ty)x+f(tx,ty)+t\frac{ \partial g }{ \partial x }(tx,ty)y  \right]dt\\
		&=\int_0^1\left[ t\Big( x\frac{ \partial f }{ \partial x }(tx,ty)+y\frac{ \partial f }{ \partial y }(tx,ty) \Big)+f(tx,ty) \right]dt
	\end{aligned}
\end{equation}
où nous avons utilisé l'hypothèse $\partial_yf=\partial_xg$. Ce qui se trouve dans la parenthèse n'est autre que $\partial_t\big( f(tx,ty) \big)$, plus précisément, si nous posons $\mF(x,y,t)=f(tx,ty)$, nous avons
\begin{equation}
	\frac{ \partial \mF }{ \partial t }(x,y,t)= x\frac{ \partial f }{ \partial x }(tx,ty)+y\frac{ \partial f }{ \partial y }(tx,ty).
\end{equation}
En recopiant le résultat \eqref{EqIMI33dsdsFlolo} en termes de $\mF$, nous avons
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }(x,t)	&=\int_0^1\left( t\frac{ \partial \mF }{ \partial t }(x,y,t)+\mF(x,y,t) \right)dt\\
		&=\int_0^1\partial_t\big( t\mF(x,y,t) \big)dt\\
		&=\big[ f\mF(x,y,t) \big]_0^1\\
		&=\mF(x,y,1)\\
		&=f(x,y).
	\end{aligned}
\end{equation}
Le résultat correspondant pour $\frac{ \partial F }{ \partial y }(x,y)=g(x,y)$ s'obtient de la même manière. Nous avons donc obtenu que
\begin{equation}		\label{EqIMFormI33Fffdd}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }&=f,  &\text{et}&& \frac{ \partial F }{ \partial y }=g.
	\end{aligned}
\end{equation}
En ayant prouvé cela, nous avons prouvé que si $\omega=fdx+gdy$ avec $\partial_yf=\partial_xg$, alors $\omega=dF$ où $F$ est définie par \eqref{EqIMDefFformI33}.
\end{proof}

\begin{proof}[Démonstration alternative du théorème \ref{ThoMSofFxL}]
Nous posons $u=tx$ et $v=ty$, ainsi que $\mF(x,y,t)=f(u,v)$ et $\mG(x,y,t)=g(u,v)$. Avec cette notation, nous avons $F(x,y)=\int_0^1\big( x\mF(x,y,t)+y\mG(x,y,t) \big)dt$, et
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial \mF }{ \partial x }&=\frac{ \partial f }{ \partial u }\frac{ \partial u }{ \partial x }+\frac{ \partial f }{ \partial v }\frac{ \partial v }{ \partial x }=t\frac{ \partial f }{ \partial u },\\
		\frac{ \partial \mG }{ \partial x }&=t\frac{ \partial g }{ \partial u }.
	\end{aligned}
\end{equation}
Ainsi,
\begin{equation}
	\begin{aligned}[]
		\frac{ \partial F }{ \partial x }	&=\int_0^1\left( x\frac{ \partial \mF }{ \partial x }+\mF+y\frac{ \partial G }{ \partial x } \right)dt\\
							&=\int_0^1\left( xt\frac{ \partial f }{ \partial u } +\mF+yt\frac{ \partial g }{ \partial u } \right)dt\\
							&=\int_0^1\left[  t\left( x\frac{ \partial f }{ \partial u }+y\frac{ \partial f }{ \partial v } \right)+\mF  \right]dt.
	\end{aligned}
\end{equation}
où nous avons utilisé le fait que, par hypothèse, $\frac{ \partial g }{ \partial u }=\frac{ \partial f }{ \partial v }$. Nous calculons par ailleurs que
\begin{equation}
	\frac{ \partial F }{ \partial t }=\frac{ \partial f }{ \partial u }\frac{ \partial u }{ \partial t }+\frac{ \partial f }{ \partial v }\frac{ \partial v }{ \partial t }=x\frac{ \partial f }{ \partial u }+y\frac{ \partial f }{ \partial v }.
\end{equation}
Donc, nous avons
\begin{equation}
	\frac{ \partial F }{ \partial x }=\int_0^1\left( t\frac{ \partial \mF }{ \partial t }+\mF \right)dt=\int_0^1\frac{ \partial  }{ \partial t }(t\mF)dt.
\end{equation}
Par conséquent,
\begin{equation}
	\frac{ \partial F }{ \partial x }=[t\mF]_0^1=\mF(x,y,1)=f(x,y).
\end{equation}
Le même genre de calculs fournit $\frac{ \partial F }{ \partial y }=g(x,y)$.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Théorème d'Abel angulaire}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Abel angulaire\cite{KXjFWKA}]   \label{ThoTGjmeen}
    Soit \( \sum_{n}a_nz^n\) une série entière de rayon de convergence plus grand ou égal à \( 1\) et de somme \( f\). Soit \( \theta_0\in\mathopen[ 0 , \frac{ \pi }{2} \mathclose[\). Nous posons
    \begin{equation}
        \Delta_{\theta_0}=\{ z=1-\rho e^{i\varphi}\tq \rho>0,\varphi\in\mathopen[ \theta_0 , \theta_0 \mathclose],| z |<1 \}.
    \end{equation}
    Nous supposons de plus que \( \sum_na_n\) converge. Alors
    \begin{equation}
        \lim_{\substack{z\to1\\z\in\Delta_0}}f(z)=\sum_{k=0}^{\infty}a_k.
    \end{equation}
\end{theorem}
\index{Abel!angulaire}
\index{convergence!suite numérique!Abel angulaire}
\index{somme partielles!Abel angulaire}
\index{série!entière!Abel angulaire}

\begin{proof}

    Le résultat de ce théorème est que l'on peut calculer la limite \( z\to 1\) avec des chemins contenus dans un domaine de la forme de celui dessiné à la figure \ref{LabelFigJGuKEjH}. % From file JGuKEjH
    \newcommand{\CaptionFigJGuKEjH}{La zone dans laquelle peut être le chemin qui va vers \( z=1\).}
    \input{Fig_JGuKEjH.pstricks}

    De façon très classique nous posons
    \begin{equation}
        \begin{aligned}[]
            S&=\sum_{k=0}^{\infty}a_k&S_n&=\sum_{k=0}^na_k,
        \end{aligned}
    \end{equation}
    et \( R_n=S-S_n\). En particulier \( a_n=R_{n-1}-R_n\). 

    Le but du théorème est de montrer que \( \sum a_nz^n\) converge vers \( S\) lorsque \( z\) converge vers \( 1\) à l'intérieur de \( \Delta_{\theta_0}\). Pour cela nous calculons pour un \( N\) donné la différence \( \sum_{n=0}^{N}a_nz^n-S_N\) en triant les termes par ordre de \( R_n\), en isolant le terme \( R_0\) et le terme \( R_N\) :
    \begin{subequations}
        \begin{align}
            \sum_{n=0}^Na_nz^n-S_N&=\sum_{n=1}^Na_n(z^n-1)\\
            &=\sum_{n=1}^N(R_{n-1}-R_n)(z^n-1)\\
            &=R_0(z-1)+\sum_{n=1}^{N-1}R_n(z^{n+1}-1-z^n+1)+R_N(z^N-1)\\
            &=R_0(z-1)+\sum_{n=1}^{N-1}R_nz^n(z-1)+R_N(z^N-1)\\
            &=(z-1)\sum_{n=0}^{N-1}R_nz^n+R_N(z^N-1).
        \end{align}
    \end{subequations}
    Cela est valable pour tout \( N\) et \( | z |<1\). Nous avons donc
    \begin{equation}
        \sum_{n=0}^Na_nz^n-S_N=(z-1)\sum_{n=0}^{N-1}R_nz^n+R_N(z^N-1).
    \end{equation}
    Par hypothèse nous avons \( \lim_{N\to \infty} R_N=0\). Et de plus le membre de gauche converge parce que chacun des deux termes converge séparément. En passant à la limite nous avons pour tout \( | z |<1\) :
    \begin{equation}
        f(z)-S=(z-1)\sum_{n=0}^{\infty}R_nz^n.
    \end{equation}
    Nous voudrions étudier le comportement de la différence \( f(z)-S\) lorsque \( z\) tend vers \( 1\). Pour cela nous nous fixons \( \epsilon>0\) et \( N\geq 1\) tel que \( | R_n |<\epsilon\) dès que \( n\geq N\). Alors pour tout \( | z |<1\) nous avons
    \begin{subequations}
        \begin{align}
            | f(z)-S |&\leq | z-1 |\left( \sum_{n=0}^N| R_n | \underbrace{|z^n |}_{\leq 1} +\sum_{n=N+1}^{\infty}\underbrace{| R_n |}_{\leq \epsilon} |z^n | \right)\\
            &\leq | z-1 |\sum_{n=0}^N| R_n |+\epsilon\frac{ | z-1 | }{ 1-| z | }
        \end{align}
    \end{subequations}
    où nous avons utilisé la somme de la série géométrique \eqref{EqASYTiCK} et l'égalité \( | z^n |=| z |^n\). Avant de nous particulariser à \( z\in\Delta_{\theta_0}\) nous devons anticiper un problème au dénominateur en multipliant par le binôme conjugué :
    \begin{equation}
        \frac{ | z-1 | }{ 1-| z | }=\frac{ | z-1 |(1+| z |) }{ 1-| z |^2 }.
    \end{equation}
    C'est maintenant que nous nous particularisons à \( z\in\Delta_{\theta_0}\) en posant \( z=\rho e^{i\varphi}\) et en remarquant que \( | z |^2=1-2\rho\cos(\varphi)+\rho^2\). Nous avons le calcul suivant :
    \begin{subequations}
        \begin{align}
            \frac{ | z-1 | }{ 1-| z | }&=\frac{ \rho(1+| z |) }{ 2\rho\cos(\varphi)-\rho^2 }\\
            &=\frac{ 1+| z | }{ 2\cos(\varphi)-\rho}\\
            &\leq\frac{ 2 }{ 2\cos(\varphi)-\rho }\\
            &\leq\frac{ 2 }{ 2\cos(\varphi)-\cos(\theta_0) }\\
            &\leq\frac{ 2 }{ 2\cos(\theta_0)-\cos(\theta_0) }\\
            &=\frac{ 2 }{ \cos(\theta_0) }.
        \end{align}
    \end{subequations}
    Quelque justifications.
    \begin{itemize}
        \item Vu que nous avons dans l'idée de faire \( \rho\to 0\) nous supposons que \( \rho<\cos(\theta_0)\).
        \item Nous avons \( \cos(\varphi)>\cos(\theta_0)\) parce que \( z\) est dans \( \Delta_{\theta_0}\).
    \end{itemize}
    Nous avons donc, pour tout \( z\in\Delta_{\theta_0}\) que
    \begin{equation}
        | f(z)-S |\leq | z-1 |\sum_{n=0}^N| R_n |+\epsilon\frac{ 2 }{ \cos(\theta_0) }.
    \end{equation}
    Il suffit de prendre \( \rho\) assez petit pour que 
    \begin{equation}
        | z-1 |\sum_{n=0}^N| R_n |<\epsilon
    \end{equation}
    et nous avons
    \begin{equation}
        | f(z)-S |\leq \epsilon\left( 1+\frac{ 2 }{ \cos(\theta_0) } \right).
    \end{equation}
    Nous avons donc bien \( \lim_{\substack{z\to 1\\z\in\Delta_0}}f(z)=S\), comme nous le voulions.
\end{proof}

La réciproque du théorème d'Abel angulaire est que si \( f(z)=\sum_na_nz^n\) sur \( B(0,1)\) se prolonge par continuité en \( z=1\) alors cette prolongation se fait par \( f(1)=\sum_na_n\). Cela est faux comme le montre l'exemple suivant.

\begin{example}
    Nous considérons la série entière \( \sum_{n=0}^{\infty}(-1)^nz^n\) qui converge\footnote{C'est la série géométrique de raison \( -z\).} vers
    \begin{equation}
        f(z)=\frac{1}{ 1+z }
    \end{equation}
    sur \( B(0,1)\). De plus nous avons
    \begin{equation}
        \lim_{\substack{z\to 1\\    | z |<1}}\frac{1}{ 1+z }=\frac{ 1 }{2}.
    \end{equation}
    Donc la fonction converge bien vers quelque chose lorsque \( z\) tend vers \( 1\). La fonction \( f\) se prolonge par continuité en \( 1\). Pourtant la série es coefficients \( \sum_n(-1)^n\) ne converge pas.
\end{example}

Le théorème suivant donne une espèce d'inverse au théorème d'Abel angulaire. En effet il dit que si la série converge  en allant vers \( 1\) le long de l'axe réel, alors ça converge vers la somme des coefficients. Il faut cependant une hypothèse en plus sur les \( a_n\).
\begin{theorem}[Théorème taubérien faible\cite{KXjFWKA}]
    Soit \( \sum_na_nz^n\) une série entière de rayon de convergence \( 1\) et de somme \( f\). Nous supposons
    \begin{enumerate}
        \item
            Il existe \( S\in \eC\) tel que \( \lim_{\substack{x\to 1\\x\in\mathopen] -1 , 1 \mathclose[}}f(x)=S\).
            \item
                \( \lim_{n\to \infty} na_n=0\).
    \end{enumerate}
    Alors la série \( \sum_{n=0}^{\infty}a_n\) converge et vaut \( S\).
\end{theorem}
\index{théorème!taubérien faible}

\begin{proof}
    Nous notons \( S_n=\sum_{k=0}a_k\) et \( M=\sup_{k\geq 1}k| a_k |\), qui est fini par hypothèse. Pour \( x\in \mathopen] 0 , 1 \mathclose[\) et \( n\geq 0\) nous avons
    \begin{equation}
        S_n-f(x)=\sum_{k=1}^na_k-\sum_{k=1}^na_kx^k-\sum_{k=n+1}^{\infty}a_kx^k=\sum_{k=1}^na_k(1-x^k)-\sum_{k=n+1}^{\infty}a_kx^k.
    \end{equation}
    Nous utilisons la série géométrique sous la forme \( 1-x^k=(1-x)\sum_{i=0}^nx^i\) pour écrire
    \begin{subequations}
        \begin{align}
            S_n-f(x)&=\sum_{k=1}^na_k(1-x)\underbrace{\sum_{i=0}^{k-1}x^i}_{\leq k}-\sum_{k=n+1}^{\infty}a_kx^k\\
            &\leq\sum_{k=1}^nka_k(1-x)-\sum_{k=n+1}^{\infty}a_kx^k,
        \end{align}
    \end{subequations}
    donc en passant à la norme
    \begin{subequations}
        \begin{align}
            \big| S_n-f(x) \big|&\leq (1-x)Mn+\sum_{k=n+1}| a_k |x^k\\
            &\leq (1-x)Mn+\sum_{k=n+1}^{\infty}\underbrace{\frac{ k }{ n }| a_k |}_{\leq M/n}x^k\\
            &\leq (1-x)Mn+\frac{ M }{ n }\sum_{k=n+1}^{\infty}x^k\\
            &\leq (1-x)Mn+\frac{ M }{ n }\frac{1}{ 1-x }.
        \end{align}
    \end{subequations}
    Ce que nous cherchons à étudier est le comportement \( x\to 1\) et montrer que \( S_n\to S\), ce qui nous incite à calculer \( | S_n-f(1-\frac{ \epsilon }{n  }) |\) avec \( 0<\epsilon<1\) :
    \begin{equation}
        \big| S_n-f\big( 1-\frac{ \epsilon }{ n } \big) \big|\leq \epsilon M+\epsilon.
    \end{equation}
    Nous choisissons \( N_1\) tel que \( \frac{ M }{ n }\leq \epsilon^2\) dès que \( n\geq N_1\). En sus nous savons que 
    \begin{equation}
        \lim_{\epsilon\to 0}f(1-\epsilon)=S.
    \end{equation}
    Nous choisissons \( N_2\) de telle sorte à avoir
    \begin{equation}
        \left| f\left( 1-\frac{ \epsilon }{ n } \right)-S \right| <\epsilon,
    \end{equation}
    et en prenant \( n\geq\max(N_1,N_2)\) nous avons
    \begin{equation}
        | S_n-S |\leq \left| S_n-f\left( 1-\frac{ \epsilon }{ n } \right) \right| +\left| f\left( 1-\frac{ \epsilon }{ n } \right)-S \right|  \leq \epsilon M+2\epsilon.
    \end{equation}
    Il suffit de choisit \( \epsilon\) suffisamment petit (en particulier pour que \( \epsilon M\) soit petit) pour montrer que \( | S_n-S |\) est borné par un nombre arbitrairement petit.
\end{proof}



%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Passage à la limite sous le signe intégral}
%---------------------------------------------------------------------------------------------------------------------------

Un autre résultat très important pour l'étude de l'intégrabilité est le théorème de la \defe{convergence dominée de Lebesgue}{}:
\begin{theorem}
	Soit $E\subset \eR^n$ un ensemble mesurable et $\{ f_k \}$, une suite de fonctions intégrables sur $E$ qui converge simplement vers une fonction $f\colon E\to \overline{ \eR }$. Supposons qu'il existe une fonction $g$ intégrable sur $E$ telle que pour tout $k$,
\begin{equation}
	| f(x) |\leq g(x)
\end{equation}
pour tout $x\in E$. Alors $f$ est intégrable sur $E$ et 
\begin{equation}
	\int_Ef=\lim_{k\to\infty}\int_Ef_k.
\end{equation}
\end{theorem}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Intégrale en dimension un}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[Critère de comparaison]
Soit $f$ mesurable sur $]a,\infty[$ et bornée sur tout $]a,b]$, et supposons qu'il existe un $X_0\geq a$, tel que sur $]X_0,\infty[$,
\begin{equation}
	| f(x) |\leq g(x)
\end{equation}
où $g(x)$ est intégrable. Alors $f(x)$ est intégrable sur $]a,\infty[$.
\end{proposition}

\begin{corollary}[Critère d'équivalence]
Soient $f$ et $g$ des fonctions mesurables et positives ou nulles sur $]a,\infty[$, bornées sur tout $]a,b]$, telles que 
\begin{equation}
	\lim_{x\to\infty}\frac{ f(x) }{ g(x) }=L
\end{equation}
existe dans $\bar\eR$.
\begin{enumerate}
\item Si $L\neq\infty$ et $\int_{a}^{\infty}g(x)$ existe, alors $\int_a^{\infty}f(x)dx$ existe,
\item Si $L\neq 0$ et si $\int_a^{\infty}f(x)dx$ existe, alors $\int_a^{\infty}g(x)dx$ existe,
\end{enumerate}
\end{corollary}

\begin{corollary}[Critère des fonctions test]			\label{CorCritFonsTest}
Soit $f(x)$ une fonction mesurable et positive ou nulle sur $]a,\infty[$ et bornée pour tout $]a,b]$. Nous posons
\begin{equation}
	L(\alpha)=\lim_{x\to\infty}x^{\alpha}f(x),
\end{equation}
et nous supposons qu'elle existe.
\begin{enumerate}
\item Si il existe $\alpha>1$ tel que $L(\alpha)\neq\infty$, alors $\int_a^{\infty}f(x)dx$ existe,
\item Si il existe $\alpha\leq1$ et $L(\alpha)\neq 0$, alors $\int_a^{\infty}f(x)dx$ n'existe pas.
\end{enumerate}
\end{corollary}

\begin{corollary}		\label{CorAlphaLCasInteabf}
	Soit $f\colon ]a,b]\to \eR$ une fonction mesurable, positive ou nulle, et bornée sur $[a+\epsilon,b]$ $\forall\epsilon>0$. Si $\lim_{x\to a}(x-a)^{\alpha}f(x)=L$ existe, alors
	\begin{enumerate}
		\item Si $\alpha<1$ et $L\neq\infty$, alors $\int_a^bf(x)dx$ existe,
		\item Si $\alpha\geq 1$ et $L\neq 0$, alors $\int_a^bf(x)dx$ n'existe pas.
	\end{enumerate}
\end{corollary}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Intégrales convergentes}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Soit $f$, une fonction mesurable sur $[a,\infty[$, bornée sur tout intervalle $[a,b]$. On dit que l'intégrale
    \begin{equation}
        \int_a^{\infty}f(x)dx
    \end{equation}
    \defe{converge}{intégrale!convergente} si la limite
    \begin{equation}		\label{EqDEfConvergeZeroInftX}
        \lim_{X\to\infty}\int_a^{X}f
    \end{equation}
    existe et est finie.
\end{definition}
