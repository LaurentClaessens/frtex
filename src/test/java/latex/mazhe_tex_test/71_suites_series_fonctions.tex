% This is part of Mes notes de mathématique
% Copyright (c) 2011-2016
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Propriétés}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[\cite{ooGMNAooSLnIio}]      \label{THOooVADUooLiRfGK}
    Soient deux espaces mesurables \( (S_1,\tribF_1)\) et \( (S_2,\tribF_2)\) ainsi qu'une application mesurable \( \varphi\colon S_1\to S_2\). Soit encore \( \mu\), une mesure positive sur \( (S_1,\tribF_1)\).

    Si \( f\colon S_2\to\bar \eR\) ou \( \eC\) est mesurable alors,
    \begin{enumerate}
        \item      \label{ItemooKMBIooZpHJSS}
            \( f\) est \( \varphi(\mu)\)-intégrale si et seulement si \( f\circ\varphi\) est \( \mu\)-intégrable.
        \item       \label{ItemooLAPYooUreDEl}
            dans le cas où \( f\) est \( \varphi(\mu)\)-intégrable, nous avons
            \begin{equation}        \label{EqooSOHXooXSbdoy}
                \int_{S_2}fd\big( \varphi(\mu) \big)=\int_{S_1}(f\circ\varphi)d\mu.
            \end{equation}
    \end{enumerate}
\end{theorem}

\begin{proof}
    L'intégrabilité est la définition \ref{DefTCXooAstMYl}, et demande que \( | f |\) soit intégrable. L'égalité \eqref{EqooSOHXooXSbdoy} a un sens si les deux membres sont infinis. Tant que les fonctions considérées sont positives, le point \ref{ItemooKMBIooZpHJSS} est immédiat. Ce n'est qu'au moment où les fonctions considérées deviennent à valeurs dans \( \eC\) ou \( \eR\) que l'intégrabilité de \( | f |\) commence à jouer parce qu'il faut que \(  f^+  \) et \( f^-\) soient séparément intégrables.

    Nous allons prouver la formule \eqref{EqooSOHXooXSbdoy} pour des fonctions de plus en plis générales. Pour la suite nous notons \( \mu'=\varphi(\mu)\).

    \begin{subproof}
        \item[Pour \( f=\mtu_B\), \( B \) mesurable]
            Soit \( B\in\tribF_2 \). Nous avons \( \mtu_B\circ\varphi=\mtu_{\varphi^{-1}(B)}\). Donc en utilisant le lemme \ref{LemooPJLNooVKrBhN} nous avons
            \begin{equation}
                \int_{S_2}\mtu_{B}d\mu'=\mu'(B)=\mu\big( \varphi^{-1}(B) \big)=\int_{S_1}\mtu_{\varphi^{-1}(B)}d\mu=\int_{S_1}(\mtu_B\circ \varphi)d\mu.
            \end{equation}
        \item[\( f\) est étagée positive]

            La fonction \( f\) peut être écrite sous la forme
            \begin{equation}
                f=\sum_{k=1}^na_k\mtu_{B_k}
            \end{equation}
            avec \( B_k\in\tribF_2\) et \( a_k\in \eR^+\). Nous avons alors, en utilisant la sous-additivité de l'intégrale du théorème \ref{ThoooCZCXooVvNcFD}\ref{ITEMooOJRAooQkoQyD},
            \begin{subequations}
                \begin{align}
                    \int_{S_2}fd\mu'&=\sum_ka_k\int_{S_2}\mtu_{B_k}d\mu'\\
                    &=\sum_ka_k\int_{S_1}(\mtu_{B_k}\circ\varphi)d\mu\\
                    &=\int_{S_1}\Big( \sum_ka_k\mtu_{B_k} \Big)\circ \varphi d\mu\\
                    &=\int_{S_1}(f\circ\varphi)d\mu.
                \end{align}
            \end{subequations}
        \item[\( f\) à valeurs dans \( \bar \eR^+\)]

            Vu que \( f\) est mesurable, par le théorème \ref{THOooXHIVooKUddLi} il existe une suite croissante de fonctions étagées positives convergeant vers \( f\). Soit donc cette suite, \( f_n\colon S_2\to \eR^+\). Les fonction s\( f_n\circ\varphi\) sont étagées et positives et nous avons aussi la limite ponctuelle et croissante \( f_n\circ\varphi\to f\circ\varphi\) parce que \( \varphi\) est continue. Le théorème de la convergence monotone (théorème \ref{ThoRRDooFUvEAN}) permet d'écrire ceci :
            \begin{equation}
                \int_{S_2}fd\mu'=\lim\int_{S_2}f_nd\mu'= \lim\int_{S_1}(f_n\circ\varphi)d\mu=\int_{S_1}(f\circ\varphi)d\mu.
            \end{equation}
        \item[Pour \( f\colon S_2\to \bar \eR\) ou \( \eC\) ]
            
            C'est maintenant que l'intégrabilité va jouer. Nous avons \( | f |\circ\varphi=| f\circ\varphi |\), donc
            \begin{equation}
                \int_{S_2}| f |d\mu'=\int_{S_1}| f |\circ\varphi d\mu=\int_{S_1}| f\circ \varphi |d\mu,
            \end{equation}
            ce qui montre que \( f\) est \( \mu'\)-intégrable si et seulement si \( f\circ\varphi\) est \( \mu\)-intégrable.

            De plus si \(f=f^+-f^- \) alors \( f^+\circ\varphi=(f\circ\varphi)^+\), \( f^-\circ\varphi=(f\circ\varphi)^-\), et de façon similaire pour les parties imaginaires et réelles.
    \end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Primitives et intégrales}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{enumerate}
    \item
        L'existence d'une primitive pour toute fonction continue est le théorème \ref{ThoEOMRooZPUfJg}.
    \item
        La définition d'une primitive est la définition \ref{DefXVMVooWhsfuI}.
\end{enumerate}

En termes de notations, si \( a<b\) nous posons
\begin{equation}
    \int_a^bf(t)dt=\int_{\mathopen[ a , b \mathclose]}f.
\end{equation}
Si par contre \( a>b\) nous posons \( \int_a^bf=-\int_b^af\).

\begin{proposition}[Primitive et intégrale] \label{PropEZFRsMj}
    Soit \( f\) une fonction intégrable sur \( \mathopen[ a , b \mathclose]\) et continue sur \( \mathopen] a , b \mathclose[\). Alors la fonction
    \begin{equation}
        \begin{aligned}
            F\colon \mathopen[ a , b \mathclose]&\to \eR \\
            x&\mapsto \int_{\mathopen[ a , x \mathclose]}f(t)dt.
        \end{aligned}
    \end{equation}
est une primitive de \( f\) sur \( \mathopen] a , b \mathclose[\).
\end{proposition}
\index{primitive!et intégrale}

\begin{proof}
Nous devons prouver que \( F\) est dérivable et que pour tout \( x_0\in\mathopen] a , b \mathclose[\) nous ayons \( F'(x_0)=f(x_0)\). Soit \( \epsilon>0\). Par continuité de \( f\) en \( x_0\), il existe une fonction \( \alpha\colon \eR\to \eR\) telle que
    \begin{equation}
        f(x_0+h)=f(x_0)+\alpha(h)
    \end{equation}
    avec \( \lim_{h\to 0} \alpha(h)=0\). De plus il existe un \( \delta>0\) tel que \( |\alpha(h)|<\epsilon\) pour tout \( h<\delta\). À partir de maintenant nous ne considérons plus que de tels \( h\).

    Nous calculons la dérivée de \( F\) en \( x_0\). Pour cela,
    \begin{subequations}
        \begin{align}
            F(x_0+h)-F(x_0)&=\int_{x_0}^{x_0+h}f(t)dt\\
        &=\int_0^hf(x_0+t)dt\\
        &=\int_0^h\big[ f(x_0)+\alpha(t) \big]dt\\
        &=hf(x_0)+\int_0^{h}\alpha(t)dt.
        \end{align}
    \end{subequations}
    Nous avons donc, pour tout \( h<\delta\),
    \begin{equation}
        hf(x_0)-h\epsilon\leq F(x_0+h)-F(x_0)\leq hf(x_0)+h\epsilon.
    \end{equation}
    En divisant par \( h\) et en prenant la limite \( h\to 0\),
    \begin{equation}
        F'(x_0)\in B\big( f(x_0),\epsilon \big).
    \end{equation}
    Cela étant valable pour tout \( \epsilon>0\) nous en déduisons que
    \begin{equation}
        F'(x_0)=f(x_0).
    \end{equation}
\end{proof}

\begin{remark}
    Le lien entre primitive et intégrale est fondamentalement lié à l'invariance par translation de la mesure de Lebesgue, et non à la construction précise de cette mesure. Mais en même temps, la mesure de Lebesgue est l'unique à être invariante par translation.
\end{remark}

\begin{remark}
    Une primitive est forcément une fonction continue parce qu'une primitive est dérivable.
\end{remark}

Ce petit résultat nous donne une façon «pratique» de calculer des intégrales en cherchant des primitives. Nous rappelons qu'en vertu du corollaire \ref{CorZeroCst}, une fonction ne possède qu'une seule primitive à constante près.

\begin{proposition}[\cite{ooIEJXooIYpBbd}]      \label{PROPooWZFGooMVLtFz}
    Soient des fonction \( f,g\colon I\to \eR\) de classe \(  C^{1}\) sur l'ouvert \( I\) de \( \eR\) telles que \( f^2+g^2=1\). Soit \( t_0\in I\) et \( \theta_0\) tel que \( f(t_0)=\cos(\theta_0)\) et \( g(t_0)=\sin(\theta_0)\).

    Alors il existe une unique fonction continue \( \theta\colon I\to \eR\) telle que 
    \begin{subequations}
        \begin{numcases}{}
            \theta(t_0)=\theta_0\\
            f=\cos\circ \theta\\
            g=\sin\circ \theta.
        \end{numcases}
    \end{subequations}
\end{proposition}

\begin{proof}
    Nous commençons par l'existence, en passant par les nombres complexes. Soit \( h\colon I\to \eC\) définie par \( h=f+ig\). Nous avons \( h\bar h=1\) et nous définissons
    \begin{equation}
        \theta(t)=\theta_0-i\int_{t_0}^th'(s)\overline{ h(s) }ds.
    \end{equation}
    Cette intégrale existe pour tout \( t\) parce que les fonctions \( f\) et \( g\) étant de classe \(  C^{\infty}\), elles sont bornées sur le compact \( \mathopen[ t_0 , t  \mathclose]\). De plus \( \theta\) est une fonction continue parce que c'est une primitive (proposition \ref{PropEZFRsMj})\footnote{En réalité nous appliquons la proposition \ref{PropEQRooQXazLz} à chacune des parties réelles et imaginaires de la fonction \( s\mapsto h'(s)\overline{ h(s) }\).}.

    La dérivée de \( \theta\) est la fonction \( s\mapsto -i h'(s)\overline{ h(s) }\).

    Calculons 
    \begin{equation}
        \Dsdd{ h e^{-i\theta} }{t}{0}= e^{-i\theta}(h'-h\theta')= e^{-i\theta}(h'-ih(-i)h'\bar h)=0.
    \end{equation}
    Par conséquent il existe \( c\in \eC\) tel que \( h e^{-i\theta}=c\). Mais \( h(t_0)=f(t_0)+ig(t_0)=\cos(\theta_0)+i\sin(\theta_0)= e^{i\theta_0}\), du coup
    \begin{equation}
        h(t_0) e^{-i\theta(t_0)}=c
    \end{equation}
    donne immédiatement \( c=1\), ou encore \(  e^{i\theta(t)}=h(t)\), c'est à dire que
    \begin{equation}
        f+ig=\cos\circ\theta+i\sin\circ\theta,
    \end{equation}
    ce qu'il fallait pour l'existence.

    Pour l'unicité nous supposons avoir une autre fonction, \(\alpha\) qui satisfait aux exigences. Pour tout \( t\in I\) nous avons
    \begin{equation}
        e^{i\theta(t)}= e^{i\alpha(t)}.
    \end{equation}
    Il existe donc une fonction \( n\colon I\to \eN\) telle que \( \theta(t)=\alpha(t)+2n(t)\pi\). Par continuité de \( \theta\) et \( \alpha\), la fonction \( n\) doit être constante, mais vu que \( \theta(t_0)=\alpha(t_0)\) nous avons \( n=1\).
\end{proof}

Le théorème suivant est à utiliser pour calculer des intégrales des fonctions réelle lorsqu'on a des primitives sur un domaine strictement plus large que le domaine sur lequel nous voulons intégrer.
\begin{theorem}[Théorème fondamental du calcul intégral]    \label{ThoRWXooTqHGbC}
    Soit \( f\) une fonction continue sur un intervalle ouvert \( I\) contenant strictement l'intervalle \( \mathopen[ a , b \mathclose]\subset \eR\) et \( F\) une primitive de \( f\) sur \( I\). Alors
    \begin{equation}
        \int_a^bf(t)dt=F(b)-F(a).
    \end{equation}
\end{theorem}
\index{théorème!fondamental du calcul intégral}
Une version pour les intégrales impropres sera donnée au corollaire \ref{CorMUIooXREleR}.

\begin{proof}
    Nous avons vu par la proposition \ref{PropEZFRsMj} que la fonction
    \begin{equation}
        \begin{aligned}
            \tilde F\colon \mathopen[ a , b \mathclose]&\to \eR \\
            x&\mapsto  \int_a^xf(t)dt
        \end{aligned}
    \end{equation}
    était une primitive de \( f\); c'est même l'unique\footnote{Corollaire \ref{CorZeroCst}.} primitive de \( f\) sur \( \mathopen[ a , b \mathclose]\) à s'annuler pour \( x=a\). Nous avons évidemment
    \begin{equation}
        \int_a^bf(t)dt=\tilde F(b).
    \end{equation}
    Si \( F\) est une primitive quelconque, il suffit de soustraire sa valeur en \( x=a\) : \( \tilde F(x)=F(x)-F(a)\) et donc
    \begin{equation}
        \int_a^bf(t)dt=\tilde F(b)=F(b)-F(a),
    \end{equation}
    comme il fallait le prouver.
\end{proof}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Primitives et intégrales}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[Primitive]
    Soit une fonction \( f\) définie sur un intervalle \( I\). Une \defe{primitive}{primitive} de \( f\) sur \( I\) est une fonction définie sur \( I\) dont la dérivée est \( f\).
\end{definition}

Les deux propriétés fondamentales sont les suivantes.
\begin{proposition}
    À propos de primitives.
    \begin{enumerate}
        \item
            Toute fonction continue sur un intervalle admet une primitive (sur cet intervalle).
        \item
            Deux primitives d'une même fonction sur le m\^eme intervalle ne diffèrent que d'une constante.
    \end{enumerate}
\end{proposition}

\begin{proof}
    La première partie est relativement compliquée et nous ne la traitons pas ici. En ce qui concerne la seconde partie, supposons que \( F_1\) et \( F_2\) soient deux primitives de la fonction \( f\) sur l'intervalle \( I\). Alors \( (F_1-F_2)'=f-f=0\). La fonction \( F_1-F_2\) est donc une fonction dont la dérivée est nulle; elle est donc constante. Nous avons donc \( F_1-F_2=c\) pour un certain \( c\in \eR\).
\end{proof}

Si \( f\) est une fonction définie sur un intervalle \( I\) et y admettant des primitives, nous notons
\begin{equation}
    \int f(x)dx
\end{equation}
l'ensemble des primitives de \( f\) sur \( I\) :
\begin{equation}
    \int f(x)dx=\left\{    F(x)+C\tq C\in \eR   \right\}
\end{equation}
où \( F\) est une quelconque primitive de \( f\).

\begin{example}
    Une primitive bien connue de \(  f\colon x\mapsto x^2 \) est la fonction \( F\colon x\to \frac{ x^3 }{ 3 }\). Nous écrivons donc
    \begin{equation}
        \int x^2dx=\frac{ x^3 }{ 3 }+C.
    \end{equation}
\end{example}

\begin{definition}[Intégrale]\label{defintegrale}
    Soit une fonction \( f\) continue sur un intervalle \( I\) et \( a\neq b\) deux nombres dans \( I\). Si \( F\) est une primitive de \( f\) sur \( I\) nous définissons l'\defe{intégrale}{intégrale!fonction sur un intervalle} de \( a\) à \( b\) de la fonction \( f\) comme étant le nombre \( F(b)-F(a)\).
\end{definition}
En termes de notations, nous posons
\begin{equation}\label{Thfondcalc}
    \int_a^bf(t)dt=\Big[ F(t) \Big]_{t=a}^{t=b}=F(b)-F(a).
\end{equation}

\begin{remark}
  La valeur de l'intégrale ne dépend pas de la primitive qu'on choisi pour le calculer, car si $F_1$ et $F_2$ sont deux primitives de $f$ alors $F_1 = F_2 + C$ et $F_1(b)-F_1(a) = (F_2(b) + C)-(F_2(a)+C) = F_2(b)-F_2(a)$.
\end{remark}

\begin{remark}
  Si l'intervalle d'intégration est réduit à un seul point alors la valeur de l'intégrale est zéro, car $ \int_a^af(t)dt=F(a)-F(a) =0$.
\end{remark}

\begin{remark}
    Conformément à ce que nous montre la figure \ref{LabelFigKKRooHseDzC}, si une fonction continue est positive sur l'intervalle \( \mathopen[ a , b \mathclose]\), alors le nombre \( \int_a^bf(t)dt\) est l'aire de la portion de plan comprise entre les droites verticales \( x=a\), \( x=b\), la courbe représentant la fonction \( f\) et l'axe des abscisses.

    Si la fonction est négative : l'aire est comptée négativement.
\end{remark}

\begin{example} 
    Comme nous le voyons sur le dessin suivant,
    \begin{equation}
        \int_{-3\pi/2}^{3\pi/2}\sin(x)\,dx=0
    \end{equation}
    parce que les deux parties bleues s'annulent avec les deux parties rouges (qui sont comptées comme des aires négatives).
    \begin{center}
       \input{Fig_JSLooFJWXtB.pstricks}
    \end{center}
\end{example}

\begin{remark}
  Toute intégrale d'une fonction impaire sur un intervalle symétrique par rapport à l'origine est nulle. 
\end{remark}

\begin{proposition}[Intégrale et primitive] \label{PropZEJooEsnrgY}
    Soit \( f\) une fonction continue sur l'intervalle \( I\) et un élément \( a\in I\). Soit la fonction
    \begin{equation}
        \begin{aligned}
            F\colon I&\to \eR \\
            x&\mapsto \int_a^xf(t)dt. 
        \end{aligned}
    \end{equation}
    Alors \( F\) est l'unique primitive de \( f\) s'annulant en \( x=a\).
\end{proposition}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Intégrales impropres}
%---------------------------------------------------------------------------------------------------------------------------
\label{SecGAVooBOQddU}

% TODO : l'exemple avec arcsin(1/x)-1/x de la page 
%  http://fr.wikipedia.org/wiki/Intégrale_impropre

\begin{definition}[\cite{TrenchRealAnalisys}]
    Une fonction \( f\colon D\subset\eR\to \eR\) est \defe{localement intégrable}{localement!intégrable} sur un intervalle \( I\) si \( f\) est intégrable sur tout intervalle compact contenu dans \( I\).
\end{definition}
\index{intégrale!impropre}

%Dans \cite{TrenchRealAnalisys}, la proposition \ref{PropCJAooQhNYkp} est prise comme une définition de \( \int_a^bf\) lorsque \( f\) est localement intégrable sur \( \mathopen[ a , b [\). Le point est que lui, il ne passe pas par Lebesgue et la construction abstraite d'intégrale par rapport à une mesure. Nous par contre nous avons déjà une définition de
%\begin{equation}
%    \int_a^bf=\int_{\mathopen[ a , b \mathclose]}f
%\end{equation}
%pour tout choix de \( a\), \( b\) et \( f\), que ce soit borné ou non.

\begin{proposition}     \label{PropCJAooQhNYkp}
    Soit \( f\colon \mathopen[ a , b \mathclose]\to \eR\) une fonction intégrable. Alors
    \begin{equation}    \label{EqPPMooBQDTYl}
        \int_{\mathopen[ a , b \mathclose]}f=\lim_{x\to b^-} \int_a^xf.
    \end{equation}
\end{proposition}

\begin{proof}
    Notons que la valeur de \( f\) en \( b\) n'a strictement aucune importance parce que l'intégrale de Lebesgue ne dépend pas du choix de la valeur de la fonction en un ensemble de mesure nulle; et en même temps la limite à gauche de \eqref{EqPPMooBQDTYl} ne dépend pas non plus de la valeur de \( f\) en \( b\). Bref si \( f\) n'est pas définie en \( b\), nous pouvons poser \( f(b)=42\).

    Notons de plus que du point de vue de l'intégrale de Lebesgue, \( \int_{\mathopen[ a , b \mathclose]}\) et \( \int_{\mathopen[ a , b [}\) sont identiques et valent toutes les deux \( \int_a^b\) (lorsque ça existe).

    Supposons d'abord que \( f\) est positive. Alors nous posons \( f_n=f\mtu_{\mathopen[ a , b-\frac{1}{ n } \mathclose]}\). Ponctuellement nous avons la limite croissante \( f_n\to f\) et de plus
    \begin{equation}
        \lim_{x\to b^-} \int_{\mathopen[ a , x \mathclose]}f=\lim_{n\to \infty} \int_{\mathopen[ a , b \mathclose]}f_n.
    \end{equation}
    Chacun des \( f_n\) est intégrable sur \( \mathopen[ a , b \mathclose]\). Le théorème de Beppo-Levi \ref{ThoRRDooFUvEAN} implique que \( f\) est intégrable sur \( \mathopen[ a , b \mathclose]\) et que
    \begin{equation}
        \lim_{n\to \infty} \int_a^bf_n=\int_a^bf.
    \end{equation}
    Cela montre que dans le cas d'une fonction \( f\) positive nous avons bien \eqref{EqPPMooBQDTYl}.

    Si \( f\) n'est pas positif, alors nous la décomposons en partie positive et négative \( f=f^+-f^{-}\) et par définition de l'intégrale d'une fonction non positive,
    \begin{equation}
        \lim_{x\to b^-} \int_{\mathopen[ a , x [}f=\lim\int f^{+}-\lim\int f^-.
    \end{equation}
\end{proof}

Il peut cependant arriver que la limite \( \lim_{x\to b} \int_a^bf\) existe alors que \( f\) n'est pas intégrable sur \( \mathopen[ a , b \mathclose]\). C'est l'ennui des fonctions non positives. Un exemple classique est
\begin{equation}\label{EqMMVooDSpgfz}
    \int_0^{\infty}\frac{ \sin(t) }{ t }dt
\end{equation}

\begin{definition}[\cite{DWNooWUZxRP}]
    Si
    \begin{equation}
        \lim_{x\to b} \int_a^bf
    \end{equation}
    existe alors nous disons que l'intégrale est \defe{convergente}{intégrale!convergente} en \( b\). Ce procédé de limite est l'intégrale \defe{impropre}{intégrale!impropre} de \( f\) sur \( \mathopen[ a , b \mathclose]\).
\end{definition}

\begin{example}[Intégale impropre]
    Nous considérons la fonction \( f\colon \mathopen[ 0 , \infty [\to \eR\) définie par
    \begin{equation}
        f(x)=\begin{cases}
            \frac{1}{ n }    &   \text{si \( x\in\mathopen[ 2n-2 , 2n-1 [\)}\\
                -\frac{1}{ n }    &    \text{si \( x\in\mathopen[ 2n-1 , 2n [\).}
        \end{cases}
    \end{equation}
    Par la divergence de la série harmonique, \( \int_{0}^{\infty}| f |\) n'existe pas. La fonction \( f\) n'est donc pas intégrable au sens de Lebesgue (définition \ref{DefTCXooAstMYl}).

    Cependant pour tout \( n\) pair nous avons
    \begin{equation}
        \int_0^nf=0.
    \end{equation}
    Du coup pour tout \( x\geq 0\) nous avons
    \begin{equation}
        \int_0^xf=\int_{2n}^xf
    \end{equation}
    où \( 2n\) est le plus grand nombre pair inférieur à \( x\). Nous avons \( | x-2n |\leq 2\) et \( | f(x) |\leq \frac{1}{ n }\) pour \( x\in\mathopen[ 2n , x \mathclose]\). Donc
    \begin{equation}
        \int_{2n}^xf\leq \frac{ 2 }{ n }.
    \end{equation}
    Nous avons par conséquent
    \begin{equation}
        \lim_{x\to \infty} \int_0^xf=0,
    \end{equation}
    ce qui signifie que l'intégrale de \( f\) sur \( \mathopen[ 0 , \infty [\) converge au sens des intégrales impropres.
\end{example}


L'intégrale \eqref{EqMMVooDSpgfz} est une intégrale convergente mais la fonction n'est pas intégrable (parce que pour être intégrale il faut que \( | f |\) soit intégrable). Nous pouvons ainsi dire que cette intégrale converge mais n'existe pas.

Le corollaire suivant nous autorise à utiliser le théorème fondamental du calcul intégral \ref{ThoRWXooTqHGbC} même dans les cas limites.
\begin{corollary}   \label{CorMUIooXREleR}
    Si \( f\) est localement intégrable sur \( \mathopen[ a , b \mathclose]\) et si \( F\) est une primitive de \( f\) sur tout ouvert de \( \mathopen[ a , b \mathclose]\) alors
    \begin{equation}
        \int_a^bf=\lim_{x\to b^-} F(x)-F(a).
    \end{equation}
\end{corollary}
\index{primitive!et intégrale}

\begin{proof}
    Pour chaque \( x\) dans \( \mathopen[ a , b [\) nous avons
    \begin{equation}
        \int_a^xf=F(x)-F(b).
    \end{equation}
    La proposition \ref{PropCJAooQhNYkp} nous explique que la limite \( x\to b^-\) du membre de gauche existe et vaut \( \int_a^bf\). Donc également le membre de droite :
    \begin{equation}
        \int_a^bf=\lim_{x\to b^-} \int_a^xf=\lim_{x\to b^-} F(x)-F(b).
    \end{equation}
\end{proof}

La convergence des intégrales de fonctions \( \frac{1}{ x^{\alpha} }\) en \( 0\) et \( \infty\) est une question classique de l'intégration. De plus ces fonctions servent souvent à utiliser une théorème de comparaison (type intégrale dominée de Lebesgue).
\begin{proposition} \label{PropBKNooPDIPUc}
    Deux intégrales remarquables.
    \begin{enumerate}
        \item
            
            Nous avons 
    \begin{equation}
        \int_0^1\frac{1}{ x^\alpha }=\infty
    \end{equation}
    si et seulement si \( \alpha\geq 1\).

\item

    Nous avons
    \begin{equation}
        \int_1^{\infty}\frac{1}{ x^{\alpha} }=\infty
    \end{equation}
    si et seulement si \( \alpha\leq1\).

    \end{enumerate}
    
\end{proposition}

\begin{proof}
La fonction \( \frac{1}{ x^{\alpha} }\) admet la primitive \( F(x)=\frac{1}{ 1-\alpha }\frac{1}{ x^{\alpha-1} }\) sur tout compact de \( \mathopen] 0 , \infty \mathclose[\). Le corollaire \ref{CorMUIooXREleR} nous permet\footnote{Tout ce que nous avons fait avec la borne \( b\) de l'intégrale \( \int_a^b\) reste valable avec la borne \( a\).} de dire que \( \int_0^1\frac{1}{ x^{\alpha} }\) vaudra
    \begin{equation}
        \lim_{x\to 0-^+} \frac{1}{ 1-\alpha }\frac{1}{ x^{\alpha-1} }.
    \end{equation}
    Cela est strictement plus petit que \( \infty\) si et seulement si \( \alpha<1\).
\end{proof}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Théorème de Fubini}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Fubini-Tonelli et de Fubini}
%---------------------------------------------------------------------------------------------------------------------------

Il existe plusieurs résultats similaires. 
\begin{itemize}
    \item
        le théorème de Fubini-Tonelli \ref{ThoWTMSthY} demande que la fonction soit mesurable et positive;
    \item
        le théorème de Fubini \ref{ThoFubinioYLtPI} demande que la fonction soit intégrable (mais pas spécialement positive);
    \item
        le corollaire \ref{CorTKZKwP} demande l'intégrabilité de la valeur absolue des intégrales partielles pour déduire que la fonction elle-même est intégrable.
\end{itemize}

%TODO : des démonstrations de ces trois théorèmes seraient les bienvenues.

Nous rappelons que \( \eR^n\) muni de la mesure de Lebesgue est un espace mesuré \( \sigma\)-fini, conformément à la définition \ref{DefBTsgznn}.

\begin{theorem}[Fubini-Tonelli\cite{NBoIEXO}]\label{ThoWTMSthY}
    Soient \( (\Omega_i,\tribA_i,\mu_i)\) deux espaces mesurés \( \sigma\)-finis, et \( (\Omega,\tribA,\mu)\) l'espace produit. Soit une fonction \( f\colon \Omega_1\times \Omega_2\to \eR\) une fonction mesurable et positive (valant éventuellement \( \infty\) à certains endroits)
    Alors :
    \begin{enumerate}
        \item
            Les fonction
            \begin{equation}
                F_1\colon x\mapsto \int_{\Omega_2}f(x,y)d\mu_2(y)
            \end{equation}
            et
            \begin{equation}
                F_2\colon y\mapsto \int_{\Omega_1}f(x,y)d\mu_1(x)
            \end{equation}
            sont mesurables.
        \item
            Toutes les intégrales imaginables existent et sont égales :
            \begin{subequations}    \label{EqJRVtOGx}
                \begin{align}
                    \iint_{\Omega_1\times \Omega_2}f(x,y)d(\mu_1\otimes \mu_2)(x,y)&=\int_{\Omega_1}\left[ \int_{\Omega_2}f(x,y)d\mu_2(y) \right]d\mu_1(x)\\
                &=\int_{\Omega_2}\left[ \int_{\Omega_1}f(x,y)d\mu_1(x) \right]d\mu_2(y).
                \end{align}
            \end{subequations}
    \end{enumerate}
\end{theorem}
\index{théorème!Fubini-Tonelli}

\begin{proof}
    Commençons par prouver le théorème dans le cas d'une fonction caractéristique d'un ensemble mesurable : \( f(x,y)=\mtu_{A}(x,y)\) pour un certain ensemble \( A\subset \Omega_1\times \Omega_2\). Dans ce cas,
    \begin{equation}
        F_1(x)=\int_{\Omega_2}\mtu_A(x,y)d\mu_2(y)=\int_{\omega_2}\mtu_{A_1(y)}(x)d\mu_2(y)=\mu_2\big( A_1(x) \big),
    \end{equation}
    et nous avons déjà vu au théorème \ref{ThoCCIsLhO} que cette fonction \( F_1\) était alors mesurable. En utilisant maintenant les égalités \eqref{EqDFxuGtH} ainsi que le fait que \( \mtu_A(x,y)=\mtu_{A_2(x)}(y)\) nous avons
    \begin{subequations}
        \begin{align}
            \iint_{\Omega_1\times \Omega_2}\mtu_A(x,y)d(\mu_1\otimes \mu_2)(x,y)&=(\mu_1\otimes \mu_2)(A)\\
            &=\int_{\Omega_1}\mu_2\big( A_2(x) \big)d\mu_1(x)\\
            &=\int_{\Omega_1}\left[   \int_{\Omega_2}\mtu_{A_2(x)}(y)d\mu_2(y)  \right]d\mu_1(x)\\
            &=\int_{\Omega_1}\left[ \int_{\Omega_2}\mtu_A(x,y)d\mu_2(y) \right]d\mu_1(x).
        \end{align}
    \end{subequations}
    Le théorème étant valable pour les fonctions caractéristiques, il est valable pour les fonctions simples (définition \ref{DefBPCxdel}) par linéarité de l'intégrale.

    Si \( f\) n'est pas une fonction simple, alors la proposition \ref{THOooXHIVooKUddLi} nous donne une suite croissante de fonctions simples et positives convergeant ponctuellement vers \( f\). La partie du théorème sur les fonctions simples dit que pour chaque \( n\) l'intégrale
    \begin{equation}
        \iint_{\Omega_1\times \Omega_2}f_n(x,y)d(\mu_1\otimes\mu_2)(x,y)
    \end{equation}
    peut être décomposée comme il faut en suivant la formule \eqref{EqJRVtOGx}. Il faut pouvoir permuter la limite et l'intégrale dans chacun de cas. D'abord le théorème de la convergence monotone \ref{ThoRRDooFUvEAN} appliqué à l'espace \( \Omega_1\times \Omega_2\) dit que
    \begin{equation}
        \lim_{n\to \infty} \iint_{\Omega_1\times \Omega_2}f_n(x,y)d(\mu_1\otimes \mu_2)(x,y)= \iint_{\Omega_1\times \Omega_2}f(x,y)d(\mu_1\otimes \mu_2)(x,y).
    \end{equation}
    Ensuite, pour chaque \( x\in\Omega_1\), les fonctions
    \begin{equation}
        \sigma_n(y)=\int_{\Omega_1}f_n(x,y)d\mu_1(x)
    \end{equation}
    forment une suite croissante de fonctions mesurables; nous leur appliquons encore le théorème de la convergence monotone :
    \begin{subequations}
        \begin{align}
            \lim_{n\to \infty} \int_{\Omega_2}\left[ \int_{\Omega_1}f_n(x,y)d\mu_1(x) \right]d\mu_2(y)&=\lim_{n\to \infty} \int_{\Omega_2}\sigma_n(y)d\mu_2(y)\\
            &=\int_{\Omega_2}\left[\lim_{n\to \infty} \int_{\Omega_1}f_n(x,y)d\mu_1(x)\right]d\mu_2(y)\\
            &=\int_{\Omega_2}\left[ \int_{\Omega_1}f(x,y)d\mu_1(x) \right]d\mu_2(y)
        \end{align}
    \end{subequations}
    où nous avons utilisé une seconde fois Beppo-Levi.
\end{proof}

\begin{theorem}[Fubini\cite{MesIntProbb}]\label{ThoFubinioYLtPI}
    Soient \( (\Omega_i,\tribA_i,\mu_i)\) deux espaces mesurés \( \sigma\)-finis, et \( (\Omega,\tribA,\mu)\) l'espace produit. Soit 
    \begin{equation}
        f\in L^1\big( (\Omega,\tribA),\eR \big),
    \end{equation}
    c'est à dire une fonction à valeurs réelles mesurable et intégrable sur \( \Omega\). Alors :
    \begin{enumerate}
        \item
            Pour presque tout \( x\in \Omega_1\), la fonction \( y\mapsto f(x,y)\) est \( L^1(\Omega_2)\).
        \item       \label{ITEMooCYMKooUdizni}
            Si nous posons
            \begin{equation}
                \varphi_f(x)=\int_{\Omega_2}f(x,y)d\mu_2(y);
            \end{equation}
            alors \( \varphi_f\in L^1(\Omega_1)\).
        \item   \label{ItemQMWiolgiii}
            Nous avons la formule d'inversion d'intégrale
            \begin{subequations}
                \begin{align}
                \int_{\Omega}fd(\mu_1\otimes \mu_2)&=\int_{\Omega_1}\varphi_fd\mu_1\\
                &=\int_{\Omega_1}\left[ \int_{\Omega_2}f(x,y)d\mu_2(y) \right]d\mu_1(x)\\
                &=\int_{\Omega_2}\left[ \int_{\Omega_1}f(x,y)d\mu_1(x) \right]d\mu_2(y).
                \end{align}
            \end{subequations}
    \end{enumerate}
\end{theorem}
\index{théorème!Fubini!espace mesuré}

Si la fonction \( (x,y)\mapsto f(x)g(y)\) satisfait aux hypothèse du théorème de Fubini alors
\begin{equation}    \label{EqTJEEsJW}
    \int_{\Omega_1\times \Omega_2} f(x)g(y)dx\otimes dy=\left( \int_{\Omega_1}f(x)dx \right)\left( \int_{\Omega_2}g(y)dy \right).
\end{equation}
Le théorème de Fubini est souvent utilisé sous cette forme.

\begin{corollary}           \label{CorTKZKwP}
    Soient \( (\Omega_i,\tribA_i,\mu_i)\) deux espaces mesurés \( \sigma\)-finis, et \( (\Omega,\tribA,\mu)\) l'espace produit\footnote{Définition \ref{DefUMlBCAO}.}. Soit une fonction mesurable \( f\colon \Omega\to \eR\). Alors les conditions suivantes sont équivalentes
    \begin{enumerate}
        \item
            \( f\in L^1(\Omega)\),
        \item
            \begin{equation}
                \int_{\Omega_1}\left[ \int_{\Omega_2}| f |d\mu_2 \right]d\mu_1 <\infty,
            \end{equation}
        \item
            \begin{equation}
                \int_{\Omega_2}\left[ \int_{\Omega_1}| f |d\mu_1 \right]d\mu_2 <\infty.
            \end{equation}
    \end{enumerate}
\end{corollary}
En pratique, lorsqu'on ne sait pas a priori si \( f\) est intégrable sur \( \Omega_1\times \Omega_2\), nous testons l'intégrabilité en chaine de \( | f |\), et si c'est bon, alors nous savons que \( f\) est intégrable sur le produit et qu'on peut permuter les intégrales.

\begin{example}
    Nous montrons que le théorème ne tient pas si une des deux mesures n'est pas \( \sigma\)-finie. Soit \( I=\mathopen[ 0 , 1 \mathclose]\). Nous considérons l'espace mesuré
    \begin{equation}
        (I,\Borelien(I),\lambda)
    \end{equation}
    où \( \Borelien(I)\) est la tribu des boréliens sur \( I\) et \( \lambda\) est la mesure de Lebesgue (qui est $\sigma$-finie). D'autre part nous considérons l'espace mesuré
    \begin{equation}
        (I,\partP(I),m)
    \end{equation}
    où \( \partP(I)\) est l'ensemble des parties de \( I\) et \( m\) est la mesure de comptage. Cette dernière n'est pas $\sigma$-finie parce que les seuls ensembles de mesure finie pour la mesure de comptage sont des ensembles finis, or une union dénombrable d'ensemble finis ne peut pas recouvrir l'intervalle \( I\).

    Nous allons montrer que dans ce cadre, l'intégrale de la fonction indicatrice de la diagonale sur \( I^2\) ne vérifie pas le théorème de Fubini. Étant donné que \( \Borelien(I)\subset\partP(I)\) nous avons
    \begin{equation}
        \Borelien(I^2)\subset\Borelien(I)\otimes\partP(I).
    \end{equation}
    Soit \( \Delta=\{ (x,x)\tq x\in I \}\). La fonction
    \begin{equation}
        \begin{aligned}
            g\colon I^2&\to \eR \\
            (x,y)&\mapsto x-y 
        \end{aligned}
    \end{equation}
    est continue et \( \Delta=g^{-1}(\{ 0 \})\) est donc fermé dans \( I^2\). L'ensemble \( \Delta\) est donc un borélien de \( I^2\) et par conséquent un élément de la tribu \( \Borelien(I)\otimes\partP(I)\). La fonction indicatrice \( \mtu_{\Delta}\) est alors mesurable pour l'espace mesuré
    \begin{equation}
        (I\times I,\Borelien(I)\otimes\partP(I),\lambda\otimes m).
    \end{equation}
    Pour \( x\) fixé nous avons
    \begin{equation}
        \mtu_{\Delta}(x,y)=\begin{cases}
            1    &   \text{si \( y= x\)}\\
            1    &    \text{si \( y\neq x\)}
        \end{cases}=\mtu_{\{ x \}}(y),
    \end{equation}
    et donc
    \begin{subequations}
        \begin{align}
            A_1&=\int_I\left( \int_I\mtu_{\Delta}(x,y)dm(y) \right)d\lambda(x)\\
            &=\int_I\left( \int_I\mtu_{\{ x \}}(y)dm(y) \right)d\lambda(x)\\
            &=\int_I\Big( m(\{ x \}) \Big)d\lambda(x)\\
            &=\int_I 1d\lambda(x)\\
            &=1.
        \end{align}
    \end{subequations}
    Par contre le support de \( \mtu_{\Delta}\) étant de mesure nulle pour la mesure de Lebesgue, nous avons
    \begin{equation}
        \int_I\mtu_{\Delta}(x,y)d\lambda(x)=0
    \end{equation}
    et par conséquent
    \begin{equation}
        A_2=\int_I\left( \int_I\mtu_{\Delta}(x,y)d\lambda(x) \right)dm(y)=0.
    \end{equation}
    Nous voyons donc que le théorème de Fubini ne s'applique pas.
\end{example}

\begin{example} \label{ExrgMIni}
    Nous nous proposons de calculer l'intégrale suivante en utilisant le théorème de Fubini :
    \begin{equation}
        G=\int_{\eR} e^{-x^2}dx,
    \end{equation}
    alors que la fonction \( x\mapsto  e^{-x^2}\) n'a pas de primitives parmi les fonctions élémentaires.

    Par symétrie nous pouvons nous contenter de calculer
    \begin{equation}
        G_+=\int_0^{\infty} e^{-x^2}dx.
    \end{equation}
    L'astuce est de passer par l'intermédiaire
    \begin{subequations}
        \begin{align}
            H&=\int_{\eR^+\times\eR^+} e^{-(x^2+y^2)}dxdy       \label{EqIntFausasub}\\
            &=\int_{\eR^+}\left( \int_{\eR^+} e^{-x^2} e^{-y^2}dx \right)dy\\
            &=\left( \int_{\eR^+} e^{-x^2} dx\right)^2\\
            &=G_+^2
        \end{align}
    \end{subequations}
    L'intégrale \eqref{EqIntFausasub} se calcule en passant aux coordonnées polaires et le résultat est \( H=\frac{ \pi }{ 4 }\). Nous avons alors \( G=\frac{ \sqrt{\pi} }{ 2 }\) et
    \begin{equation}
        \int_{\eR} e^{-x^2}=\sqrt{\pi}.
    \end{equation}
\end{example}

\begin{example}     \label{EXooLUFAooGcxFUW}
    Une variante, qui n'applique pas Fubini sur un domaine non borné. Nous commençons par écrire
\begin{equation}
	I=\int_{-\infty}^{+\infty} e^{-x^2} dx := \lim_{R \to +\infty} \int_{-R}^{+R} e^{-x^2} dx 
\end{equation}
et puis nous faisons le calcul
\begin{equation}		\label{EqCalculInteeemoisxcar}
	\begin{aligned}[]
		I^2 &= \lim_{R \to +\infty} \left( (\int_{-R}^{+R} e^{-x^2} dx)( \int_{-R}^{+R} e^{-y^2} dy) \right) \\
		&= \lim_{R \to +\infty} \left( \iint_{K_R}e^{-(x^2+y^2)} dx dy \right) \\
		&= \lim_{R \to +\infty} \left( \iint_{C_R}e^{-(x^2+y^2)} dx dy \right) 
	\end{aligned}
\end{equation}
où $K$ est le carré de demi côté $R$ centré à l'origine et de côtés parallèles aux axes et $C_R$ est le cercle de rayon $R$ centré à l'origine.

	La première étape à justifier est simplement l'application de Fubini. Pour le passage de l'intégrale du carré vers le cercle, définissons
	\begin{equation}
		\begin{aligned}[]
			I_K(r)&=\int_{K_r}f,&I_C(r)&=\int_{C_r}f
		\end{aligned}
	\end{equation}
	où $K_r$ est la carré de demi côté $r$ et $C_r$ est le cercle de rayon $r$. Le demi côté du carré inscrit à $C_r$ est $\sqrt{2}$, donc pour tout $r$ nous avons
	\begin{equation}
		I_K(\sqrt{2}r)\leq I_C(r)<I_K(r),
	\end{equation}
	et en prenant la limite, nous avons évidement
	\begin{equation}
		\lim_{r\to \infty}I_K(\sqrt{2}r)=\lim_{r\to\infty}I_K(r),
	\end{equation}
	et donc cette limite est également égale à $\lim_{r\to\infty}I_C(t)$.

    Il ne reste qu'à calculer la dernière intégrale sur le cercle en passant aux coordonnées polaires :
	\begin{equation}
        \iint_{C_R} e^{-(x^2+y^2)}dxdy=\int_0^{2\pi}d\theta\int_0^Rr e^{-r^2}dr=\pi(1- e^{-R^2}).
	\end{equation}
	La limite donne $\pi$, nous en déduisons que
    \begin{equation}    \label{EqFDvHTg}
		\int_{-\infty}^{\infty} e^{-x^2}dx=\sqrt{\pi}.
	\end{equation}

\end{example}

Le théorème de Fubini-Tonelli nous permet également d'inverser des sommes et des séries. En effet une somme n'est rien d'autre qu'une intégrale pour la mesure de comptage :
\begin{equation}
    \sum_{n=0}^{\infty}a_n=\int_{\eN}a_ndm(n).
\end{equation}
La proposition suivante montre comment il faut faire.

\begin{proposition}\label{PropInversSumIntFub}  
    Soient les espaces mesurés \( (\eN,\partP(\eN),m)\), \( (\eR^n,\Borelien(\eR^n),\lambda)\) où \( \lambda\) est la mesure de Lebesgue ainsi qu'une suite de fonctions positives \( f_n\colon \eR^d\to \eR\). Nous supposons de plus que la fonction \( f_n\) soit intégrable pour tout \( n\) et que les résultats forment une suite sommable. Alors
    \begin{equation}   
        \sum_{n=0}^{\infty}\int_{\eR^n}f_n(x)dx=\int_{\eR^d}\sum_{n\in \eN}f_n(x)dx.
    \end{equation}
\end{proposition}
\index{mesure!de comptage}
\index{permuter!intégrale!et série}

\begin{proof}
    Nous pouvons la récrire le membre de gauche sous la forme
    \begin{equation}
        \int_{\eN}\left( \int_{\eR^n}f(n,x)dx \right)dm(n)
    \end{equation}
    avec la notation évidente \( f(n,x)=f_n(x)\). Prouvons que la fonction \( f\colon \eN\times\eR^d\to \eR\) ainsi définie est une fonction mesurable pour l'espace mesuré
    \begin{equation}
        \big( \eN\times\eR^d,\partP(\eN)\otimes\Borelien(\eR^d),m\otimes\lambda \big).
    \end{equation}
    Si \( A\subset\eR\), nous avons
    \begin{equation}
        f^{-1}(A)=\bigcup_{n\in\eN}\{ n \}\times f_n^{-1}(A).
    \end{equation}
    Chacun des ensembles dans l'union appartient à la tribu \( \partP(\eN)\times\Borelien(\eR^d)\) tandis que les tribus sont stables sous les unions dénombrables. La fonction \( f\) est donc mesurable. Comme nous avons supposé que \( f\) était positive, le théorème de Fubini-Tonelli s'applique et nous avons
    \begin{equation}
        \int_{\eR^d}\left( \int_{\eN}f(n,x)dm(n) \right)dx=\int_{\eR^d}\sum_{n\in \eN}f_n(x)dx.
    \end{equation}
\end{proof}

\begin{theorem}[Fubini]\label{ThoFubini}
Soit $(x,t)\mapsto f(x,y)\in\bar \eR$ une fonction intégrable sur $B_n\times B_m\subset\eR^{n+m}$ où $B_n$ et $B_m$ sont des ensembles mesurables de $\eR^n$ et $\eR^m$. Alors :
\begin{enumerate}
\item pour tout $x\in B_n$, sauf éventuellement en les points d'un ensemble $G\subset B_n$ de mesure nulle, la fonction $y\in B_m\mapsto f(x,y)\in\bar\eR$ est intégrable sur $B_m$
\item
la fonction
\begin{equation}
	x\in B_n\setminus G\mapsto\int_{B_m}f(x,y)dy\in\eR
\end{equation}
est intégrable sur $B_n\setminus G$

\item 
On a
\begin{equation}
	\int_{B_n\times B_m}f(x,y)dxdy=\int_{B_n}\left( \int_{B_m}f(x,y)dy \right)dx.
\end{equation}

\end{enumerate}
\end{theorem}
\index{théorème!Fubini!dans $ \eR^n$}
\index{Fubini!théorème!dans $ \eR^n$}

Notons en particulier que si $f(x,y)=\varphi(x)\phi(y)$, alors $\int_{B_m}\varphi(y)dy$ est une constante qui peut sortir de l'intégrale sur $B_n$, et donc
\begin{equation}		\label{EqFubiniFactori}
	\int_{B_n\times B_m}\varphi(x)\phi(y)dxdy=\int_{B_n}\varphi(x)dx\int_{B_m}\phi(y)dy.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Interprétation géométrique du déterminant}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooSQRDooGifgQi}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Par rapport à la mesure de Lebesgue}
%---------------------------------------------------------------------------------------------------------------------------

Dans la suite, \( Q_0\) désigne le cube unité : \( Q_0=\big( \mathopen[ 0 , 1 \mathclose[ \big)^N\).

\begin{theorem}[Interprétation géométrique du déterminant\cite{PMTIooJjAmWR}]    \label{ThoBVIJooMkifod}
    Soit une application linéaire \( T\colon \eR^N\to \eR^N\). Alors pour tout borélien \( B\) de \( \eR^N\),
    \begin{equation}
        \lambda_N\big( T(B) \big)=| \det(T) |\lambda_N(B).
    \end{equation}
\end{theorem}
\index{déterminant!interprétation géométrique}

\begin{proof}
    Nous considérons la mesure positive \( \mu\) donnée par \( \mu(B)=\lambda_N\big( T(B) \big)\), qui est bien une mesure par la proposition \ref{PropJCJQooAdqrGA}. Cette mesure est invariante par translation parce que \( \lambda_N\) l'est :
    \begin{equation}
        \mu(B+a)=\lambda_N\big( T(B)+a \big)=\lambda_N\big( T(B) \big)=\mu(B).
    \end{equation}
    De plus, \( T(Q_0)\) est borné et nous notons \( \mu(Q_0)=C\). Nous avons \( \mu=C\lambda_N\) par le corollaire \ref{CorKGMRooHWOQGP}.

    \begin{subproof}
        \item[\( C(T_1T_2)=C(T_1)C(T_2)\)]
            Par définition, 
            \begin{equation}
                C(T_1T_2)\lambda_N(B)=\lambda_N\big( (T_1T_2)(B) \big)=\lambda_N\big( T_1(T_2B) \big)=C(T_1)\lambda_N\big( T_2(B) \big)=C(T_1)C(T_2)\lambda_N(B).
            \end{equation}
            Par conséquent la fonction \( C\) est multiplicative : 
            \begin{equation}
                C(T_1T_2)=C(T_1)C(T_2).
            \end{equation}
            Et en plus, \( C(\id)=1\).
        \item[Matrice diagonale]
            Nous considérons pour \( T=D\) l'application linéaire diagonale \( D=\diag(d_1,\ldots, d_N)\) qui fait
            \begin{equation}
                T(Q_0)=\mathopen[ 0 , d_1 \mathclose[\times \ldots\times \mathopen[  0, d_N \mathclose[
            \end{equation}
            La mesure de cela est \( |d_1\cdots d_N|\), ce qui nous donne
            \begin{equation}
                C(D)=| d_1\ldots d_N |=| \det(D) |.
            \end{equation}
        \item[Matrice orthogonale]
            Nous considérons maintenant \( T=U\) où \( U\) est une matrice orthogonale (\( UU^t=1\)). Une matrice orthogonale est une isométrie\footnote{Proposition \ref{PropKBCXooOuEZcS}.} qui conserve donc la boule unité : \( UB(0,1)=B(0,1)\). Nous avons
            \begin{equation}
                \lambda_N\big( B(0,1) \big)=\lambda_N\big( UB(0,1) \big)=C(U)\lambda_N\big( B(0,1) \big)
            \end{equation}
            par conséquent \( C(U)=1\), et \( 1\) est justement le déterminant de \( U\).
        \item[Matrice quelconque]
            Nous savons par le corollaire \ref{CorAWYBooNCCQSf} de la décomposition polaire que toute matrice peut être écrite sous la forme \( T=U_1DU_2\) où \( U_i\) sont orthogonales et \( D\) est diagonale. Donc \( C(T)=C(U_1)C(D)C(U_2)=\det(U_1)\det(D)\det(U_2)=\det(U_2DU_2)=\det(T)\) parce que le déterminant est multiplicatif (proposition \ref{PropYQNMooZjlYlA}\ref{ItemUPLNooYZMRJy}).
    \end{subproof}
\end{proof}

Ce théorème donne une interprétation géométrique du déterminant en tant que facteur de dilatation des volumes lors de l'utilisation d'une application linéaire. Si \( T\) est une application linéaire quelconque,
\begin{equation}
    \lambda_N\big( T(Q_0) \big)=| \det(T) |\lambda_N(Q_0)=| \det(T) |.
\end{equation}
Le déterminant de \( T\) est le volume de l'image du cube unité par l'application \( T\).

De la même façon, en utilisant l'application linéaire \( T(x)=ax\) nous avons pour tout borélien \( B\) :
\begin{equation}
    \lambda_N(aB)=a^N\lambda_N(B).
\end{equation}
Une dilatation d'un facteur \( a\) des longueurs provoque une multiplication par \( a^N\) des volumes.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{En petite dimension}
%---------------------------------------------------------------------------------------------------------------------------

Le déterminant d'une matrice et d'une application linéaire est la définition \ref{DefCOZEooGhRfxA}, et les principales propriétés algébriques sont données dans la proposition \ref{PropYQNMooZjlYlA}.

En dimension deux, le déterminant de la matrice
    $\begin{pmatrix}
        a    &   b    \\ 
        c    &   d    
    \end{pmatrix}$
est le nombre
\begin{equation}
    \begin{vmatrix}
          a  &   b    \\ 
        c    &   d    
    \end{vmatrix}=ad-cb.
\end{equation}
Ce nombre détermine entre autres le nombre de solutions que va avoir le système d'équations linéaires associé à la matrice.

Pour une matrice $3\times 3$, nous avons le même concept, mais un peu plus compliqué. Le déterminant de la matrice
\begin{equation}
    \begin{pmatrix}
        a_{11}    &   a_{12}    &   a_{13}    \\
        a_{21}    &   a_{22}    &   a_{23}    \\
        a_{31}    &   a_{32}    &   a_{33}    
    \end{pmatrix}
\end{equation}
est le nombre
\begin{equation}
    \begin{vmatrix}
        a_{11}    &   a_{12}    &   a_{13}    \\
        a_{21}    &   a_{22}    &   a_{23}    \\
        a_{31}    &   a_{32}    &   a_{33}    
    \end{vmatrix}=
    a_{11}\begin{vmatrix}
        a_{22}  &   a_{23}    \\ 
        a_{32}    &   a_{33}    
    \end{vmatrix}+
    a_{12}\begin{vmatrix}
        a_{21}  &   a_{23}    \\ 
        a_{31}    &   a_{33}
    \end{vmatrix}+
    a_{13}\begin{vmatrix}
        a_{21}  &   a_{22}    \\ 
        a_{31}    &   a_{32}
    \end{vmatrix}.
\end{equation}


La proposition suivante énumère des conséquences de la proposition \ref{PropYQNMooZjlYlA}.
\begin{proposition}
    Quelques propriétés du déterminant vu de la matrice.
    \begin{enumerate}
        \item
            Si on permute deux lignes ou deux colonnes d'une matrice, alors le déterminant change de signe.
        \item
            Si on multiplie une ligne ou une colonne d'une matrice par un nombre $\lambda$, alors le déterminant est multiplié par $\lambda$.
        \item
            Si deux lignes ou deux colonnes sont proportionnelles, alors le déterminant est nul.
        \item
            Si on ajoute à une ligne une combinaison linéaire des autres lignes, alors le déterminant ne change pas (idem pour les colonnes).
    \end{enumerate}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Produit vectoriel}
%---------------------------------------------------------------------------------------------------------------------------

Une application importante du déterminant $3\times 3$ est qu'il détermine le \defe{produit vectoriel}{produit!vectoriel} entre deux vecteurs. Pour cela nous introduisons les vecteurs de base
\begin{equation}
    \begin{aligned}[]
        e_x&=\begin{pmatrix}
            1    \\ 
            0    \\ 
            0    
        \end{pmatrix}
        ,&e_y=\begin{pmatrix}
            0    \\ 
            1    \\ 
            0    
        \end{pmatrix},&e_z&=\begin{pmatrix}
            0    \\ 
            0    \\ 
            1    
        \end{pmatrix}.
    \end{aligned}
\end{equation}
Ensuite, si $v$ et $w$ sont des vecteurs dans $\eR^3$, nous définissons
\begin{equation}
    \begin{aligned}[]
        \begin{pmatrix}
            v_x    \\ 
            v_y    \\ 
            v_z    
        \end{pmatrix}\times\begin{pmatrix}
            w_x    \\ 
            w_y    \\ 
            w_z    
        \end{pmatrix}=
        \begin{vmatrix}
              e_x  &   e_y    &   e_z    \\
              v_x  &   v_y    &   v_z    \\
              w_x  &   w_y    &   w_z    \\
        \end{vmatrix}&=
        (v_yw_z-w_yvz)e_x\\
        &-(v_xw_z-w_xvz)e_y\\
        &+(v_xw_y-w_xvy)e_z\in\eR^3
    \end{aligned}
\end{equation}

Ce produit vectoriel peut aussi être écrit sous la forme
\begin{equation}        \label{EqProdVectEspilonijk}
    v\times w=\sum_{i,j,k}\epsilon_{ijk}v_iw_j1_k.
\end{equation}
où $\epsilon_{ijk}$ est défini par $\epsilon_{xyz}=1$ et ensuite $\epsilon_{ijk}$ est $1$ ou $-1$ suivant que la permutation des $x$, $y$ et $z$ est paire ou impaire. C'est à dire que \( \epsilon_{ijk}\) est la signature de la permutation qui amène \( (1,2,3)\) sur \( (i,j,k)\).

Un grand intérêt du produit vectoriel est qu'il fournit un vecteur qui est simultanément perpendiculaire aux deux vecteurs donnés.
\begin{proposition}
    Le vecteur $v\times w$ est perpendiculaire à $v$ et à $w$.
\end{proposition}

\begin{proposition}
    Le produit vectoriel est une opération antisymétrique, c'est à dire
    \begin{equation}
        v\times w=-w\times v.
    \end{equation}
    En particulier $v\times v=0$ pour tout vecteur $v\in\eR^3$.
\end{proposition}

\begin{proposition}
    Le produit vectoriel est linéaire. Pour tout vecteurs $a$, $b$, $c$ et pour tout nombre $\alpha$ et $\beta$ nous avons
    \begin{equation}
        \begin{aligned}[]
            a\times (\alpha b +\beta c)&=\alpha(a\times b)+\beta(a\times c)\\
            (\alpha a+\beta b)\times c&=\alpha(a\times c)+\beta(b\times c).
        \end{aligned}
    \end{equation}
\end{proposition}

Les trois vecteurs de base $e_x$, $e_y$ et $e_y$ ont des produits vectoriels faciles à retenir :
\begin{equation}
    \begin{aligned}[]
        e_x\times e_y&=e_z\\
        e_y\times e_z&=e_x\\
        e_z\times e_x&=e_y
    \end{aligned}
\end{equation}

\begin{example}
    Calculons le produit vectoriel $v\times w$ avec
    \begin{equation}
        \begin{aligned}[]
            v&=\begin{pmatrix}
                3    \\ 
                -1    \\ 
                1    
            \end{pmatrix}&w=\begin{pmatrix}
                1    \\ 
                2    \\ 
                -1    
            \end{pmatrix}.
        \end{aligned}
    \end{equation}
    Les vecteurs s'écrivent sous la forme $v=3e_x-e_y+e_z$ et $w=e_x+2e_y-e_z$. Le produit vectoriel s'écrit
    \begin{equation}
        \begin{aligned}[]
            (3e_x-e_y+e_z)\times (e_x+2e_y-e_z)&=6e_x\times e_y-3e_x\times e_z\\
                                &\quad -e_y\times e_x + e_y\times e_z\\
                                &\quad + e_z\times e_x + 2e_z\times e_y\\
                                &=6e_z+3e_y+e_z+e_x+e_y-2e_x\\
                                &=-e_x+4e_y+7e_z.
        \end{aligned}
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Produit mixte}
%---------------------------------------------------------------------------------------------------------------------------

Si $a$, $b$ et $c$ sont trois vecteurs, leur \defe{produit mixte}{produit!mixte} est le nombre $a\cdot(b\times c)$. En écrivant le produit vectoriel sous forme de somme de trois déterminants $2\times 2$, nous avons
\begin{equation}
    \begin{aligned}[]
        a\cdot& (b\times c)\\&=(a_1e_x+a_2e_y+a_3e_z)\cdot\left(
        \begin{vmatrix}
            b_2    &   b_3    \\ 
            c_2    &   c_3    
        \end{vmatrix}e_x-\begin{vmatrix}
            b_1    &   b_3    \\ 
            c_1    &   c_3    
        \end{vmatrix}e_y+\begin{vmatrix}
            b_1    &   b_2    \\ 
            c_1    &   c_2    
        \end{vmatrix}\right)\\
        &=a_1\begin{vmatrix}
            b_2    &   b_3    \\ 
            c_2    &   c_3    
        \end{vmatrix}-a_2\begin{vmatrix}
            b_1    &   b_3    \\ 
            c_1    &   c_3    
        \end{vmatrix}+a_3\begin{vmatrix}
            b_1    &   b_2    \\ 
            c_1    &   c_2    
        \end{vmatrix}\\
        &=\begin{vmatrix}
            a_1    &   a_2    &   a_3    \\
            b_1    &   b_2    &   b_3    \\
            c_1    &   c_2    &   c_3
        \end{vmatrix}.
    \end{aligned}
\end{equation}
Le produit mixte s'écrit donc sous forme d'un déterminant. Nous retenons cette formule:
\begin{equation}        \label{EqProduitMixteDet}
    a\cdot (b\times c)=\begin{vmatrix}
        a_1    &   a_2    &   a_3    \\
        b_1    &   b_2    &   b_3    \\
        c_1    &   c_2    &   c_3
    \end{vmatrix}.
\end{equation}


\begin{proposition}
    Le produit vectoriel $a\times b$ est un vecteur orthogonal à $a$ et $b$.
\end{proposition}

\begin{proof}
    Vérifions que $a\perp (a\times b)$. Pour cela, nous calculons $a\cdot (a\times b)$, c'est à dire le produit mixte
    \begin{equation}
        a\cdot(a\times b)=\begin{vmatrix}
            a_1    &   a_2    &   a_3    \\
            a_1    &   a_2    &   a_3    \\
            b_1    &   b_2    &   b_3
        \end{vmatrix}=0.
    \end{equation}
    L'annulation de ce déterminant est due au fait que deux de ses lignes sont égales.
\end{proof}

\begin{proposition}     \label{PropNormeProdVectoabsint}
    Nous avons
    \begin{equation}
        \| a\times b \|=\| a \|\| b \|\sin(\theta)
    \end{equation}
    où $\theta\in\mathopen[ 0.\pi \mathclose]$ est l'angle formé par $a$ et $b$.
\end{proposition}

\begin{proof}
    En utilisant la décomposition du produit vectoriel, nous avons
    \begin{equation}
        \begin{aligned}[]
            \| a\times b \|^2&=\begin{vmatrix}
                a_2    &   a_3    \\ 
                b_2    &   b_3    
            \end{vmatrix}^2+\begin{vmatrix}
                a_1    &   a_3    \\ 
                b_1    &   b_3    
            \end{vmatrix}^2+\begin{vmatrix}
                a_1    &   a_2    \\ 
                b_1    &   b_2    
            \end{vmatrix}^2\\
            &=(a_2b_3-b_2a_3)^2+(a_1b_3-a_3b_1)^2+(a_1b_2-a_2b_1)^2\\
            &=(a_1^2+a_2^2+a_3^2)(b_1^2+b_2^2+b_3^2)-(a_1b_1+a_2b_2+a_3b_3)^2\\
            &=\| a \|^2\| b \|^2-(a\cdot b)^2\\
            &=\| a \|^2\| b \|^2-\| a \|^2\| b \|^2\cos^2(\theta)\\
            &=\| a \|^2\| b \|^2\big( 1-\cos^2(\theta) \big)\\
            &=\| a \|^2\| b \|^2\sin^2(\theta).
        \end{aligned}
    \end{equation}
    D'où le résultat.
\end{proof}

\begin{remark}      \label{RemaAireParalProdVect}
    Le nombre $\| a \|\| b \|\sin(\theta)$ est l'aire du parallélogramme formé par les vecteurs $a$ et $b$, comme cela se voit sur la figure \ref{LabelFigBNHLooLDxdPA}. % From file BNHLooLDxdPA
\newcommand{\CaptionFigBNHLooLDxdPA}{Calculer l'aire d'un parallélogramme.}
\input{Fig_BNHLooLDxdPA.pstricks}

\end{remark}

Ces résultats admettent une intéressante généralisation.
\begin{lemma}       \label{LEMooFRWKooVloCSM}
    Soit \( X\in \eR^n\) ainsi que \( v_1,\ldots, v_{n-1}\in \eR^n\). Alors
    \begin{enumerate}
        \item
            Nous avons
            \begin{equation}        \label{EQooMQNPooRHHBjz}
                \det(X,v_1,\ldots, v_{n-1})=X\cdot 
                \det\begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\ 
                        &   v_{n-1}    &   
                 \end{pmatrix}
            \end{equation}
        \item
            Le vecteur
            \begin{equation}
                \det\begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\ 
                        &   v_{n-1}    &   
                 \end{pmatrix}
            \end{equation}
            est orthogonal à tous les \( v_i\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Vu que les deux côtés de \eqref{EQooMQNPooRHHBjz} vus comme fonctions de \( X\), sont des applications linéaires de \( \eR^n\) dans \( \eR\), il suffit de vérifier l'égalité sur une base.

    Nous posons \( \tau_i\colon \eR^n\to \eR^{n-1}\),
    \begin{equation}
        \tau_i(v)_k=\begin{cases}
            v_k    &   \text{si \( k<i\)}\\
            v_{k+1}    &    \text{si \( k\geq i\).}
        \end{cases}
    \end{equation}
    et nous avons d'une part
    \begin{equation}
        e_k\cdot
                \det
                \begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\ 
                        &   v_{n-1}    &   
                 \end{pmatrix}
                 =\det\begin{pmatrix}
                     \tau_kv_1   \\ 
                     \vdots   \\ 
                     \tau_kv_{n-1}   
                 \end{pmatrix}
            \end{equation}
     et d'autre part,
     \begin{equation}
         \det(e_k,v_1,\ldots, v_{n-1})=\det
         \begin{pmatrix}
             0&&&\\  
             \vdots&&&\\  
             1&v_1&\cdots&v_{n-1}\\  
             \vdots&&&\\  
             0&&&  
         \end{pmatrix}=\det(\tau_k v_1,\ldots, \tau_k v_{n-1}).
     \end{equation}
     La première assertion est démontrée.

     En ce qui concerne la seconde, il suffit d'appliquer la première et se souvenir qu'un déterminant est nul lorsque deux lignes sont égales. En effet :
     \begin{equation}
         v_k\cdot \det
                \begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\ 
                        &   v_{n-1}    &   
                 \end{pmatrix}
                 =
                 \det(v_k,v_1,\ldots, v_n)=0.
     \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Déterminant en dimension deux}
%---------------------------------------------------------------------------------------------------------------------------

La valeur absolue du déterminant 
\begin{equation}        \label{EqDeratb}
    \begin{vmatrix}
        a_1    &   a_2    \\ 
        b_1    &   b_2    
    \end{vmatrix}
\end{equation}
est l'aire du parallélogramme déterminé par les vecteurs $\begin{pmatrix}
    a_1    \\ 
    a_2    
\end{pmatrix}$ et $\begin{pmatrix}
    b_1    \\ 
    b_2    
\end{pmatrix}$. En effet, d'après la remarque \ref{RemaAireParalProdVect}, l'aire de ce parallélogramme est donnée par la norme du produit vectoriel
\begin{equation}
    \begin{pmatrix}
        a_1    \\ 
        a_2    \\ 
        0    
    \end{pmatrix}\times
    \begin{pmatrix}
          b_1  \\ 
        b_2    \\ 
        0    
    \end{pmatrix}=\begin{vmatrix}
        e_x    &   e_y    &   e_z    \\
        a_1    &   a_2    &   0    \\
        b_1    &   b_2    &   0
    \end{vmatrix}=
    \begin{vmatrix}
        a_1    &   a_2    \\ 
        b_1    &   b_2    
    \end{vmatrix}e_z,
\end{equation}
donc la norme $\| a\times b \|$ est bien donnée par la valeur absolue du déterminant \eqref{EqDeratb}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Déterminant en dimension trois}
%---------------------------------------------------------------------------------------------------------------------------

Si les vecteurs $a$, $b$ et $c$ ne sont pas coplanaires, alors la valeur absolue du produit mixte (voir équation \eqref{EqProduitMixteDet}) $a\cdot(b\times c)$ donne le volume du parallélépipède construit sur les vecteurs $a$, $b$ et $c$.

En effet si $\varphi$ est l'angle entre $b\times c$ et $a$, alors la hauteur du parallélépipède vaut $\| a \|\cos(\varphi)$ parce que la direction verticale est donnée par $b\times c$, et la hauteur est alors la «composante verticale» de $a$. Par conséquent, étant donné que $\| b\times c \|$ est l'aire de la base, le volume du parallélépipède vaut
\begin{equation}
    V=\| b\times c\|  \| a \|\cos(\varphi).
\end{equation}
Or cette formule est le produit scalaire de $a$ par $b \times c$; ce dernier étant donné par le déterminant de la matrice formée des composantes de $a$, $b$ et $c$ grâce à la formule \eqref{EqProduitMixteDet}.

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Changement de variables dans une intégrale multiple}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Dans ce qui suit, \( U\) et \( V\) sont des ouverts de \( \eR^N\) et \( \phi\colon U\to V\) est un \( C^1\)-difféomorphisme. Nous notons \( \mQ\) l'ensemble des cubes fermés dans \( U\) dont les cotés sont parallèles aux axes.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Des lemmes}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{PMTIooJjAmWR}]      \label{LemooJYCGooIkkDVn}
    Soient \( \mu\) et \( \nu\) deux mesures de Borel sur l'ouvert \( U\) de \( \eR^N\). Si \( \mu(Q)\leq \nu(Q)\) pour tout \( Q\in \mQ\) alors \( \mu(B)\leq \nu(B)\) pour tout borélien \( B\).
\end{lemma}

\begin{proof}
    Si \( Q\) est un cube semi-ouvert, c'est à dire de la forme
    \begin{equation}
        Q=\prod_{i=1}N\mathopen[ a_n , a_n+h \mathclose[\subset U
    \end{equation}
    alors \( Q\) est une réunion croissante de cubes fermés du type \( \mathopen[ a_n+\epsilon , a_n+h-\epsilon \mathclose]\), et donc \( \mu(Q)\leq \nu(Q)\) par le lemme \ref{LemAZGByEs}\ref{ItemJWUooRXNPci}. La propriété est donc vraie pour les cubes semi-ouverts.

    Si \( \Omega\) est un ouvert, alors il est réunion disjointe dénombrable de cubes semi-ouverts par la proposition \ref{PropSKXGooRFHQst}. Donc pour tout ouvert \( \Omega\subset U\) nous avons \( \mu(\Omega)\leq\nu(\Omega)\). En vertu de la proposition \ref{PropNCASooBnbFrc} et de la remarque \ref{RemooOAGCooRHpjxd}, les mesures \( \mu\) et \( \nu\) sont régulières, et l'inégalité au niveau des ouverts se répercute en inégalité pour tout boréliens de \( U\) :
    \begin{equation}
        \mu(B)\leq \nu(B)
    \end{equation}
    pour tout \( B\in\Borelien(U)\). Notons que \( U\) étant ouvert dans \( \eR^N\), les boréliens de \( U\) sont exactement les boréliens de \( \eR^N\) inclus à \( U\) par le corollaire \ref{CorooMJQYooFfwoTd}.
\end{proof}

\begin{lemma}[\cite{PMTIooJjAmWR}]      \label{LemooJCEDooBRyjRg}
    Soit une application \( \theta\colon U\to \eR^N\) de classe \( C^1\) où \( U\) est ouvert dans \( \eR^N\). Pour tout \( Q\in\mQ\) nous avons
    \begin{equation}
        \lambda_N\big( \theta(Q) \big)\leq\sup_{s\in Q}\| d\theta_s \|^N\lambda_N(Q).
    \end{equation}
\end{lemma}

\begin{proof}
    Nous notons \( h\) la longueur du côté du cube. Le théorème des accroissements finis \ref{val_medio_2}, pour la composante \( \theta_i\) donne, pour \( u,v\in Q\) :
    \begin{equation}        \label{EqooFZMAooKWdzxJ}
        \big|  \theta_i(u)-\theta_i(v) \big|\leq\sup_{s\in Q}\| (d\theta_i)_s \|\| u-v \|\leq \sum_{s\in Q}\| (d\theta_i)_s \|h.
    \end{equation}
    D'autre part nous avons (nous écrivons pour \( N=2\) pour être plus court) :
    \begin{equation}
        d\theta_s(u)=\Dsdd{ \theta_1(s+tu)e_1+\theta_2(s+tu)e_2 }{t}{0}=(d\theta_1)_s(u)e_1+(d\theta_2)_s(u)e_2.
    \end{equation}
    Donc pour chaque \( i\) : \( \| d\theta_s \|\geq \| (d\theta_i)_s \|\), et nous continuons la majoration \eqref{EqooFZMAooKWdzxJ} :
    \begin{equation}
        \big|  \theta_i(u)-\theta_i(v) \big|\leq\leq \sum_{s\in Q}\| (d\theta_i)_s \|h\leq \sup_{s\in Q}\| d\theta_s \|h.
    \end{equation}
    
    Les points \( \theta(u)\) et \( \theta(v)\) sont donc dans un cube de côté \( \sup_{s\in Q}\| d\theta_s \|h\), ce qui permet de majorer \( \lambda_N\big( \theta(Q) \big)\) par
    \begin{equation}
        \lambda_N\big( \theta(Q) \big)\leq \left( \sup_{s\in Q}\| d\theta_s \|h \right)^N=\left( \sup_{s\in Q}\| d\theta_s \| \right)^N\lambda_N(Q)
    \end{equation}
    où le dernier facteur provient de l'égalité \( h^N=\lambda_N(Q)\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Le théorème et sa démonstration}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Changement de variable\cite{VSMEooLwNLHd,PMTIooJjAmWR}]         \label{THOooUMIWooZUtUSg}
    Soient \( U\) et \( V\) des ouverts de \( \eR^N\) ainsi qu'un \( C^1\)-difféomorphisme \(\phi\colon U\to V\).
    \begin{enumerate}
        \item   \label{ItemVWYDooOzwnyfi}
            Si \( E\subset U\) est borélien, alors \( \phi(E)\) est borélien et
            \begin{equation}
                \lambda_N\big( \phi(E) \big)=\int_E| J_{\phi} |d\lambda_N,
            \end{equation}
            c'est à dire \( \phi^{-1}(\lambda_N)=| J_{\phi} |\cdot \lambda_N\).
        \item       \label{ITEMooEZUBooGBuDOS}
            Si \( f\colon V\to \mathopen[ 0 , +\infty \mathclose]\) est mesurable alors la fonction
            \begin{equation}
                (f\circ\phi)\times | J_{\phi} |\colon U\to \mathopen[ 0 , \infty \mathclose]
            \end{equation}
            l'est également et\footnote{L'intégrabilité d'une fonction est la définition \ref{DefTCXooAstMYl} qui stipule que l'intégrale de \( | f(x) |\) est finie. L'égalité proposée a un sens si les deux membres sont infinis. Il n'y a donc pas d'hypothèses d'intégrabilité obligatoire pour écrire une intégrale lorsque la fonction a des valeurs positives.}
            \begin{equation}        \label{EqRANEooQsFhbC}
                \int_Vfd\lambda_N=\int_U(f\circ\phi)(x)| J_{\phi}(x) |d\lambda_N(x).
            \end{equation}
        \item       \label{ITEMooAJGDooGHKnvj}
            Si \( f\colon V\to \eC\) est mesurable alors elle est intégrable si et seulement si \( (f\circ \phi)\times | J_{\phi} |\colon U\to \eC\) est intégrable. Si c'est le cas, alors nous avons encore la formule de changement de variables :
            \begin{equation}        \label{EQooLYAWooTArAZR}
                \int_Vfd\lambda_N=\int_U (f\circ \phi)| J_{\phi} |d\lambda_N.
            \end{equation}
    \end{enumerate}
\end{theorem}

\begin{proof}
    Attention : la preuve va être longue.
    \begin{enumerate}
        \item
            Le fait que \( \phi(E)\) soit borélien lorsque \( E\) l'est est la proposition \ref{PropRDRNooFnZSKt}. En ce qui concerne la formule annoncée, il faut travailler.
            \begin{subproof}
            \item[Inégalité dans un sens (cubes)]
                Nous commençons par prouver l'inégalité
                \begin{equation}        \label{EqooQCXXooSjGzks}
                    \lambda_N\big( \phi(Q) \big)\leq \int_Q| J_{\phi}(x) |dx
                \end{equation}
                pour tout \( Q\in \mQ\). On peut diviser le côté du cube \( Q\) en \( k\) éléments de longueurs égales. Le cube est alors divisé en \( k^N\) petits cubes d'intérieurs disjoints. Nous les nommons \( Q_i\) (\( i=1,\ldots, k^N\)) Nous avons alors
                \begin{equation}
                    \sum_i\lambda_N(Q_i)=\sum_i\lambda_N\big( \Int(Q_i) \big)=\lambda_N\big( \bigcup_i\Int(Q_i) \big)\leq \lambda_N(Q)\leq \sum_i\lambda_N(Q_i).
                \end{equation}
                La dernière inégalité est le fait que les intersections ne sont pas disjointes. Toutes ces inégalités sont en réalité des égalités et en particulier : \( \lambda_N(Q)=\sum_i\lambda_N(Q_i)\).

                Soit \( a\in Q_i\) et posons
                \begin{equation}
                    \begin{aligned}
                        \theta&\colon U&\to U \\
                        \theta&=(d\phi_{a})^{-1}\circ\phi 
                    \end{aligned}
                \end{equation}
                Cela appelle deux commentaires. D'abord l'application \( d\phi_{a}\colon U\to V\) est inversible parce que \( \phi\) est un difféomorphisme (lemme \ref{LemooTJSZooWkuSzv}). Ensuite, l'application \( \theta\) est la composée de \( (d\phi_{a})\) (qui est linéaire) et de \( \phi\) qui est de classe \( C^1\); donc \( \theta\) est de classe \( C^1\). Donc le lemme \ref{LemooJCEDooBRyjRg} s'applique. La différentielle de \( \theta\) n'est pas trop compliquée à écrire parce que nous avons la formule de différentielle d'une composée (théorème \ref{ThoAGXGuEt}) et le fait que \( (d\phi_{a})^{-1}\) qui est linéaire et donc sa propre différentielle (lemme \ref{LemooXXUGooUqCjmp}). Nous avons donc \( d\theta=(d\phi_a)^{-1}\circ d\phi\), et le lemme donne
                \begin{equation}
                    \lambda_N\left( (d\phi_a)^{-1}\phi(a) \right)\leq \sup_{s\in Q_i}\|    (d\phi_a)^{-1}\circ d\phi_s  \|^N\lambda_N(Q_i)
                \end{equation}
                Étant donné que \( (d\phi_a)^{-1}\) est une application linéaire, la proposition \ref{ThoBVIJooMkifod} s'applique, et donc
                \begin{equation}
                    \lambda_N\left( (d\phi_a)^{-1}\phi(a) \right)=| \det(d\phi_a)^{-1} |\lambda_N\big( \phi(a) \big).
                \end{equation}
                Le déterminant d'une application réciproque est donné par la proposition \ref{PropYQNMooZjlYlA}\ref{ItemooPJVYooYSwqaE} :
                \begin{equation}
                    \det\big( (d\phi_a)^{-1} \big)=\frac{1}{ \det\big( d\phi_a \big) }=\frac{1}{ J_{\phi}(a) }.
                \end{equation}
                Recollant les morceaux,
                \begin{equation}
                    \lambda_N\big( \phi(Q_i) \big)\frac{1}{ J_{\phi}(a) }\leq \sup_{s\in Q_i}\| (d\phi_a)^{-1}\circ d\phi_s \|^N\lambda_N(Q_),
                \end{equation}
                ou encore :
                \begin{equation}
                    \lambda_N\big( \phi(Q_i) \big)\leq | J_{\phi}(a) |\sup_{s\in Q_i}\| (d\phi_a)^{-1}\circ d\phi_s \|^N\lambda_N(Q_i).
                \end{equation}
                Vu que \( a\) et \( s\) sont proches l'un de l'autre (on peut choisir encore la taille du cube), nous pouvons espérer que \( (d\phi_a)^{-1}\) ne soit pas loin d'être l'inverse de \( d\phi_s\). Et c'est en effet le cas. Pour s'en assurer, remarquons que l'application
                \begin{equation}
                    d\phi\colon Q_i\to \aL(\eR^N,\eR^N)
                \end{equation}
                est continue et même uniformément continue parce que \( Q_i\) est compact. De plus la composition de différentielles étant un produit de matrices nous pouvons permuter la limite dans le calcul suivant :
                \begin{equation}
                    \lim_{s\to a}(d\phi_a)^{-1}\circ d\phi_s=(d\phi_a)^{-1}\circ\lim_{s\to a}d\phi_s=\mtu.
                \end{equation}
                Donc si \( \epsilon>0\) est donné, il existe \( \delta\) tel que pour tout \( s\in B(a,\delta)\), \( \| (d\phi_a)^{-1}\circ d\phi_s-\mtu \|\leq \epsilon\). En ce qui concerne les  normes, si \( \| A-\mtu \|\leq \epsilon\) alors \( \| A \|\leq \| A-\mtu \|+\| \mtu \|\leq \epsilon+1\).

                Cela étant dit, nous nous souvenons que nous avions découpé \( U\) en un nombre fini de cubes \( Q_i\) d'égales dimensions; il suffit de prendre \( k\) suffisamment grand pour que la diagonale des cubes sot plus petite que le minimum des \( \delta_i\). Avec un tel découpage,
                \begin{equation}
                    \sup_{s\in Q_i}\| (d\phi_a)^{-1}\circ d\phi_s \|\leq 1+\epsilon
                \end{equation}
                et par conséquent
                \begin{equation}        \label{EqooQRMNooZduAkX}
                    \lambda_N\big( \phi(Q_i) \big)\leq (1+\epsilon)^N| J_{\phi}(a_i) |\lambda_N(Q_i)
                \end{equation}
                où nous avons ajouté un indice \( i\) au point \( a\) pour nous rappeler que nous avons choisit \( a\in Q_i\). 

                Le théorème des valeurs intermédiaires \ref{ThoooEZLGooMChwLT} appliqué à l'intégrale \( \int_{Q_i}| J_{\phi}(t) |d\lambda_N(t)\) donne l'existence d'un \( a_i\in Q_i\) tel que
                \begin{equation}
                    | J_{\phi}(a_i) |=\frac{1}{ \lambda_N(Q_i) }\int_{Q_i}| J_{\phi} |d\lambda_N.
                \end{equation}
                Ce point \( a_i\) vérifie l'inégalité \eqref{EqooQRMNooZduAkX} comme tout point de \( Q_i\). Nous sommons ces inégalités sur tous les \( i\) :
                \begin{subequations}
                    \begin{align}
                        \lambda_N\big( \phi(Q) \big)&\leq\sum_i\lambda_N\big( \phi(Q_i) \big)\\
                        &\leq (1+\epsilon^N\sum_i\left( \frac{1}{ \lambda_N(Q_i)\int_{Q_i}| J_{\phi} |d\lambda_N } \right)\lambda_N(Q_i)\\
                        &=(1+\epsilon)^N\sum_i\int_{Q_i}| J_{\phi} |d\lambda_N\\
                        &=(1+\epsilon)^N\int_Q| J_{\phi} |d\lambda_N
                    \end{align}
                \end{subequations}
                où nous avons utilisé le fait que \( \mtu_Q=\sum_i\mtu_{Q_i}\) presque partout. En prenant le limite \( \epsilon\to 0\) nous trouvons
                \begin{equation}
                    \lambda_N\big( \phi(Q) \big)\leq \int_Q| J_{\phi} |d\lambda_N.
                \end{equation}
                L'inégalité \eqref{EqooQCXXooSjGzks} est prouvée.
            \item[Inégalité pour les boréliens]

                Soit \( B\) un borélien de \( U\). Vu que \( U\) et \( V\) sont des ouverts de \( \eR^N\), les mesures de Lebesgue sur \( U\) et sur \( V\) sont les mêmes que celles sur \( \eR^n\)  par le corollaire \ref{CorooMJQYooFfwoTd}.

                Par les définitions \ref{PropooVXPMooGSkyBo} et \ref{PropJCJQooAdqrGA}, les applications \( \mu\) et \( n\) définies par \( \mu=\phi^{-1}(\lambda_N)\) et \( \nu=| J_{\phi} |\lambda_N\) sont des mesures positives sur \( U\) (de Borel, qui plus est). L'inégalité \eqref{EqooQCXXooSjGzks} à peine prouvée s'écrit \( \mu(Q)\leq \nu(Q)\) pour tout cube \( Q\). Le lemme \ref{LemooJYCGooIkkDVn} nous dit alors que l'inégalité tient pour tout borélien.

            \item[Inégalité dans l'autre sens]

                En utilisant la notation de la mesure image et du produit d'une mesure par une fonction\footnote{Définition \ref{PropJCJQooAdqrGA} et \ref{PropooVXPMooGSkyBo}}, nous pouvons écrite l'inégalité prouvée sous la forme \( \phi^{-1}(\lambda_N)\leq | J_{\phi} |\lambda_N\). En inversant les rôles de \( U\) et \( V\) (et donc de \( \phi\) et \( \phi^{-1}\)) nous avons aussi
                \begin{equation}
                    \phi(\lambda_N)\leq| J_{\phi^{-1}} |\lambda_N.
                \end{equation}
                En y appliquant \( \phi^{-1}\) et le lemme \ref{PropJCJQooAdqrGA},
                \begin{equation}        \label{EqooHJCHooVIaheI}
                    \lambda_N\leq \phi^{-1}\big( | J_{\phi^{-1}} |\lambda_N \big).    
                \end{equation}
                Nous prouvons à présent que \( \phi^{-1}\big( | J_{\phi^{-1}} |\cdot \lambda_N \big)=\Big( | J_{\phi^{-1}} |\circ\phi \Big)\cdot \phi^{-1}(\lambda_N)\) en appliquant à un borélien \( B\) de \(U\).
                D'une part 
                \begin{subequations}
                    \begin{align}
                        \phi^{-1}\big( | J_{\phi^{-1}} |\cdot\lambda_N \big)(B)&=\big( | J_{\phi^{-1}} |\cdot\lambda_N \big)\phi(B)\\
                        &=\int_{\phi(B)}| J_{\phi^{-1}} |d\lambda_N,
                    \end{align}
                \end{subequations}
                et d'autre part,
                \begin{subequations}
                    \begin{align}
                        \big( | J_{\phi^{-1}} |\circ\phi \big)\cdot\phi^{-1}(\lambda_N)B&=\int_{\eR^N}\mtu_B(x)\big( | J_{\phi^{-1}} |\circ\phi \big)(x)d\big( \phi^{-1}(\lambda_N) \big)(x)\\
                        &=   \int_{\eR^N}\mtu_B\big( \phi^{-1}(x) \big)\big( | J_{\phi^{-1}} |\circ\phi \big)\big( \phi^{-1}(x) \big)d\lambda_N(x)       \label{ooDKSWooXwQwgO}\\
                        &=\int_{\eR^N}\mtu_{\phi(B)}| J_{\phi^{-1}} |\\
                        &=\int_B| J_{\phi^{-1}} |d\lambda_N.
                    \end{align}
                \end{subequations}
                Justification :
                \begin{itemize}
                    \item Pour \eqref{ooDKSWooXwQwgO}, le théorème \ref{THOooVADUooLiRfGK}\ref{ItemooLAPYooUreDEl}.
                \end{itemize}

                L'équation \eqref{EqooHJCHooVIaheI} devient alors
                \begin{equation}
                    \lambda_N\leq \big( | J_{\phi^{-1}} |\circ\phi \big)\cdot \phi^{-1}(\lambda_N).
                \end{equation}
                Nous allons faire le produit de cette mesure par \( | J_{\phi} |\) en nous souvenant que \( J_{\phi}(x)=\det\big( d\phi_x \big)\). Par le lemme \ref{LemooTJSZooWkuSzv} nous avons aussi \(   (d\phi_x)^{-1}=d\phi^{-1}_{\phi(x)} \) et donc, par la propriété \ref{PropYQNMooZjlYlA}\ref{ITEMooZMVXooLGjvCy} du déterminant,
                \begin{equation}
                    J_{\phi}(x)=\frac{1}{ \det\big( d\phi^{-1}_{\phi(x)} \big) }=\frac{1}{ J_{\phi^{-1}}\big( \phi(x) \big) }.
                \end{equation}
                Nous avons
                \begin{equation}
                    | J_{\phi} |\cdot\lambda_N\leq | J_{\phi} |\cdot\big( | J_{\phi^{-1}} |\circ\phi \big)\cdot\phi^{-1}(\lambda_N).
                \end{equation}
                En utilisant la proposition \ref{PropooJMWAooDzfpmB}, il s'agit de multiplier la mesure \( \phi^{-1}(\lambda_N)\) par la fonction
                \begin{equation}
                    x\mapsto | J_{\phi}(x)J_{\phi^{-1}}\big( \phi(x) \big) |=1.
                \end{equation}
                Nous avons donc bien
                \begin{equation}
                    | J_{\phi} |\cdot \lambda_N\leq \phi^{-1}(\lambda_N),
                \end{equation}
                et donc l'égalité
                \begin{equation}
                    | J_{\phi} |\cdot\lambda_N=\phi^{-1}(\lambda_N),
                \end{equation}
                c'est à dire le point \ref{ItemVWYDooOzwnyfi}.
            \end{subproof}
        \item
            Le fait que la fonction proposée soit mesurable est le fait que la mesurabilité n'est pas affectée par produit et composition (propositions \ref{PROPooODDVooEEmmTX} et \ref{PROPooEFHKooARJBwW}), et le fait que pour les mêmes raisons, l'application \( J_{\phi}\colon U\to \eR\) est également mesurable. En ce qui concerne la formule nous allons la démontrer dans le cas de fonctions de plus en plus générales.
            \begin{subproof}
            \item[Pour les fonctions indicatrices]
                Soit \( B\) un borélien de \( U\), et considérons la fonction \( f=\mtu_{\phi(B)}\). Alors
                \begin{equation}    \label{EqYXRFooJEqVBH}
                        \int_V fd\lambda_N=\int_{\eR^N}\mtu_{\phi(B)}(y)\mtu_V(y)d\lambda_N(y)
                        =\int_{\eR^N}\mtu_{\phi(B)}d\lambda_N
                        =\lambda_N\big( \phi(B) \big).
                \end{equation}
                parce que \( V=\phi(U)\) et \( B\subset U\), donc \( \mtu_{\phi(B)}\mtu_{\phi(U)}=\mtu_{\phi(B)}\). D'autre part, pour calculer l'autre membre de \eqref{EqRANEooQsFhbC} nous remarquons que \( f=\mtu_{\phi(B)}=\mtu_B\circ\phi^{-1}\), ce qui donne
                \begin{equation}        \label{EqHWRQooKIfPTu}
                    \int_Uf\big( \phi(x) \big)| J_{\phi}(x) |d\lambda_N(x)=\int_U\mtu_B| J_{\phi} |d\lambda_N=\int_B| J_{\phi} |d\lambda_N.
                \end{equation}
                L'ensemble \( B\) étant borélien, il est extrêmement mesurable, ce qui fait que le point \ref{ItemVWYDooOzwnyfi} s'applique : les expressions \eqref{EqYXRFooJEqVBH} et \eqref{EqHWRQooKIfPTu} sont égales.

            \item[Pour les fonctions étagées]

                   Soit \( f\colon V\to \eR^+\) une fonction étagée :
                   \begin{equation}
                       f(x)=\sum_{i=1}^na_i\mtu_{A_i}(x)
                   \end{equation}
                   Nous pouvons faire le calcul suivant :
                   \begin{subequations}
                       \begin{align}
                           \int_Vfd\lambda_N&=\int_V\sum_ia_i\mtu_{A_i}d\lambda_N\\
                           &=\sum_ia_i\int_{V}\mtu_{A_i}d\lambda_N      \label{ooNESRooDuNUYF}\\
                           &=\sum_i\int_U(\mtu_{a_i}\circ\phi)(x)| J_{\phi}(x) |d\lambda_N(x)   \label{ooYXHSooKMPrIT}\\
                           &=\sum_ia_i\int_U\mtu_{\phi^{-1}(A_i)}| J_{\phi}(x) |d\lambda_N(x)\\
                           &=\int_V\underbrace{\sum_ia_i\mtu_{\phi^{-1}(A_i)}(x)}_{=(f\circ\phi)(x)}| J_{\phi}(x) |d\lambda_N(x)\\
                           &=\int_V(f\circ\phi)| J_{\phi} |d\lambda_N.
                       \end{align}
                   \end{subequations}
                   Justifications :
                   \begin{itemize}
                       \item Pour \eqref{ooNESRooDuNUYF} : linéarité de l'intégrale, théorème \ref{ThoooCZCXooVvNcFD}\ref{ITEMooBLEVooDznQTY}\footnote{Il est remarquable que nous n'utilisons cette linéarité que pour les fonction étagées.}
                       \item Pour \eqref{ooYXHSooKMPrIT} : le cas des fonctions indicatrices est utilisé pour chaque \( i\) entre \( 1\) et \( n\).
                   \end{itemize}

               \item[Fonction mesurable positive]
                   Soit \( f\colon V\to \mathopen[ 0 , \infty \mathclose]\). Par le théorème fondamental d'approximation \ref{THOooXHIVooKUddLi}, il existe une suite croissante de fonctions étagées et mesurables \( \varphi_n\colon V\to \mathopen[ 0 , \infty \mathclose[\) dont la limite ponctuelle est \( f\).  Nous avons alors le calcul suivant :
                       \begin{subequations}
                           \begin{align}
                               \int_Vfd\lambda_N&=\lim_{n\to \infty} \int_V\varphi_nd\lambda_N  \label{ooGMMFooXLHijj}\\
                               &=\lim_{n\to \infty} \int_U(\varphi_n\circ\phi)| J_{\phi} |d\lambda_N \label{ooWIFWooXELNUs}\\
                               &=\int_U\lim_{n\to \infty} (\varphi_n\circ\phi)| J_{\phi} |d\lambda_N \label{ooNKXNooUYeWKo}\\
                               &=\int_U(f\circ\phi)| J_{\phi} |d\lambda_N       \label{ooOAIDooAILHIB}.
                           \end{align}
                       \end{subequations}
                       Justifications :
                       \begin{itemize}
                           \item Pour \eqref{ooGMMFooXLHijj}, c'est le théorème de la convergence monotone \ref{ThoRRDooFUvEAN}.
                           \item Pour \eqref{ooWIFWooXELNUs}, c'est le présent théorème pour la fonction étagée \( \varphi_n\).
                           \item Pour \eqref{ooNKXNooUYeWKo}, c'est encore la convergence dominée, justifiée par le fait que \(  \varphi_n\circ\phi    \) est également une suite croissante : si \( x\in U\) alors \( \varphi_{n+1}\big( \phi(x) \big)\geq \varphi_n\big( \phi(x) \big)   \).\
                           \item Pour \eqref{ooOAIDooAILHIB}, c'est la limite ponctuelle \( \varphi_n\big( \phi(x) \big)\to f\big( \phi(x) \big)\).
                       \end{itemize}
            \end{subproof}
        \item
            La partie sur l'intégrabilité repose sur le fait (ici \( | . |\) est le module et non une valeur absolue) \( | f |\circ\phi=| f\circ\phi |\). Les faits suivants sont équivalents :
            \begin{itemize}
                \item la fonction \( f\colon V\to \eC\) est intégrable
                \item la fonction \( | f |\colon V\to \eR\) est intégtrable
                \item la fonction \( (| f |\circ\phi)| J_{\phi} |\colon U\to \eR\) est intégrable (par le point \ref{ITEMooEZUBooGBuDOS}).
                \item la fonction \( (f\circ\phi)| J_{\phi} |\colon U\to \eR\) est intégrable.
            \end{itemize}
            En ce qui concerne la formule, il s'agit seulement d'appliquer le point \ref{ITEMooEZUBooGBuDOS} aux parties positives, négatives, imaginaires et réelles de \( f\).
    \end{enumerate}
\end{proof}

% Attention : ce théorème est utilisé avec \varphi dans ce sens-ci.
%\begin{theorem} \label{ThomFeRCi}
%    Soit \( \mO\) un ouvert de \( \eR^n\) et \( \varphi\colon \mO\to \varphi(\mO)\) un difféomorphisme \( C^1\). Si \( f\colon \mO\to \eR\) est une fonction mesurable, positive et intégrable, alors
%    \begin{equation}
%        \int_{\mO}f(u)du=\int_{\varphi(\mO)}f\big( \varphi^{-1}(v) \big)| J_{\varphi^{-1}}(v) |dv.
%    \end{equation}
%\end{theorem}

%\begin{theorem}		\label{ThoChmVarInt}
%  Soient $U$ et $V$ deux ouverts bornés de $\eR^p$, $\phi$ un difféomorphisme de classe $\mathcal{C}^1$ de $U$ sur $V$ et $f$ une fonction intégrable de $V$ sur $\eR$. Alors nous avons la formule de changement de variables 
%  \begin{equation}
%    \int_{V}f(y)\, dy= \int_{U} f(\phi(x))\, \left| J_{\phi}(x)\right|\, dx,
%  \end{equation}
%  où $J_{\phi}$ est le déterminant de la matrice jacobienne\index{jacobienne} de $\phi$. 
%\end{theorem}

\begin{normaltext}
La formule de changement de variables peut être comprise de la façon suivante. Si $\phi$ est linéaire  alors le facteur $|J_{\phi}|$ est la mesure de l'image par $\phi$ d'une portion de $\eR^p$ de mesure $1$, sinon  $|J_{\phi}|$ est le rapport entre la mesure de l'image d'un élément infinitésimale de volume de $\eR^p$ et sa mesure originale. 

Soit $\phi(u,v)=g(u,v)e_1+h(u,v)e_2$ un difféomorphisme dans $\eR^2$. Soit $(x_0, y_0)$ l'image par $\phi$ de $(u_0,v_0)$. On considère le petit rectangle $R$ de sommets $(u_0,v_0)$, $(u_0+\Delta u,v_0)$, $(u_0+\Delta u,v_0+\Delta v)$ et $(u_0,v_0+\Delta v)$. L'image de $R$ n'est pas un rectangle en général, mais peut être bien approximée par le rectangle de sommets $(x_0,y_0)$, $(x_0 ,y_0)+ \phi_{u}\Delta u$, $(x_0 ,y_0)+\phi_{u}\Delta u +\phi_{v}\Delta v$ et  $(x_0 ,y_0)+ \phi_{v}\Delta v$ et son aire est $\| \phi_{u}\times \phi_{v}\| \Delta u\Delta v$. La valeur $|\phi_{u}\times \phi_{v}|$ est exactement $|J_{\phi}|$ 
\end{normaltext}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Exemples}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}
Soit $V$ la région trapézoïdale de sommets $(0,-1)$, $(1,0)$, $(2,0)$, $(0,-2)$, comme à la figure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci0}. Calculons ensemble l'intégrale double  
\[
\int_{V}e^{\frac{x+y}{x-y}}\,dV,
\] 
avec le changement de variable $\psi(x,y)=(x+y,x-y)$. C'est à dire que nous considérons les nouvelles variables
\begin{subequations}
	\begin{numcases}{}
		u=x+y\\
		v=x-y.
	\end{numcases}
\end{subequations}
Il faut remarquer d'abord que le changement de variable proposé est dans le mauvais sens. On écrit alors $\phi(u,v)=\psi^{-1}(u,v)=\big((u+v)/2, (u-v)/2\big)$, c'est à dire
\begin{subequations}
	\begin{numcases}{}
		x=\frac{ u+v }{ 2 }\\
		y=\frac{ u-v }{2}.
	\end{numcases}
\end{subequations}
La région qui correspond à $V$ est $U$, le trapèze de sommets  $(-1,1)$, $(1,1)$, $(2,2)$ et $(-2,2)$, qu'on voit sur la figure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci1} et qu'on décrit par
\[
U=\{ (u,v)\in\eR^2\,\vert\, 1\leq v\leq 2, \, -v\leq u\leq v\}.
\] 

% Celui-ci a été supprimée le 17 juillet 2014
%\ref{LabelFigexamplechangementvariables}
%\newcommand{\CaptionFigexamplechangementvariables}{Avant et après le changement de variables}
%\input{Fig_examplechangementvariables.pstricks}

%The result is on figure \ref{LabelFigZTTooXtHkci}. % From file ZTTooXtHkci
%See also the subfigure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci0}
%See also the subfigure \ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci1}
\newcommand{\CaptionFigZTTooXtHkci}{Avant et après le changement de variables}
\input{Fig_ZTTooXtHkci.pstricks}

On observe que $U$ est une région du premier type tandis que $V$ n'est pas du premier ou du deuxième type. Le déterminant de la  matrice  jacobienne de $\psi^{-1}$ est  $J_{\psi^{-1}}$,
\begin{equation}
 J_{\psi^{-1}}(u,v)= \left\vert\begin{array}{cc}
\frac{1}{2} & \frac{1}{2} \\
\frac{1}{2}  & -\frac{1}{2}
\end{array}\right\vert= -\frac{1}{2}.
\end{equation}
On a alors 
\[
\int_{V}e^{\frac{x+y}{x-y}}\,dV=\int_{U}e^{\frac{u}{v}}\,\frac{1}{2}\,dV=\int_1^2\int_{-v}^{v}e^{\frac{u}{v}}\,\frac{1}{2}\, du\,dv= \frac{3}{4}(e-e^{-1}).
\] 
\end{example}

\begin{example} 
\textbf{Coordonnées polaires : }On veut évaluer l'intégrale de la fonction $f(x,y)= x^2+y^2$ sur la région $V$ suivante :
\[
V=\{(x,y) \in \eR^2\,\vert\, x^2+y^2\leq 1,\, x>0,\, y>0\}.
\]
On peut faire le calcul directement,
\[
\int_{V}f(x,y)\, dV=\int_0^1\int_0^{\sqrt{1-x^2}}x^2+y^2\, dy\,dx=\int_0^1x^2\sqrt{1-x^2} + \frac{(1-x^2)^{3/2}}{3}\, dx  
\] 
mais c'est un peu ennuyeux. On peut simplifier beaucoup les calculs avec un changement de variables vers les coordonnées polaires. Dans ce cas, on sait bien que le difféomorphisme à utiliser est $\phi(r,\theta)=(r\cos \theta, r\sin\theta)$. Le jacobien  $J_{\phi}$ est
\begin{equation}
 J_{\phi}(r, \theta)= \left\vert\begin{array}{cc}
\cos \theta & \sin \theta \\
-r\sin \theta  & r\cos \theta
\end{array}\right\vert= r,
\end{equation}
qui est toujours positif. La fonction $f$ peut s'écrire comme $f(\phi(r,\theta))=r^2$ et $\phi^{-1}(V)=]0,1]\times]0, \pi/2[$.  
La formule du changement de variables nous donne
\[
\int_{V}f(x,y)\, dV=\int_0^{\pi/2}\int_0^{1}r^3 dr\,d\theta=\int_0^{\pi/2}\frac{1}{4}\,d\theta=\frac{\pi}{8}.  
\] 
\end{example}

\begin{example}
\textbf{Coordonnées cylindriques : }On veut calculer le volume de la région $A$ définie par  l'intersection entre la boule unité et le cylindre qui a pour base un disque de rayon $1/2$ centré en $(0, 1/2)$
\[
A=\{(x,y,z) \in\eR^3 \,\vert\, x^2+y^2+z^1\leq 1\}\cap\{(x,y,z) \in \eR^3\,\vert\, x^2+(y-1/2)^2\leq 1/4\}.
\]
On peut décrire $A$ en coordonnées cylindriques
\begin{equation}
  \begin{aligned}
    A=\Big\{(r,\theta,z) &\in ]0, +\infty[\times [-\pi,\pi[\times \eR\,\vert\,\\
& -\pi/2<\theta<\pi, \, 0<r\leq \sin\theta, \, -\sqrt{1-r^2}\leq z\leq\sqrt{1-r^2} \Big\}.
  \end{aligned}
\end{equation}
Le jacobien de ce changement de variables,  $J_{cyl}$, est
\begin{equation}
 J_{cyl}(r, \theta), z= \left\vert\begin{array}{ccc}
\cos \theta & \sin \theta & 0\\
-r\sin \theta  & r\cos \theta &0 \\
0&0&
\end{array}\right\vert= r,
\end{equation}
qui est toujours positif. Le volume de $A$ est donc
\[
\int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_{-\pi/2}^{\pi/2}\int_0^{\sin\theta}\int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}} r dz\,dr\,d\theta=\frac{2\pi}{8}+\frac{8}{9}.  
\] 
\end{example}

\begin{example}
\textbf{Volume d'un solide de révolution : }Soit $g:[a,b]\to\eR_+$ une fonction continue et positive. On dit que le solide $A$ décrit par
\[
A=\left\{(x,y,z)\in\eR^3\, \vert \, z\in[a,b], \,\sqrt{x^2+y^2}\leq g^2(z) \right\}
\]
est un solide de révolution. Afin de calculer son volume, on peut décrire $A$ en coordonnées cylindriques, 
\[
A=\left\{(r,\theta,z) \in ]0, +\infty[\times [-\pi,\pi[\times \eR\,\vert\, a\leq z\leq b, \, 0<r^2\leq g^2(z) \right\}.
\]
Le jacobien de ce changement de variables est  $J_{cyl}=r$, comme dans l'exemple précédent. Le volume de $A$ est donc
\[
\int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_a^{b}\int_{-\pi}^{\pi}\int_{0}^{g(z)} r  \,dr\,d\theta\, dz=\int_a^{b} \pi g^2(z) \, dz.
\] 
Cette formule peut être utilisée pour tout solide de révolution. 
\end{example}

\begin{example}
\textbf{Coordonnées sphériques : }On veut calculer le volume du cornet de glace  $A$ 
\[
A=\left\{(x,y,z)\in\eR^3\, \vert \, (x,y)\in \mathbb{S}^2, \,\sqrt{x^2+y^2}\leq z\leq \sqrt{1-x^2-y^2} \right\}. 
\]
On peut décrire $A$ en coordonnées sphériques. 
\[
A=\{(\rho,\theta,\phi) \in ]0, +\infty[\times [-\pi,\pi[\times [0,\pi[\,\vert\, 0<\phi\leq\pi/4, \, 0<\rho\leq 1 \}.
\]
Le jacobien de ce changement de variables  $J_{sph}$ est
\begin{equation}
 J_{sph}(\rho, \theta, \phi)= \left\vert\begin{array}{ccc}
\cos \theta \sin\phi & \sin \theta\sin\phi & \cos\phi\\
-\rho\sin \theta\sin\phi  & \rho\cos \theta\sin\phi & 0 \\
\rho\cos\theta\cos\phi&\rho\sin\theta\cos\phi& -\rho\sin\phi
\end{array}\right\vert= \rho^2\sin\phi,
\end{equation}
Le volume de $A$ est donc
\[
\int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_{-\pi}^{\pi}\int_0^{\pi/4}\int_{0}^{1}\rho^2\sin\phi \,d\rho\,d\phi\,d\theta=\frac{2\pi}{3}\left(1-\frac{1}{\sqrt{2}}\right).  
\] 
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Récapitulatif des changements de variables}
%---------------------------------------------------------------------------------------------------------------------------

En pratique, nous retiendrons les formules suivantes:
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées polaires}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{subequations}
    \begin{numcases}{}
        x=r\cos\theta\\
        y=r\sin\theta
    \end{numcases}
\end{subequations}
avec \( r\in\mathopen] 0 , \infty \mathclose[\) et \( \theta\in\mathopen[ 0 , 2\pi [\). Le jacobien vaut \( r\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées cylindriques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{subequations}
    \begin{numcases}{}
        x=r\cos\theta\\
        y=r\sin\theta\\
        z=z
    \end{numcases}
\end{subequations}
avec \( r\in\mathopen] 0 , \infty \mathclose[\), \( \theta\in\mathopen[ 0 , 2\pi [\) et \( z\in\eR\). Le jacobien vaut \( r\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées sphériques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{subequations}
    \begin{numcases}{}
        x=\rho\cos\theta\sin\phi\\
        y=\rho\sin\theta\sin\phi\\
        z=\rho\cos\phi
    \end{numcases}
\end{subequations}
avec \( \rho\in\mathopen] 0 , \infty \mathclose[\), \( \theta\in\mathopen[ 0 , 2\pi [\) et \( \phi\in\mathopen[ 0 , \pi [\). Le jacobien vaut \( -\rho^2\sin(\phi)\). 

N'oubliez pas que lorsqu'on effectue un changement de variables dans une intégrale, la \emph{valeur absolue} du jacobien apparaît.

Cependant notre convention de coordonnées sphériques fait venir \( \sin(\phi)\) avec \( \phi\in\mathopen[ 0 , \pi [\); vu que le signe de \( \sin(\phi)\) y est toujours positif, cette histoire de valeur absolue est sans grandes conséquent. Ce n'est pas le cas de toutes les conventions possibles.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Changement de variables}
%---------------------------------------------------------------------------------------------------------------------------

Le domaine $E=\{ (x,y)\in\eR^2\tq x^2+y^2<1 \}$ s'écrit plus facilement $E=\{ (r,\theta)\tq r<1 \}$ en coordonnées polaires. Le passage aux coordonnées polaire permet de transformer une intégration sur un domaine rond à une intégration sur le domaine rectangulaire $\mathopen]0,2\pi\mathclose[\times\mathopen]0,1\mathclose[$. La question est évidement de savoir si nous pouvons écrire
\begin{equation}
	\int_Ef=\int_{0}^{2\pi}\int_0^1f(r\cos\theta,r\sin\theta)drd\theta.
\end{equation}
Hélas, non; la vie n'est pas aussi simple.

\begin{theorem}
Soit $g\colon A\to B$ un difféomorphisme. Soient $F\subset B$ un ensemble mesurable et borné et $f\colon F\to \eR$ une fonction bornée et intégrable. Supposons que $g^{-1}(F)$ soit borné et que $Jg$ soit borné sur $g^{-1}(F)$. Alors
\begin{equation}
	\int_Ff(x)dy=\int_{g^{-1}(F)f\big( g(x) \big)}| Jg(x) |dx
\end{equation}
\end{theorem}
Pour rappel, $Jg$ est le déterminant de la matrice \href{http://fr.wikipedia.org/wiki/Matrice_jacobienne}{jacobienne} (aucun lien de \href{http://fr.wikipedia.org/wiki/Jacob}{parenté}) donnée par
\begin{equation}
	Jg=\det\begin{pmatrix}
	\partial_xg_1	&	\partial_yg_1	\\ 
	\partial_xg_2	&	\partial_tg_2	
\end{pmatrix}.
\end{equation}
Un \defe{difféomorphisme}{difféomorphisme} est une application $g\colon A\to B$ telle que $g$ et $g^{-1}\colon B\to A$ soient de classe $C^1$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Coordonnées polaires}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Les coordonnées polaires sont données par le difféomorphisme
\begin{equation}
	\begin{aligned}
		g\colon \mathopen]0,\infty\mathclose[\times\mathopen]0,2\pi\mathclose[ &\to\eR^2\setminus D\\
		(r,\theta)&\mapsto \big( r\cos(\theta),r\sin(\theta) \big)
	\end{aligned}
\end{equation}
où $D$ est la demi droite $y=0$, $x\geq 0$. Le fait que les coordonnées polaires ne soient pas un difféomorphisme sur tout $\eR^2$ n'est pas un problème pour l'intégration parce que le manque de difféomorphisme est de mesure nulle dans $\eR^2$. Le jacobien est donné par
\begin{equation}
	Jg=\det\begin{pmatrix}
	\partial_rx	&	\partial_{\theta}x	\\ 
	\partial_ry	&	\partial_{\theta}y
\end{pmatrix}=\det\begin{pmatrix}
	\cos(\theta)	&	-r\sin(\theta)	\\ 
	\sin(\theta)	&	r\cos(\theta)	
\end{pmatrix}=r.
\end{equation}

\begin{example}    
    Montrons comment intégrer la fonction $f(x,y)=\sqrt{1-x^2-y^2}$ sur le domaine délimité par la droite $y=x$ et le cercle $x^2+y^2=y$, représenté sur la figure \ref{LabelFigQXyVaKD}. Pour trouver le centre et le rayon du cercle $x^2+y^2=y$, nous commençons par écrire $x^2+y^2-y=0$, et ensuite nous reformons le carré : $y^2-y=(y-\frac{ 1 }{2})^2-\frac{1}{ 4 }$.
    \newcommand{\CaptionFigQXyVaKD}{Passage en polaire pour intégrer sur un morceau de cercle.}
\input{Fig_QXyVaKD.pstricks}

    Le passage en polaire transforme les équations du bord du domaine en
    \begin{equation}
        \begin{aligned}[]
            \cos(\theta)&=\sin(\theta)\\
            r^2&=r\sin(\theta).
        \end{aligned}
    \end{equation}
    L'angle $\theta$ parcours donc $\mathopen] 0 , \pi/4 \mathclose[$, et le rayon, pour chacun de ces $\theta$ parcours $\mathopen] 0 , \sin(\theta) \mathclose[$. La fonction à intégrer se note maintenant $f(r,\theta)=\sqrt{1-r^2}$. Donc l'intégrale à calculer est
    \begin{equation}		\label{PgRapIntMultFubiniBoutCercle}
        \int_{0}^{\pi/4}\left( \int_0^{\sin(\theta)}\sqrt{1-r^2}r\,rd \right).
    \end{equation}
    Remarquez la présence d'un $r$ supplémentaire pour le jacobien.

    Notez que les coordonnées du point $P$ sont $(1,1)$.
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées sphériques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Les coordonnées sphériques sont données par
\begin{equation}		\label{EqChmVarSpherique}
	\left\{
\begin{array}{lllll}
x=r\cos\theta\sin\varphi	&			&r\in\mathopen] 0 , \infty \mathclose[\\
y=r\sin\theta\sin\varphi	&	\text{avec}	&\theta\in\mathopen] 0 , 2\pi \mathclose[\\
z=r\cos\varphi			&			&\phi\in\mathopen] 0 , \pi \mathclose[.
\end{array}
\right.
\end{equation}
Le jacobien associé est $Jg(r,\theta,\varphi)=-r^2\sin\varphi$. Rappelons que ce qui rentre dans l'intégrale est la valeur absolue du jacobien.

Si nous voulons calculer le volume de la sphère de rayon $R$, nous écrivons donc
\begin{equation}
	\int_0^Rdr\int_{0}^{2\pi}d\theta\int_0^{\pi}r^2 \sin(\phi)d\phi=4\pi R=\frac{ 4 }{ 3 }\pi R^3.
\end{equation}
Ici, la valeur absolue n'est pas importante parce que lorsque $\phi\in\mathopen] 0,\pi ,  \mathclose[$, le sinus de $\phi$ est positif.

Des petits malins pourraient remarquer que le changement de variable \eqref{EqChmVarSpherique} est encore une paramétrisation de $\eR^3$ si on intervertit le domaine des angles : 
\begin{equation}
	\begin{aligned}[]
		\theta&\colon 0 \to \pi\\
		\phi	&\colon 0\to 2\pi,
	\end{aligned}
\end{equation}
alors nous paramétrons encore parfaitement bien la sphère, mais hélas
\begin{equation}		\label{EqVolumeIncorrectSphere}
	\int_0^Rdr\int_{0}^{\pi}d\theta\int_0^{2\pi}r^2 \sin(\phi)d\phi=0.
\end{equation}
Pourquoi ces «nouvelles» coordonnées sphériques sont-elles mauvaises ? Il y a que quand l'angle $\phi$ parcours $\mathopen] 0 , 2\pi \mathclose[$, son sinus n'est plus toujours positif, donc la \emph{valeur absolue} du jacobien n'est plus $r^2\sin(\phi)$, mais $r^2\sin(\phi)$ pour les $\phi$ entre $0$ et $\pi$, puis $-r^2\sin(\phi)$ pour $\phi$ entre $\pi$ et $2\pi$. Donc l'intégrale \eqref{EqVolumeIncorrectSphere} n'est pas correcte. Il faut la remplacer par
\begin{equation}
	\int_0^Rdr\int_{0}^{\pi}d\theta\int_0^{\pi}r^2 \sin(\phi)d\phi- \int_0^Rdr\int_{0}^{\pi}d\theta\int_{\pi}^{2\pi}r^2 \sin(\phi)d\phi = \frac{ 4 }{ 3 }\pi R^3
\end{equation}

\subsection{Coordonnées polaires}
Soit $T$ la fonction de $]0, +\infty[\times \eR$ dans $\eR^2\setminus\{(0,0)\}$ définie par
\begin{equation}
  \begin{array}{lccc}
    T: &]0, +\infty[\times \eR & \to & \eR^2\setminus\{(0,0)\}\\
 & (r, \theta)&\mapsto& (r\cos \theta, r \sin \theta),
  \end{array}
\end{equation}
Cette fonction est surjective. Elle est bijective sur chaque bande de la forme  $]0, +\infty[\times [a-\pi,a+\pi[$. Si $a=0$ l'inverse de $T$  est la fonction $T^{-1}(x,y)= (\sqrt{x^2+y^2}, \arctg (y/x))$. Soit $P=(x,y)$ un élément dans $\eR^2$, on dit que $r=\sqrt{x^2+y^2}$ est le rayon de $P$ et que $\theta=\arctg (y/x) $ est son argument principal. L'origine ne peut pas être décrite en coordonnées polaires parce que si son rayon est manifestement zéro, on ne peut pas lui associer une valeur univoque de l'angle $\theta$. 

\begin{example}
L'équation du cercle de rayon $a$ et centre $(0, 0)$ en coordonnées polaires est $r=a$. 
\end{example}

\begin{example}
	Une équation possible pour la demi-droite $x=y$, $x>0$,  est $\theta=\pi/4$.         
\end{example}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++   
\subsection{Coordonnées cylindriques}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Soit $T$ la fonction de $]0, +\infty[\times \eR^2$ dans $\eR^3\setminus\{(0,0,0)\}$ définie par
\begin{equation}
  \begin{array}{lccc}
    T: &]0, +\infty[\times \eR\times \eR & \to & \eR^3\setminus\{(0,0,0)\}\\
 & (r, \theta, z)&\mapsto& (r\cos \theta, r \sin \theta, z),
  \end{array}
\end{equation}
Cette fonction est surjective. Elle est bijective sur chaque bande de la forme  $]0, +\infty[\times [a-\pi,a+\pi[\times \eR$, $a$ dans $\eR$. Il n'y a presque rien de nouveau par rapport aux coordonnées polaires. Les coordonnées  cylindriques sont intéressantes si on décrit un objet invariant par rapport aux rotations autour de l'axe des $z$. 

\begin{example}
Il faut savoir ce que décrivent les équations les plus simples en coordonnées cylindriques, 
\begin{itemize}
\item $r\leq a$, pour $a$ constant dans  $]0, +\infty[$, est le cylindre de hauteur infinie qui a pour axe l'axe des $z$ et pour base le disque de rayon $a$ centré à l'origine, 
\item $r= a$ est  la surface du cylindre,
\item $\theta = b$ est un demi-plan ouvert et sa fermeture contient l'axe des $z$,
\item $z=c$ est un plan parallèle au plan $x$-$y$. 
\end{itemize}
\end{example}

\begin{example}
  Un demi-cône qui a  son sommet en l'origine et  pour axe l'axe des $z$ est décrit par $z=d r$.  Si $d$ est positif  il s'agit  de la moitié supérieure du cône, si $d<0$ de la moitié inférieure.
\end{example}

\begin{example}
 De même,  la sphère de rayon $a$ et centrée à l'origine est l'assemblage des calottes $z=\sqrt{a^2-r^2}$ et $z=-\sqrt{a^2-r^2}$. 
\end{example}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++   
\subsection{Coordonnées sphériques}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit $T$ la fonction de $]0, +\infty[\times \eR^2$ dans $\eR^3\setminus\{(0,0,0)\}$ définie par
\begin{equation}
  \begin{array}{lccc}
    T: &]0, +\infty[\times \eR\times \eR & \to & \eR^3\setminus\{(0,0,0)\}\\
 & (\rho, \theta, \phi)&\mapsto& (\rho\cos \theta\sin \phi, \rho \sin \theta\sin \phi, \rho\cos \phi),
  \end{array}
\end{equation}
Cette fonction est surjective. Elle est bijective sur chaque bande de la forme  $]0, +\infty[\times [a-\pi,a+\pi[\times [b-\pi/2, b+\pi/2[$, $a$ et $b$ dans $\eR$.  Si $a =0$ et $b=-\pi/2$ la fonction inverse $T^{-1}$ est donnée donnée
\begin{equation}
  \begin{array}{lccc}
    T: &\eR^3\setminus\{(0,0,0)\} & \to & ]0, +\infty[\times [-\pi,\pi[\times [0, \pi[\\
 & (x,y,z)&\mapsto& \left(\sqrt{x^2+y^2+z^2}, \arctg \frac{y}{x}, \arccos \left(\frac{z}{\sqrt{x^2+y^2+z^2}}\right)\right). 
  \end{array}
\end{equation}
Soit $ P$ un point dans $\eR^3$. L'angle $\phi$ est l'angle entre le demi-axe positif des $z$ et le vecteur $\overrightarrow{OP}$, $\rho$ est la norme de $\overrightarrow{OP}$ et $\theta$ est l'argument en coordonnées polaires de la projection de $\overrightarrow{OP}$ sur le plan $x$-$y$.  

\begin{remark}
	Dans la littérature, les angles $\theta$ et $\phi$ sont parfois inversés (voire, changent de nom, par exemple $\varphi$ au lieu de $\phi$). Il faut donc être très prudent lorsqu'on veut utiliser dans un cours des formules données dans un autre cours.
\end{remark}

\begin{example}
Il faut connaître le sens des équations plus simples, 
\begin{itemize}
\item $\rho\leq a$, pour $a$ constant dans  $]0, +\infty[$, est la boule fermée de rayon $a$ centrée à l'origine, 
\item $\rho= a$ est  la sphère de rayon $a$ centrée à l'origine,
\item $\theta = b$ est un demi-plan ouvert et sa fermeture contient l'axe des $z$,
\item $\phi= c$ est un demi-cône qui a  son sommet à l'origine et  pour axe l'axe des $z$.  Si $c$ est positif  il s'agit  de la moitié supérieure du cône, si $d<0$ de la moitié inférieure. 
\end{itemize}
 \end{example}
